{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7505990",
   "metadata": {},
   "source": [
    "# Data Management and Relational Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afab4880",
   "metadata": {},
   "source": [
    "## Data Management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c139d2",
   "metadata": {},
   "source": [
    "Data-Driven Decisions\n",
    "Which of the following statements is/are correct? \n",
    "\n",
    "\n",
    "Data-driven decisions are the decisions that an organisation makes on the basis of various data metrics.    ✓ Correct\n",
    "\n",
    "Data metrics are reported and business users make decisions based on this data. Business users make data-driven decisions based on the reports delivered from certain data metrics.\n",
    "\n",
    "\n",
    "Data-driven decisions help organisations analyse markets before launching new products.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb462283",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c6bf0c3",
   "metadata": {},
   "source": [
    "Database Structures\n",
    "Choose whether the following statement is true or false:\n",
    "\n",
    "‘The database structures used for transaction systems and for data analysis are different.’\n",
    "\n",
    "\n",
    "True    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ba891f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3387fac",
   "metadata": {},
   "source": [
    "## Components of Data Management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e631348",
   "metadata": {},
   "source": [
    "Data Quality\n",
    "Choose whether the following statement is true or false:\n",
    "\n",
    "‘Data quality ensures that every field contains data of the specified data type and only permitted values are used in every field.’\n",
    "\n",
    "\n",
    "True    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3b9523",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "694d8983",
   "metadata": {},
   "source": [
    "Data Integrity\n",
    "Which of the following issue/s can be prevented with data integrity?\n",
    "\n",
    "\n",
    "Data inconsistency   ✓ Correct\n",
    "\n",
    "\n",
    "Storage of the same data at different locations   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785881de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3df6427",
   "metadata": {},
   "source": [
    "Data Governance\n",
    "Complete the following sentence:\n",
    "\n",
    "Data governance in a file system is difficult because ___________  (Multiple options may be correct.)\n",
    "\n",
    "\n",
    "Files do not exist in just one format.    ✓ Correct\n",
    "\n",
    "Programs written to manipulate data in a file are particular to each file and can be written in any language.  ✓ Correct\n",
    "\n",
    "The number of programs that are written to access and manipulate each file can be large.   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6680bbca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b86a236b",
   "metadata": {},
   "source": [
    "Data Security\n",
    "Which of the following statement/s about data security is/are correct?\n",
    "\n",
    "\n",
    "It defines authorised users for data usage.   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91df844d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2ca8ab0",
   "metadata": {},
   "source": [
    "DBMS\n",
    "In which of the following formats do a relational DBMS stores data?\n",
    "\n",
    "\n",
    "Structured Format   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e94bdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75668597",
   "metadata": {},
   "source": [
    "## Uses of Managed Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4baf25",
   "metadata": {},
   "source": [
    "Central Repository\n",
    "Choose whether the following statement is true or false:\n",
    "\n",
    "A central repository is used for data integration.\n",
    "\n",
    "\n",
    "True    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf89e752",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf03e138",
   "metadata": {},
   "source": [
    "Data Sources\n",
    "Which of the following data source/s is/are used by a company to collect data?\n",
    "\n",
    "\n",
    "The Web   ✓ Correct\n",
    "\n",
    "Daily Transaction Systems   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92649927",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a2612b4",
   "metadata": {},
   "source": [
    "Data Warehouses\n",
    "Choose whether the following statement is true or false:\n",
    "\n",
    "'Data warehouses contain only structured data.'\n",
    "\n",
    "\n",
    "True    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246bb64c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a14fe1c5",
   "metadata": {},
   "source": [
    "Data Repository\n",
    "Which of the following systems is used as a repository for data in a semi-structured or an unstructured format?\n",
    "\n",
    "\n",
    "Data Warehouse\n",
    "\n",
    "\n",
    "Data Lake   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16076f57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b82795b9",
   "metadata": {},
   "source": [
    "Data Warehouses\n",
    "Choose the correct criterion for the statement given below:\n",
    "\n",
    "In an organisation, queries are made on the data stored in a data warehouse to create reports. For this, the data stored in the data warehouse must be _______\n",
    "\n",
    "\n",
    "Secure\n",
    "\n",
    "\n",
    "Consistent\n",
    "\n",
    "\n",
    "Integrated\n",
    "\n",
    "\n",
    "All of these     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bbe18e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78125ec4",
   "metadata": {},
   "source": [
    "# E-R Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b34f1e",
   "metadata": {},
   "source": [
    "## Three-Level Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ba7f77",
   "metadata": {},
   "source": [
    "View Level\n",
    "Complete the following statement with the correct option(s): \n",
    "\n",
    "Different applications can be developed to access a database and retrieve information from it. These applications are a part of the view level in the three-level architecture of a database. As these applications access the same database, the view level __________\n",
    "\n",
    "\n",
    "Provides secure access to each user.   ✓ Correct\n",
    "\n",
    "Applications are not affected by the physical storage of data.   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9f3860",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38260d83",
   "metadata": {},
   "source": [
    "## Data Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dea4fac",
   "metadata": {},
   "source": [
    "Data Models\n",
    "Why is data modelling necessary at the logical level of a database?\n",
    "\n",
    "\n",
    "To design different data elements in a particular structure     ✓ Correct\n",
    "\n",
    "To design the physical structure in which data can be stored on devices\n",
    "\n",
    "\n",
    "To give a specific structure to the data in accordance with the business requirements    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cba4f00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "401dcc26",
   "metadata": {},
   "source": [
    "E-R Model\n",
    "Which of the following element does an E-R model identify real-life objects as?\n",
    "\n",
    "\n",
    "Entity    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3edcdf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e9dd38d",
   "metadata": {},
   "source": [
    "Relational model\n",
    "In which of the following formats does a relational model store data?\n",
    "\n",
    "\n",
    "Tables    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e201569b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c82c01cf",
   "metadata": {},
   "source": [
    "## Building an E-R Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28852e4",
   "metadata": {},
   "source": [
    "Entities and Attributes\n",
    "Suppose you are developing an E-R model for an online retail store, where every user has an ‘Address’. The ‘Address’ attribute is further divided into various other attributes such as City, State and Country. Among these attributes, only the values of the attribute Zip Code can be used to obtain the values of the attributes State and Country, as every city has a different zip code. Considering these factors, which of the following statements is correct?\n",
    "\n",
    "\n",
    "The address must be kept as an attribute.\n",
    "\n",
    "\n",
    "Zip Code must be kept as an attribute, with Address as a different entity.     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15779bce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46d00684",
   "metadata": {},
   "source": [
    "Relational Model\n",
    "Complete the following sentence with the correct option:\n",
    "\n",
    "In a relational model, an entity is a _______\n",
    "\n",
    "\n",
    "Table    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80328c12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd12fbf0",
   "metadata": {},
   "source": [
    "Relational Model\n",
    "Complete the following sentence with the correct option:\n",
    "\n",
    "In a relational model, an attribute is a _________\n",
    "\n",
    "\n",
    "Table\n",
    "\n",
    "\n",
    "Column    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f813704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c9768fd",
   "metadata": {},
   "source": [
    "E-R Model\n",
    "Suppose there is an entity named Department that has multiple attributes. This E-R model is implemented into a physical database. How is the record for each department stored in a table?\n",
    "\n",
    "\n",
    "Rows    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6706c800",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1747099",
   "metadata": {},
   "source": [
    "E-R Model\n",
    "Customer and Product are two different entities. Now, can you have Customer as one entity and Product as an attribute for the entity Customer?\n",
    "\n",
    "\n",
    "Yes\n",
    "\n",
    "\n",
    "No     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28171e4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f884caad",
   "metadata": {},
   "source": [
    "Entities\n",
    "Consider three different entities -  Department, Employee and User. The attributes for these entities are given along with them. Which of the following entities are incorrect?\n",
    "\n",
    "\n",
    "Department - Name, Manager and Number of Employees\n",
    "\n",
    "\n",
    "Employee - Employee ID and Name\n",
    "\n",
    "\n",
    "User - Login, Name and Orders    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7886c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35463b3a",
   "metadata": {},
   "source": [
    "## Relation in an E-R Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0286df66",
   "metadata": {},
   "source": [
    "Degree of Relation\n",
    "Suppose for one row in the entity Team, there are many corresponding rows in the entity Project. Which of the following relations exists between the entity Team and the entity Project in this case? (Multiple options may be correct.)\n",
    "\n",
    "\n",
    "A one-to-many relation\n",
    "\n",
    "\n",
    "A one-to-one relation\n",
    "\n",
    "\n",
    "Maybe a one-to-many relation    ✓ Correct\n",
    "\n",
    "Maybe a many-to-many relation     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95e636a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6aad56c0",
   "metadata": {},
   "source": [
    "Degree of Relation\n",
    "Suppose for one row in the entity Team, there is only one corresponding row in the entity Project. And for one row in the entity Project, there are many corresponding rows in the entity Team. Which of the following relations exists between the entity Team and the entity Project in this case?\n",
    "\n",
    "\n",
    "A one-to-one relation\n",
    "\n",
    "\n",
    "A one-to-many relation\n",
    "\n",
    "\n",
    "A many-to-one relation    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013d6f74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7abacdec",
   "metadata": {},
   "source": [
    "Degree of Relation\n",
    "Every department in a company has many employees, but an employee can only belong to one department. What is the type of relation between the department and the employee entities?\n",
    "\n",
    "\n",
    "One-to-One\n",
    "\n",
    "\n",
    "One-to-Many     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7ed6b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "140c1158",
   "metadata": {},
   "source": [
    "Degree of Relation\n",
    "Entity A and entity B have a many-to-many relation. Which of the following statement/s is/are correct?\n",
    "\n",
    "\n",
    "Each row of entity A is necessarily related to many rows of entity B.\n",
    "\n",
    "\n",
    "Each row of entity B can be related to many rows of entity A.    ✓ Correct\n",
    "\n",
    "Each row of entity A can be related to only one row of entity B.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1194360d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7556389",
   "metadata": {},
   "source": [
    "## Cardinality\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db2e938",
   "metadata": {},
   "source": [
    "Maximum cardinality defines the maximum participation of an entity in a relation. State whether this statement is true or false.\n",
    "\n",
    "\n",
    "True   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882cc97d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9194d0ed",
   "metadata": {},
   "source": [
    "Which of the following can be identified if the degree of relation between entities is known?\n",
    "\n",
    "\n",
    "Maximum Cardinality   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48015586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22f3dee8",
   "metadata": {},
   "source": [
    "Consider a case where: An employee must belong to only one company, but a company can have any number of employees.\n",
    "\n",
    "Which of the following statement/s is/are correct? \n",
    "\n",
    "\n",
    "The relation between an employee and a company is many-to-one.    ✓ Correct\n",
    "\n",
    "The relation between a company and an employee is one-to-many.    ✓ Correct\n",
    "\n",
    "The minimum cardinality of the employee entity is 1.    ✓ Correct\n",
    "\n",
    "The maximum cardinality of the company entity is 1.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307349aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a5f62ab",
   "metadata": {},
   "source": [
    "## Comprehension - ERD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42840849",
   "metadata": {},
   "source": [
    "Primary Key\n",
    "Which of the following fields can be a possible primary key of the ‘Marks’ table? Multiple options can be correct.\n",
    "\n",
    "\n",
    "grades   ✓ Correct\n",
    "\n",
    "marks_range   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d806b7ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd246b14",
   "metadata": {},
   "source": [
    "Foreign Key\n",
    "What are the foreign keys in the ‘Student’ table? Multiple options can be correct.\n",
    "\n",
    "\n",
    "student_id\n",
    "\n",
    "\n",
    "marks_range    ✓ Correct\n",
    "\n",
    "year\n",
    "\n",
    "\n",
    "branch_id    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfe8129",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3542592",
   "metadata": {},
   "source": [
    "Primary and Foreign Keys\n",
    "Choose the correct statements for the ‘HoD’ table from the options given below. Multiple options can be correct.\n",
    "\n",
    "\n",
    "‘branch_id’ can be the primary key of the ‘HoD’ table.\n",
    "\n",
    "\n",
    "‘branch_id’ is the foreign key of the ‘HoD’ table.  ✓ Correct\n",
    "\n",
    "‘branch_id’ and ‘year_of_service_as_HoD’ can be the composite primary key of the ‘HoD’ table.   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9049069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e66e7bf",
   "metadata": {},
   "source": [
    "# Relational Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bcacf6",
   "metadata": {},
   "source": [
    "## A Relational Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9fb3c2",
   "metadata": {},
   "source": [
    "Relational Model\n",
    "Which of the following is another name for a row? (Multiple options may be correct.)\n",
    "\n",
    "\n",
    "Tuple   ✓ Correct\n",
    "\n",
    "Record   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81905478",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc3ed053",
   "metadata": {},
   "source": [
    "Relational model\n",
    "How does a table in a relational model provide data quality assurance? (Multiple options may be correct.)\n",
    "\n",
    "\n",
    "By ensuring that non-null fields contain values     ✓ Correct\n",
    "\n",
    "By ensuring that every field contains only permitted values     ✓ Correct\n",
    "\n",
    "By ensuring that the data in a field is of the specified data type     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff49c84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "036b25e8",
   "metadata": {},
   "source": [
    "Relational Model\n",
    "Which of the following is present in a table in a relational model? (Multiple options may be correct.)\n",
    "\n",
    "\n",
    "A unique primary key   ✓ Correct\n",
    "\n",
    "Attributes in a particular order\n",
    "\n",
    "\n",
    "A unique name   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8925e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "333e8b01",
   "metadata": {},
   "source": [
    "## Database Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b88614",
   "metadata": {},
   "source": [
    "Super Keys\n",
    "For an Employee table containing the following attributes, Please identify the super keys. (Multiple options may be correct.)\n",
    "\n",
    "Each Employee have only one registered phone number.\n",
    "\n",
    "<Employee ID, Name, Phone Number, ZipCode>\n",
    "\n",
    "\n",
    "<Employee ID>    ✓ Correct\n",
    "\n",
    "<Employee ID, ZipCode>    ✓ Correct\n",
    "\n",
    "<Name, Phone Number>    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78b5ab7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7688843d",
   "metadata": {},
   "source": [
    "Candidate Keys\n",
    "Identify the candidate keys for a table containing the following attributes. (Multiple options may be correct.)\n",
    "\n",
    "Each Employee have only one registered phone number.\n",
    "\n",
    "<Employee ID, Name, Phone Number, ZipCode>\n",
    "\n",
    "\n",
    "<Employee ID>    ✓ Correct\n",
    "\n",
    "<Phone Number>    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f743eac5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d8ea0d7",
   "metadata": {},
   "source": [
    "Composite Keys\n",
    "Which of the following statement/s about composite keys is/are correct? \n",
    "\n",
    "\n",
    "A composite key is every super key that contains more than one attribute.\n",
    "\n",
    "\n",
    "A composite key is a chosen candidate key that contains more than one attribute.    ✓ Correct\n",
    "\n",
    "A composite key is a primary key with one attribute.\n",
    "\n",
    "\n",
    "A composite key contains only the attributes necessarily required for uniquely identifying each row.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b1bad5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7cfb9b89",
   "metadata": {},
   "source": [
    "Foreign Keys\n",
    "Which of the following statement/s about foreign keys is/are correct? \n",
    "\n",
    "\n",
    "Foreign keys are the primary keys of some related tables.    ✓ Correct\n",
    "\n",
    "The values present in the foreign key column must be present in the primary key of the related table.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d04266f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c27edb4",
   "metadata": {},
   "source": [
    "Database Keys\n",
    "Consider the three tables with the following attributes: (Multiple options may be correct.)\n",
    "Table 1: <Student ID, Name, ZipCode>\n",
    "Table 2: <ZipCode, City Name, State ID>\n",
    "Table 3: <State ID, State Name>\n",
    "\n",
    "The ZIP code in table 1 is a foreign key.     ✓ Correct\n",
    "\n",
    "The State ID in table 3 is a foreign key.\n",
    "\n",
    "\n",
    "The State ID in table 2 is a foreign key.     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d55c7a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b49a9219",
   "metadata": {},
   "source": [
    "## Building a Relational Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa83a49",
   "metadata": {},
   "source": [
    "Cardinality\n",
    "Suppose two entities have a one-to-one relation. The participation of entity A is optional but that of entity B is mandatory. Which of the following statement/s is/are correct?\n",
    "\n",
    "\n",
    "The minimum cardinality of entity A is 0.     ✓ Correct\n",
    "\n",
    "The minimum cardinality of entity A is 1.\n",
    "\n",
    "\n",
    "The maximum cardinality of entity A is 1.     ✓ Correct\n",
    "\n",
    "The minimum cardinality of entity B is 1.      ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5f25f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9afcaca3",
   "metadata": {},
   "source": [
    "Foreign Keys\n",
    "State whether the following statement is true or false: \n",
    "\n",
    "A foreign key column can have null values.\n",
    "\n",
    "\n",
    "True    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2796b49a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9245d208",
   "metadata": {},
   "source": [
    "Foreign Keys\n",
    "Table A and Table B have a one-to-many relation. The primary key of Table A is the foreign key of Table B. State whether the following statement is true or false: \n",
    "\n",
    "‘All values in the foreign key column will be unique’.\n",
    "\n",
    "\n",
    "True\n",
    "\n",
    "\n",
    "False   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0bad8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72666e6e",
   "metadata": {},
   "source": [
    "Foreign Keys\n",
    "Table A and Table B have a one-to-one relation. These tables have mandatory participation. The primary key of Table A is the foreign key of Table B. State whether the following statement is true or false: \n",
    "\n",
    "‘All the values in the foreign key column will be unique’.\n",
    "\n",
    "\n",
    "True    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f4da77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "882aaf17",
   "metadata": {},
   "source": [
    "## ACID Property"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c02c8d9",
   "metadata": {},
   "source": [
    "ACID property\n",
    "The atomic property of a transaction states that either a transaction occurs completely or it does not occur at all.\n",
    "\n",
    "State whether the above statement is true or false.\n",
    "\n",
    "\n",
    "True    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a673f245",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6204c74",
   "metadata": {},
   "source": [
    "# Data Normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8267d67",
   "metadata": {},
   "source": [
    "## Anomalies in a Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1970887a",
   "metadata": {},
   "source": [
    "Anomalies\n",
    "Which of the following anomaly may occur while inserting a new data record?\n",
    "\n",
    "\n",
    "Insertion Anomaly     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c93ca7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1651ea4",
   "metadata": {},
   "source": [
    "## 1st Normal Form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8590bdcd",
   "metadata": {},
   "source": [
    "First Normal Form\n",
    "In which of the following formats are multiple values that are separated by commas in a column stored?\n",
    "\n",
    "\n",
    "List\n",
    "\n",
    "\n",
    "String    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181b9c2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c49fcfe",
   "metadata": {},
   "source": [
    "First Normal Form\n",
    "What is the result of multiple values being stored as strings in one column in a table? \n",
    "\n",
    "\n",
    "Each value stored in the field cannot be extracted easily.    ✓ Correct\n",
    "\n",
    "DBMS considers the field data to be one string value.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1a29af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ff5a6f6",
   "metadata": {},
   "source": [
    "## 2nd Normal Form\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea82d646",
   "metadata": {},
   "source": [
    "Second Normal Form\n",
    "State whether this statement is true or false:\n",
    "\n",
    "A partial functional dependency occurs when one non-prime attribute depends on another non-prime attribute. \n",
    "\n",
    "\n",
    "True\n",
    "\n",
    "\n",
    "False    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00b11aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe775ce4",
   "metadata": {},
   "source": [
    "Second Normal Form\n",
    "State whether this statement is true or false:\n",
    "\n",
    "If a table has a primary key that involves only one column, then the table has no partial functional dependencies.\n",
    "\n",
    "\n",
    "True    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7eee82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af122d6b",
   "metadata": {},
   "source": [
    "## 3rd Normal Form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b982cc",
   "metadata": {},
   "source": [
    "3rd Normal Form\n",
    "Suppose A, B, C, D and E are five attributes of an entity. A and C together form the composite key for a table. What are the conditions for the table to be in 3NF? (Multiple options may be correct.)\n",
    "\n",
    "\n",
    "B, D and E must fully functionally depend on the composite key.     ✓ Correct\n",
    "\n",
    "D may determine the value of C.     ✓ Correct\n",
    "\n",
    "D must not depend only on C.     ✓ Correct\n",
    "\n",
    "E must not depend on either B or D.     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc66bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f53f625e",
   "metadata": {},
   "source": [
    "# Graded Questions - I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cc486b",
   "metadata": {},
   "source": [
    "Q1 Degree of Relation\n",
    "Please complete the below statement. \n",
    "\n",
    "In a many-to-one relation between two tables, _____.\n",
    "\n",
    "\n",
    "One table will have a minimum cardinality of 1\n",
    "\n",
    "\n",
    "One table will have a maximum cardinality of 1    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b38a061",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20af557f",
   "metadata": {},
   "source": [
    "Q2 Functional Dependencies\n",
    "Consider an entity with three attributes as- A, B and C. The value of A can be determined using the values of B and C together.\n",
    "\n",
    "Which of the following statement is correct?\n",
    "\n",
    "\n",
    "(B, C) -> A   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0a93e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f15005e1",
   "metadata": {},
   "source": [
    "Q3 Functional Dependencies\n",
    "Here, we have a table that contains information about the professor for each course. Answer the following question based on this table.\n",
    "\n",
    "Professor ID\tSubject\tProfessor Age\n",
    "101\tMarketing\t30\n",
    "101\tProduct Management\t30\n",
    "103\tData Science\t25\n",
    "105\tData Engineering\t40\n",
    "105\tData Science\t40\n",
    "\n",
    "(Professor ID, Subject) -> Professor Age. Professor ID and Subject forms the composite key.\n",
    "\n",
    "\n",
    "There are no partial dependencies in this table.\n",
    "\n",
    "\n",
    "(Professor ID) -> Subject and (Professor ID) -> Professor Age.\n",
    "\n",
    "\n",
    "The table is not in 2NF.     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7d4a0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d74f0390",
   "metadata": {},
   "source": [
    "Q4 Functional Dependencies\n",
    "In the table of a bank database given below,  an employee can work in two departments. The number of hours that the employee has worked for in each department is given.\n",
    "\n",
    "Employee Number\tDepartment ID\tDepartment Location\tName\tJob Title\tHours per week\n",
    "A3455\tB01\t3rd plot, Punjab\tJohn\tSales Manager\t15\n",
    "A3455\tB02\t1st plot, Punjab\tJohn\tSales Manager\t10\n",
    "B2341\tB01\t3rd plot, Punjab\tKapil\tSales Manager\t7\n",
    "B2341\tB02\t1st plot, Punjab\tKapil\tSales Manager\t15\n",
    "Consider the following statements:\n",
    "\n",
    "1. Department ID -> Department Location\n",
    "\n",
    "2. (Employee Number, Department ID) -> Department Location, Name, Job Title, Hours per Week\n",
    "\n",
    "3. Employee Number -> Name, Job Title, Hours per Week\n",
    "\n",
    "4. The Hours per Week attribute has a partial dependency on the composite key.\n",
    "\n",
    "Which of the statement/s is correct?\n",
    "\n",
    "\n",
    "1, 2, 3, 4\n",
    "\n",
    "\n",
    "1, 2    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7949c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0baf2bcd",
   "metadata": {},
   "source": [
    "Q5 Degree of Relation\n",
    "A movie rental company maintains the data of its users who have signed up on its website as well as of users who have rented movies on its website as customers. It also maintains the data of all the movies that it offers on the website. The company wants to store all its information in databases. You are given the task to create an E-R diagram for their databases. Suppose you have created three entities first: Users, Customers and Movies. Which of the following statements is correct?\n",
    "\n",
    " \n",
    "\n",
    "(Multiple options may be correct.)\n",
    "\n",
    "\n",
    "The relation between the Customer table and the Movie table is many-to-many.    ✓ Correct\n",
    "\n",
    "The minimum cardinality from the Customer table to the Movie table is 1.    ✓ Correct\n",
    "\n",
    "The maximum cardinality from the Customer table to the Movie table is 1.\n",
    "\n",
    "\n",
    "The minimum cardinality from the user table to movie table is 0.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc0178a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9df7ac98",
   "metadata": {},
   "source": [
    "Q7 Degree of Relation\n",
    "Consider two entities- 'Team' and 'Project'. The relation between these two entities is such that the 'Project' entity is on the 'one' side of the relation.\n",
    "\n",
    " \n",
    "\n",
    "Which of the following statement/s is/are correct?\n",
    "\n",
    " \n",
    "\n",
    "(Multiple options may be correct.)\n",
    "\n",
    "\n",
    "One Team can manage many projects.\n",
    "\n",
    "\n",
    "One Project may be managed by many teams.     ✓ Correct\n",
    "\n",
    "One Project may be managed by only one team.     ✓ Correct\n",
    "\n",
    "One Team can manage only one project.     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc6db90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87c69578",
   "metadata": {},
   "source": [
    "Q8 Foreign Keys\n",
    "The relation between Table A and Table B is one-to-many. Table A must participate in the relation. Table B has optional participation. Which of the following statement/s is/are correct?\n",
    "\n",
    " \n",
    "\n",
    "(Multiple options may be correct.)\n",
    "\n",
    "\n",
    "If the foreign key is kept in table B, it may contain null values.    ✓ Correct\n",
    "\n",
    "If the foreign key is kept in table A, it may contain multiple values.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc02aa4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3b9dbd6",
   "metadata": {},
   "source": [
    "# Graded Questions - II"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1006c57a",
   "metadata": {},
   "source": [
    "Q9 Composite Keys\n",
    "How many tables in the ERD contain composite keys?\n",
    "\n",
    "\n",
    "0\n",
    "\n",
    "\n",
    "1\n",
    "\n",
    "\n",
    "2    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d3e5c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cdd2715d",
   "metadata": {},
   "source": [
    "Q10 Relationships\n",
    "Which of the following statement is true? \n",
    "\n",
    "\n",
    "The 'instructor_faculty' column in the 'Instructor' table is a primary key.\n",
    "\n",
    "\n",
    "A particular class can have multiple courses.\n",
    "\n",
    "\n",
    "A professor can teach one or more sections.\n",
    "\n",
    "\n",
    "None of the above     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf3a649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2bad5b2a",
   "metadata": {},
   "source": [
    "# Cloud Computing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f2c18f",
   "metadata": {},
   "source": [
    "## Introduction to Cloud Computing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651fed22",
   "metadata": {},
   "source": [
    "Traditional Data Centres vs Cloud\n",
    "Moving the company to cloud might be less beneficial if the company experiences which of the following?\n",
    "\n",
    "\n",
    "Heavy Workload\n",
    "\n",
    "\n",
    "Predictable and limited workload     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aca1bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ce7f008",
   "metadata": {},
   "source": [
    "Cloud Platforms\n",
    "Which of the following is not one of the top three existing cloud providers?\n",
    "\n",
    "\n",
    "Amazon Web Services\n",
    "\n",
    "\n",
    "IBM Cloud   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bff4d79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a035924",
   "metadata": {},
   "source": [
    "Cloud-based Applications\n",
    "State whether the following statement is True or False\n",
    "\n",
    "\" Dropbox is a cloud-based application.\"\n",
    "\n",
    "\n",
    "True   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ec1507",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb968440",
   "metadata": {},
   "source": [
    "## Benefits of Cloud Computing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4724ff97",
   "metadata": {},
   "source": [
    "Cloud Computing Benefits\n",
    "Which of the following features of cloud computing allows users to increase resource capacity when the workload increases?\n",
    "\n",
    "\n",
    "Reliability\n",
    "\n",
    "\n",
    "Scalability    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6ba66c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16a3c664",
   "metadata": {},
   "source": [
    "## Cloud-based Architecture & Deployment Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6442959",
   "metadata": {},
   "source": [
    "Cloud-based Architecture\n",
    "Which of the following is not a component of the back-end of the cloud architecture?\n",
    "\n",
    "\n",
    "Storage\n",
    "\n",
    "\n",
    "Internet    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910ed186",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6509036b",
   "metadata": {},
   "source": [
    "Deployment Models\n",
    "Let’s suppose an organisation hosts its applications on the cloud and does not want to share the underlying hardware with any other organisation. Which type of cloud deployment model best suits this situation?\n",
    "\n",
    "\n",
    "Public \n",
    "\n",
    "\n",
    "Private     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45632634",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3344b7ef",
   "metadata": {},
   "source": [
    "Hybrid Cloud\n",
    "Which of the following technology/ies is/are used to connect a private and a public cloud in order to build a hybrid cloud?\n",
    "\n",
    "\n",
    "LANs\n",
    "\n",
    "\n",
    "VPNs\n",
    "\n",
    "\n",
    "APIs\n",
    "\n",
    "\n",
    "All of the above    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db838fac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0175bac",
   "metadata": {},
   "source": [
    "Multi-Cloud Strategy\n",
    "Are hybrid cloud and multi-cloud strategy similar?\n",
    "\n",
    "\n",
    "Yes\n",
    "\n",
    "\n",
    "No     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e4b231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d496491a",
   "metadata": {},
   "source": [
    "## Types of Cloud Services"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de5b009",
   "metadata": {},
   "source": [
    "Cloud Service Models\n",
    "Which of the following options describes the cloud service model that provides a well-developed application to the user?\n",
    "\n",
    "\n",
    "IaaS\n",
    "\n",
    "\n",
    "PaaS\n",
    "\n",
    "\n",
    "SaaS    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18366cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae54fb36",
   "metadata": {},
   "source": [
    "Cloud Service Models\n",
    "Which of the following services only provides virtual infrastructure, including network, storage, machines, etc.?\n",
    "\n",
    "\n",
    "IaaS    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26b10c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e94c01c1",
   "metadata": {},
   "source": [
    "Cloud Service Models\n",
    "_______ as a service provides users with a development environment that is used for building applications.\n",
    "\n",
    "\n",
    "Platform    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e9bd89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "785366fc",
   "metadata": {},
   "source": [
    "# Virtual Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a707712",
   "metadata": {},
   "source": [
    "## Introduction to Virtualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659a2539",
   "metadata": {},
   "source": [
    "Virtual Architecture\n",
    "Select all the true statements.\n",
    "\n",
    "\n",
    "The hardware on which the virtualisation layer runs multiple operating systems -  is called a host machine.    ✓ Correct\n",
    "\n",
    "The virtual machines running on the virtualisation layer are called guest machines.    ✓ Correct\n",
    "\n",
    "The multiple machines running on the same hardware using a virtualisation layer are called virtual machines.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb417ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5930d504",
   "metadata": {},
   "source": [
    "Hypervisor\n",
    "Bare-metal and hosted hypervisors are known as type-1 and type-2 hypervisors, respectively. A Windows machine is running a Red Hat Linux operating system using Oracle VM VirtualBox.\n",
    "\n",
    " \n",
    "\n",
    "Identify whether the hypervisor is of type 1 or type 2?\n",
    "\n",
    "\n",
    "Type 1\n",
    "\n",
    "\n",
    "Type 2   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51167ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "950f4a4a",
   "metadata": {},
   "source": [
    "# Graded Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c8a4a5",
   "metadata": {},
   "source": [
    "Cloud Deployment Models\n",
    "An organisation wants to store sensitive data of its users, i.e., contact number and bank account details and is looking for services that will provide high-level security and avoid a data breach. Which deployment model should be opted by the organisation?\n",
    "\n",
    "\n",
    "Private cloud    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c31335e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47a9edea",
   "metadata": {},
   "source": [
    "Multi-Cloud Strategy\n",
    "Why do some organisations opt for the multi-cloud strategy rather than choosing a hybrid cloud?\n",
    "\n",
    "\n",
    "To eliminate the need for buying or maintaining hardware & software resources and setting up data centres.\n",
    "\n",
    "\n",
    "To avoid committing with a single cloud vendor.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd059eec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9a7bfa6",
   "metadata": {},
   "source": [
    "Cloud Service Model\n",
    "Which cloud service model has a mode in which resources are shared by multiple users but their functionalities remain the same?\n",
    "\n",
    "\n",
    "Platform as a Service\n",
    "\n",
    "\n",
    "Infrastructure as a Service\n",
    "\n",
    "\n",
    "Software as a Service   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fa6fd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "351caedd",
   "metadata": {},
   "source": [
    "Cloud Service Model\n",
    "The IT team of an organisation is planning to develop an online portal for its users. It is looking for ways to develop the portal in such a way that the cost associated with the purchase of the required hardware and software is minimal. Which cloud service model fits this scenario the best?\n",
    "\n",
    "\n",
    "Software as a Service\n",
    "\n",
    "\n",
    "Infrastructure as a Service\n",
    "\n",
    "\n",
    "Platform as a Service    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0b8949",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "409ad1bb",
   "metadata": {},
   "source": [
    "Cloud Service Models\n",
    "An organisation plans to outsource all of its email systems from on-premise to Gmail. Once it does so, only the end application Gmail is provided to the user. Which class of cloud services best describes this kind of system?\n",
    "\n",
    "\n",
    "SaaS    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfdbdba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8de03982",
   "metadata": {},
   "source": [
    "AWS\n",
    "When you enter the AWS console using the Nuvepro dashboard, what should you set as the region before launching an EMR/EC2 instance?\n",
    "\n",
    "\n",
    "US East (Ohio)\n",
    "\n",
    "\n",
    "Asia Pacific (Mumbai)\n",
    "\n",
    "\n",
    "US East (N. Virginia)     ✓ Correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f21019",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5e15180",
   "metadata": {},
   "source": [
    "AWS EMR\n",
    "State whether the following statement is true or false.\n",
    "\n",
    "\"An EMR instance can be temporarily stopped.\"\n",
    "\n",
    "\n",
    "True\n",
    "\n",
    "\n",
    "False    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b10828",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc4ad535",
   "metadata": {},
   "source": [
    "AWS EMR\n",
    "Which of the following is the port that you have to configure along with the IP that you have to use for the Master node of your EMR cluster?\n",
    "\n",
    "\n",
    "Port - 22 and IP - 0.0.0.0/0    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f09d702",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e0b81fd",
   "metadata": {},
   "source": [
    "Virtual Machine\n",
    "A Windows operating system is hosted on a Linux machine using VMware’ Identify the virtual machine OS and the hypervisor in this case.\n",
    "\n",
    "\n",
    "Windows and VMware, respectively    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b404514",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1431a7ea",
   "metadata": {},
   "source": [
    "Hypervisor\n",
    "The hypervisor is also called ______.\n",
    "\n",
    "\n",
    "A kernel\n",
    "\n",
    "\n",
    "A virtual machine monitor    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7c6e78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36f89d98",
   "metadata": {},
   "source": [
    "# Big Data and its Real Life Application\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2053d8c1",
   "metadata": {},
   "source": [
    "## Big Data and its Various Aspects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a9ab0b",
   "metadata": {},
   "source": [
    "Various Big Data Use Cases\n",
    "Which of these could be a big data use case? More than one option may be correct.\n",
    "\n",
    "\n",
    "Sales data of all orders served by a popular retail chain like Walmart in a year     ✓ Correct\n",
    "\n",
    "Details of all the employees who have ever worked at a multinational company with a strength of 5000 employees. \n",
    "\n",
    "\n",
    "Player-wise ODI statistics of all the Indian cricketers till date\n",
    "\n",
    "\n",
    "Mobile sensor data that is generated every two seconds by every active cell phone in India     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71d9982",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36997da9",
   "metadata": {},
   "source": [
    "Types of Data\n",
    "Match the following: \n",
    "\n",
    "1. Structured\tA. XML\n",
    "2. Semi-Structured\tB. Video\n",
    "3. Unstructured\tC. RDBMS Tables\n",
    "\n",
    "1-B, 2-A, 3-C\n",
    "\n",
    "\n",
    "1-C, 2-B, 3-A\n",
    "\n",
    "\n",
    "1-C, 2-A, 3-B     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eff54a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0c45f64",
   "metadata": {},
   "source": [
    "## Big Data: Major Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2cab60",
   "metadata": {},
   "source": [
    "Sources of Data\n",
    "If data is generated by a satellite, then this satellite can be categorised as which data source?\n",
    "\n",
    "\n",
    "Machine    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9eb702b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0faf702",
   "metadata": {},
   "source": [
    "Data Generated by People\n",
    "Which one of these is not an example of data generated by people?\n",
    "\n",
    "\n",
    "User ratings for a movie or product\n",
    "\n",
    "\n",
    "Facebook and Twitter posts\n",
    "\n",
    "\n",
    "Data generated by weather stations    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58710699",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3e61683",
   "metadata": {},
   "source": [
    "## Types of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e82d43",
   "metadata": {},
   "source": [
    "Structured and Semi-structured\n",
    "Pick the statement that is false. More than one option may be correct.\n",
    "\n",
    "\n",
    "Structured data can be stored in RDBMSs\n",
    "\n",
    "\n",
    "Structured data does not follow any data model     ✓ Correct\n",
    "\n",
    "Structured and semi-structured data are almost the same because both of them can be stored in relational tables     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8f74c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd6cce80",
   "metadata": {},
   "source": [
    "Email: Semi-structured data\n",
    "Pick the reason that justifies why an email is a form of semi-structured data.\n",
    "\n",
    "\n",
    "It has metadata justifying the significance of each section (to, cc, bcc, subject, etc)     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b2d733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b98e69e",
   "metadata": {},
   "source": [
    "## 4 Vs of Big Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38496b25",
   "metadata": {},
   "source": [
    "Velocity Characteristic of Big Data\n",
    "Which use case corresponds to the ‘velocity’ characteristic of big data?\n",
    "\n",
    "\n",
    "Storing data that ranges in size from TB to PB\n",
    "\n",
    "\n",
    "The source of the data is not trustworthy\n",
    "\n",
    "\n",
    "An online application processing 40,000 requests per second      ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe7ec3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d91d151",
   "metadata": {},
   "source": [
    "Identifying a Big Data Problem\n",
    "Based on the discussed Vs, try to figure out which of these is NOT a big data problem\n",
    "\n",
    "\n",
    "Capturing clickstream data on a web page\n",
    "\n",
    "\n",
    "Twitter feed for sentiment analysis\n",
    "\n",
    "\n",
    "A heap of images uploaded by Facebook users in the last one year\n",
    "\n",
    "\n",
    "None of these    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250e54c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5b670c3",
   "metadata": {},
   "source": [
    "Structured vs Unstructured\n",
    "How is structured data different from unstructured data?\n",
    "\n",
    "\n",
    "Unstructured data is only generated by machines, whereas structured data is generated by both machines and users\n",
    "\n",
    "\n",
    "Unstructured data represents around 5-10% of the total data, whereas structured data represents 80% of the entire data\n",
    "\n",
    "\n",
    "Unstructured data is not organised into a format, whereas structured data has a specific format     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cf8a9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d75bd97d",
   "metadata": {},
   "source": [
    "Identifying the Type of Data\n",
    "Match the following: \n",
    "\n",
    "JSON data\n",
    "A restaurant menu\n",
    "A newspaper article\n",
    "A website form\n",
    "       A. Structured\n",
    "\n",
    "       B. Unstructured\n",
    "\n",
    "       C. Semi-structured\n",
    "\n",
    "\n",
    "1:A, 2:A, 3:B, 4:C\n",
    "\n",
    "\n",
    "1:C, 2:A, 3:B, 4:A\n",
    "\n",
    "\n",
    "1:C, 2:A, 3:B, 4:C    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d998aad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "544fbcf1",
   "metadata": {},
   "source": [
    "# Big Data Industry Case Studies and Job Roles in Big Data Domain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58fb832",
   "metadata": {},
   "source": [
    "## Big Data: Industry Case Studies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7d213b",
   "metadata": {},
   "source": [
    "Identifying the Exact Big Data Problem\n",
    "If a dataset has a lot of issues at the data level — for instance, lots of data points in the age column are negative — then this dataset is suffering from which big data problem?\n",
    "\n",
    "\n",
    "Veracity\n",
    "\n",
    "Volatility\n",
    "\n",
    "Validity   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd59787",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68e207c3",
   "metadata": {},
   "source": [
    "## Conventional Data Processing System and Big Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980bec07",
   "metadata": {},
   "source": [
    "Real Time Processing\n",
    "Pick the use cases in which data has to be captured and processed in real time.\n",
    "\n",
    "\n",
    "Quarterly sales report publishing\n",
    "\n",
    "Seat availability during tatkal booking under the IRCTC     ✓ Correct\n",
    "\n",
    "Selecting the top-selling cell phone model of 2016\n",
    "\n",
    "Traffic updates on Google Maps     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4abfe64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "547c349e",
   "metadata": {},
   "source": [
    "Instant Messenger Data is Big Data or Not?\n",
    "Pick the reason that justifies “data generated by an instant messaging app is big data”\n",
    "\n",
    "\n",
    "The data generated is vast because almost all smartphone users use the app.\n",
    "\n",
    "Along with text messages, users can also share pictures, videos, docs, etc.\n",
    "\n",
    "The sender is given a real-time notification when the message is delivered or read by the receiver.\n",
    "\n",
    "All of these    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c596e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c1e14f8",
   "metadata": {},
   "source": [
    "Big Data Use Cases\n",
    "Pick the dataset that is difficult to store and manage using traditional systems such as RDBMSs.\n",
    "\n",
    "\n",
    "Employee details of an organisation\n",
    "\n",
    "Metadata of a dataset\n",
    "\n",
    "A bank customer’s demographic data, which includes the name, age, sex, profession, etc.\n",
    "\n",
    "User details captured during Aadhar enrollment, which include demographic and biometric data. Please note that biometric data is unstructured.     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2e15b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd40afe1",
   "metadata": {},
   "source": [
    "## Comprehension-Based Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5296f0",
   "metadata": {},
   "source": [
    "Big Data Use Case\n",
    "If this use case involves big data, choose the appropriate options that justify this.​​​​​\n",
    "\n",
    "\n",
    "It involves big data because smart meters are IoT devices, and when used by a significant population, they can generate vast volumes of data     ✓ Correct\n",
    "\n",
    "It involves big data because the meter readings are done every 15 minutes. This can lead to real-time bill generation          ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce02e36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6c5c9ab",
   "metadata": {},
   "source": [
    "Sources of Data\n",
    "Let's say that to provide customised plans, the company needs user demographic (collected during the application process)/social networking data and meter reading data (logged by smart meters). These two datasets can be categorised as which data sources respectively?\n",
    "\n",
    "\n",
    "Organisation, People\n",
    "\n",
    "Organisation, Machine\n",
    "\n",
    "People, Machine    ✓ Correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564295bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7b27ec9",
   "metadata": {},
   "source": [
    "Type of Data\n",
    "What is the type of data which is generated by Smart Meters?\n",
    "\n",
    "\n",
    "Structured\n",
    "\n",
    "Unstructured    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30baec5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "362b3cf7",
   "metadata": {},
   "source": [
    "Characteristic of Big Data\n",
    "Which characteristic cannot be associated with the problem statement?\n",
    "\n",
    "\n",
    "Volume\n",
    "\n",
    "Velocity\n",
    "\n",
    "Veracity    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e4f04f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ceb5c5e",
   "metadata": {},
   "source": [
    "Traditional vs Big Data Processing Systems\n",
    "Which quality of the data generated by all the smart meters in a major metropolitan city makes it unfit for being processed by an RDBMS?\n",
    "\n",
    "\n",
    "High volume data\n",
    "\n",
    "Velocity\n",
    "\n",
    "Unstructured\n",
    "\n",
    "All of these    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd532842",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0cb4243b",
   "metadata": {},
   "source": [
    "# Introduction to Linux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcfada4",
   "metadata": {},
   "source": [
    "## Introduction to Linux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87acf8c2",
   "metadata": {},
   "source": [
    "Operating System Basics\n",
    "Which of the following statements regarding an operating system are true?\n",
    "\n",
    "\n",
    "Windows is a type of an operating system.    ✓ Correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df9ef17",
   "metadata": {},
   "source": [
    "Linux Architecture\n",
    "Which of the following statements regarding the components of the Linux architecture are true? (Note: More than one option may be correct.)\n",
    "\n",
    "\n",
    "Different Linux distributions will have the same Linux kernel.   ✓ Correct\n",
    "\n",
    "\n",
    "The kernel is the application interface inside which the user can write commands and execute functions.\n",
    "\n",
    "\n",
    "Firefox installed on the Linux OS is an example of Shell.\n",
    "\n",
    "\n",
    "A simple text editor is an example of a Linux application.   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39a9753",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92becfc8",
   "metadata": {},
   "source": [
    "Linux Architecture\n",
    "Which of the following provides a command interpreter environment?\n",
    "\n",
    "\n",
    "Shell    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32bebdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "315b5d09",
   "metadata": {},
   "source": [
    "Linux Operating System\n",
    "Which of the following statements regarding the Linux OS is not true?\n",
    "\n",
    "\n",
    "Its source code is publicly accessible.\n",
    "\n",
    "\n",
    "In Linux, the admin access is given to the users by default.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313a4c22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9ba4304",
   "metadata": {},
   "source": [
    "## Interesting features in Linux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9978cb41",
   "metadata": {},
   "source": [
    "File System in Linux\n",
    "Which of the following statements is false?\n",
    "\n",
    "\n",
    "The root user has the highest privileges in the system.\n",
    "\n",
    "\n",
    "Service accounts increase the security of your computer.\n",
    "\n",
    "\n",
    "A root account can be deleted and disabled.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c20cee3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b13e54da",
   "metadata": {},
   "source": [
    "# Most Important Linux Commands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1d15fb",
   "metadata": {},
   "source": [
    "## Admin Commands I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1669e1a5",
   "metadata": {},
   "source": [
    "Admin Commands\n",
    "By using which of the following commands can you directly move to your parent directory?\n",
    "\n",
    "\n",
    "rmdir\n",
    "\n",
    "\n",
    "cd/\n",
    "\n",
    "\n",
    "cd\n",
    "\n",
    "\n",
    "cd..    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4275d42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "390d0f19",
   "metadata": {},
   "source": [
    "Admin Commands\n",
    "Which of the following commands can be used to remove the non-empty directory named myDirectory?\n",
    "\n",
    "\n",
    "mkdir myDirectory\n",
    "\n",
    "\n",
    "rm myDirectory\n",
    "\n",
    "\n",
    "rm -r myDirectory    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda8e753",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7cdfa19b",
   "metadata": {},
   "source": [
    "Display file contents\n",
    "Which command is used for displaying contents of a file?\n",
    "\n",
    "\n",
    "cp\n",
    "\n",
    "\n",
    "rm\n",
    "\n",
    "\n",
    "cat    ✓ Correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217fdab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3254f29a",
   "metadata": {},
   "source": [
    "Mysterious display commands\n",
    "What does cat file1 file1 file1 display?\n",
    "\n",
    "\n",
    "Content of file1 once\n",
    "\n",
    "\n",
    "Error\n",
    "\n",
    "\n",
    "Content of file1 thrice    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e974728",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41426895",
   "metadata": {},
   "source": [
    "Admin Commands\n",
    "Write a Linux command to print the contents of the directory in long format listing, showing hidden/dot files.\n",
    "\n",
    "\n",
    "Suggested Answer:\n",
    "    \n",
    "The command ls -la can be used to print the contents of the directory showing hidden files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a614fc2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6091ac57",
   "metadata": {},
   "source": [
    "Admin Commands\n",
    "Create three directories using a single Linux command and print the names of all three directories in the terminal.\n",
    "\n",
    "\n",
    "Suggested Answer:\n",
    " \n",
    "mkdir folder1 folder2 folder3 (to create 3 directories)\n",
    "\n",
    " ls (to print the names of the directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cfe2e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74e13da3",
   "metadata": {},
   "source": [
    "Admin Commands\n",
    "Create two files using the cat command and display the contents of each file in the terminal.\n",
    "\n",
    "\n",
    "Suggested Answer:\n",
    " \n",
    "\n",
    "cat >file1\n",
    "\n",
    "cat >file2\n",
    "\n",
    "cat file1 file2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2b7af9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56ae49e2",
   "metadata": {},
   "source": [
    "## Admin Commands II\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49b94e8",
   "metadata": {},
   "source": [
    "Admin Commands\n",
    "Suppose you are given a file containing the numerical data 1 2 8 7 6. Which of the following commands will you use to arrange the numerical data in the file as 8 7 6 2 1?\n",
    "\n",
    "\n",
    "sort\n",
    "\n",
    "\n",
    "sort -n filename\n",
    "\n",
    "\n",
    "sort -r filename\n",
    "\n",
    "\n",
    "sort -nr filename    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f821809e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "175e558f",
   "metadata": {},
   "source": [
    "Admin Commands\n",
    "Suppose you are given a string of characters and a file. Which of the following commands can you use to print the count of the number of lines in a file that contains the string?\n",
    "\n",
    "\n",
    "find\n",
    "\n",
    "\n",
    "grep\n",
    "\n",
    "\n",
    "grep -c “string” filename    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe859ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1dbe2ed7",
   "metadata": {},
   "source": [
    "Admin Commands\n",
    "Using a Linux command, find the number of occurrences of the word ‘linux’ in a file named file.txt.\n",
    "\n",
    " \n",
    "Suggested Answer:\n",
    "    \n",
    "grep -c “linux” file.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920c8899",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6e694d8",
   "metadata": {},
   "source": [
    "Admin Commands\n",
    "Write a command to replace the word ‘bad’ with ‘good’ in a file named file.txt.\n",
    "\n",
    " \n",
    "Suggested Answer:\n",
    "    \n",
    "sed s/bad/good/ < file.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0208cab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31622d6a",
   "metadata": {},
   "source": [
    "## Admin Commands III"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d1a464",
   "metadata": {},
   "source": [
    "Admin Commands\n",
    "Suppose you are given two files containing some text. Which of the following commands can you use to find the differences between both the files?\n",
    "\n",
    "\n",
    "AWK\n",
    "\n",
    "\n",
    "chown\n",
    "\n",
    "\n",
    "chmod\n",
    "\n",
    "\n",
    "diff   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482bc3a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d107da7d",
   "metadata": {},
   "source": [
    "Admin Commands\n",
    "You are given a file called info.txt which contains the information about the mobile number of various employees. Write a command that prints all the lines in info.txt which contains the word 'person'.\n",
    "\n",
    "\n",
    "Suggested Answer:\n",
    "    \n",
    "awk '/person/ {print}' info.txt\n",
    "\n",
    " The awk command prints all the line which matches with the ‘person’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76d499b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e81285b7",
   "metadata": {},
   "source": [
    "Admin Commands\n",
    "You are given  a file called myFile.txt. Write a command which gives read, write and execute permission to the file’s owner, read permissions to the file’s group and no permissions to all other users. \n",
    "\n",
    "\n",
    "Suggested Answer:\n",
    "    \n",
    "chmod u=rwx,g=r,o= filename\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bb5009",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2266335",
   "metadata": {},
   "source": [
    "## Networking Commands I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b8aff3",
   "metadata": {},
   "source": [
    "Networking Commands\n",
    "What is the correct syntax to ping abcd.com website in command prompt?\n",
    "\n",
    "\n",
    "Ping www.abcd.com\n",
    "\n",
    "\n",
    "ping www.abcd.com    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa06e69a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b18fb52",
   "metadata": {},
   "source": [
    "Networking Commands\n",
    "Which of the following commands is used to view and change the configurations of the network interfaces on the system?\n",
    "\n",
    "\n",
    "ssh-keygen\n",
    "\n",
    "\n",
    "ifconfig    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0b0d17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "879c9989",
   "metadata": {},
   "source": [
    "Networking Commands\n",
    "Which of these commands is used to generate a public or private authentication key pair which allows the user to connect to a remote system without any use of password.\n",
    "\n",
    "\n",
    "ping\n",
    "\n",
    "\n",
    "ifconfig\n",
    "\n",
    "\n",
    "ip\n",
    "\n",
    "\n",
    "ssh-keygen    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8de61e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d82524a",
   "metadata": {},
   "source": [
    "## Networking Commands II"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1bb21d",
   "metadata": {},
   "source": [
    "Networking Commands\n",
    "Which command is used to measure the time taken by the packets to return from a specific destination sent to check connection?\n",
    "\n",
    "\n",
    "nslookup\n",
    "\n",
    "\n",
    "traceroute\n",
    "\n",
    "\n",
    "ping    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfa69f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d55e5355",
   "metadata": {},
   "source": [
    "Networking Commands\n",
    "Which of the following commands is generally used to resolve the IP address to its MAC (Media Access Control) address?\n",
    "\n",
    "\n",
    "netstat\n",
    "\n",
    "\n",
    "nslookup\n",
    "\n",
    "\n",
    "traceroute\n",
    "\n",
    "\n",
    "arp    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba3d070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b7dfd4a",
   "metadata": {},
   "source": [
    "Networking Commands\n",
    "If you wish to identify what path a certain packet follows from your system to a particular IP address, which of these commands can you use?\n",
    "\n",
    "\n",
    "ifconfig\n",
    "\n",
    "\n",
    "ping\n",
    "\n",
    "\n",
    "ip\n",
    "\n",
    "\n",
    "traceroute    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f7212d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aff5d4bf",
   "metadata": {},
   "source": [
    "# Some more Linux Commands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b04a99b",
   "metadata": {},
   "source": [
    "## Admin Commands I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5329cea6",
   "metadata": {},
   "source": [
    "Admin Commands\n",
    "Which command can you use to translate all the uppercase letters in your file to lowercase letters?\n",
    "\n",
    "\n",
    "cut\n",
    "\n",
    "\n",
    "uniq\n",
    "\n",
    "\n",
    "tr    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e576f168",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0e43942",
   "metadata": {},
   "source": [
    "Admin Commands\n",
    "Which of the following commands is used to delete all the repeated lines that exist in an input file?\n",
    "\n",
    "\n",
    "touch\n",
    "\n",
    "\n",
    "grep\n",
    "\n",
    "\n",
    "uniq    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73268b3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a844bf1d",
   "metadata": {},
   "source": [
    "Admin Commands\n",
    "Which of these commands tells you which files are opened by which process?\n",
    "\n",
    "\n",
    "ls\n",
    "\n",
    "\n",
    "mv\n",
    "\n",
    "\n",
    "lsof   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49ea289",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9abdfdd1",
   "metadata": {},
   "source": [
    "Admin Commands\n",
    "You are given a file college myFile.txt containing lowercase letters. Convert all the lowercase letters to uppercase and display the contents of the file.\n",
    "\n",
    "\n",
    "Suggested Answer:\n",
    " \n",
    "\n",
    "$cat greekfile | tr “[a-z]” “[A-Z]”\n",
    "\n",
    "or $cat geekfile | tr “[:lower:]” “[:upper:]”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350529ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9123f6a0",
   "metadata": {},
   "source": [
    "Admin Commands\n",
    "Suppose there is a user called user1 in your system. Write a command to find his user ID.\n",
    "\n",
    "\n",
    "Suggested Answer:\n",
    "    \n",
    " \n",
    "\n",
    " id -u user1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d9696d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63ab76a9",
   "metadata": {},
   "source": [
    "## Admin Commands II"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a05b82b",
   "metadata": {},
   "source": [
    "Admin Commands\n",
    "Which of the following commands can be used to display all the running processes for a certain period of time?\n",
    "\n",
    "\n",
    "ps\n",
    "\n",
    "\n",
    "top    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1c7b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "573e540f",
   "metadata": {},
   "source": [
    "Admin Commands\n",
    "You are given two integers a and b. Which of the following commands can be used to design a simple calculator?\n",
    "\n",
    "\n",
    "wc\n",
    "\n",
    "\n",
    "expr   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f258f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33a317b4",
   "metadata": {},
   "source": [
    "Admin Commands\n",
    "Which of the following is used to display the username of the current logged in user on the system?\n",
    "\n",
    "\n",
    "more\n",
    "\n",
    "\n",
    "wc\n",
    "\n",
    "\n",
    "df\n",
    "\n",
    "\n",
    "whoami    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dd2b01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dcba1676",
   "metadata": {},
   "source": [
    "Admin Commands\n",
    "Write a command to find out the disk usage summary of a /home/upGrad directory tree and each of its sub directories.\n",
    "\n",
    "\n",
    "Suggested Answer:\n",
    " \n",
    "\n",
    "du /home/upGrad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7952f5e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a25e3ff5",
   "metadata": {},
   "source": [
    "Admin Commands\n",
    "Write a command to display all the running processes in the system.\n",
    "\n",
    "\n",
    "Suggested Answer:\n",
    "    \n",
    "ps -A \n",
    "\n",
    "or\n",
    "\n",
    "ps -e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eede37a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2dfd0ccf",
   "metadata": {},
   "source": [
    "## Admin Commands III"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0b123f",
   "metadata": {},
   "source": [
    "Admin Commands\n",
    "Which of the following commands is used to keep the process running even if the user has exited the shell?\n",
    "\n",
    "\n",
    "kill\n",
    "\n",
    "\n",
    "su\n",
    "\n",
    "\n",
    "nohup   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2e3ead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3ece759",
   "metadata": {},
   "source": [
    "Admin Commands\n",
    "Suppose there is a process called process1, which is running on your system. Write a command to terminate the process manually.\n",
    "\n",
    "\n",
    "Suggested Answer:\n",
    "    \n",
    "ps \n",
    "\n",
    "kill PID\n",
    "\n",
    "The ‘ps’ command will display all the processes along with their process IDs. You can then use the process ID of process1 along with the kill command to terminate the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb0d5fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b53c1141",
   "metadata": {},
   "source": [
    "# Introduction to Shell and BASH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb431dc3",
   "metadata": {},
   "source": [
    "## Shell and BASH\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09284b87",
   "metadata": {},
   "source": [
    "Shell Script\n",
    "What is a shell script?\n",
    "\n",
    "\n",
    "It is a group of functions\n",
    "\n",
    "\n",
    "It is a group of commands\n",
    "\n",
    "\n",
    "It is a file containing special symbols\n",
    "\n",
    "\n",
    "It is a file containing a series of commands     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00330e9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0fe2a222",
   "metadata": {},
   "source": [
    "Shell and BASH\n",
    "Where do you type the commands on Linux OS?\n",
    "\n",
    "\n",
    "Kernel\n",
    "\n",
    "\n",
    "Terminal    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff955c21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc8e26d1",
   "metadata": {},
   "source": [
    "Components of Shell Script\n",
    "Which of the following words can be classified as a control flow keyword?\n",
    "\n",
    "\n",
    "pwd\n",
    "\n",
    "\n",
    "mkdir\n",
    "\n",
    "\n",
    "if-else   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0ba4b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6372166a",
   "metadata": {},
   "source": [
    "Shell\n",
    "Which of the following is an example of a shell keyword?\n",
    "\n",
    "\n",
    "whoami\n",
    "\n",
    "\n",
    "echo\n",
    "\n",
    "\n",
    "rm\n",
    "\n",
    "\n",
    "if    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb989ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a81f033a",
   "metadata": {},
   "source": [
    "Shell\n",
    "Which of the following is/are examples of Shell commands?\n",
    "\n",
    "\n",
    "cd     ✓ Correct\n",
    "\n",
    "traceroute     ✓ Correct\n",
    "\n",
    "while\n",
    "\n",
    "ifconfig     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0d1e68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ee47d88",
   "metadata": {},
   "source": [
    "Shell and BASH\n",
    "Which of the following is false?\n",
    "\n",
    "\n",
    "Programmers do not need to switch to different syntaxes while writing the shell scripts.\n",
    "\n",
    "\n",
    "Shell scripts are not prone to costly errors.     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513e0aed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a012fc95",
   "metadata": {},
   "source": [
    "Shell and BASH\n",
    "Which of the following advantages are offered by Shell Scripts?\n",
    "\n",
    "\n",
    "Automating the code compiling process.   ✓ Correct\n",
    "\n",
    "Backing up system data regularly   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4994f82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "706468ca",
   "metadata": {},
   "source": [
    "## First BASH Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0aabcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "First Shell Script\n",
    "Open your terminal and create your first shell script which prints your name and lists out all the files and directories. Write the script here.\n",
    "\n",
    "\n",
    "Suggested Answer:\n",
    "    \n",
    "echo \"Your Name\"\n",
    "\n",
    "echo \"Below is the list of all the files and directories: \"\n",
    "\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd50005",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07deeacf",
   "metadata": {},
   "source": [
    "Print your name\n",
    "Description\n",
    "Create a small script which prints the name \"Ash\" on the console.\n",
    "\n",
    "ans:\n",
    "#Read the variable from STDIN\n",
    "read a\n",
    "\n",
    "#Output the variable to STDOUT\n",
    "echo 'ASH'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263ed29a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "810fa3f8",
   "metadata": {},
   "source": [
    "Hello World!\n",
    "Description\n",
    "Create a small script which says \"Hello World!\" on the console.\n",
    "\n",
    "ans:\n",
    "#Read the variable from STDIN\n",
    "read a\n",
    "\n",
    "#Output the variable to STDOUT\n",
    "echo 'Hello World!'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4af54e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd79d019",
   "metadata": {},
   "source": [
    "# Variables and Operators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3686e094",
   "metadata": {},
   "source": [
    "## Introduction to Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae43dac",
   "metadata": {},
   "source": [
    "Variables\n",
    "Which of the following are valid variable names? (More than one option can be correct.)\n",
    "\n",
    "\n",
    "MYFILE2    ✓ Correct\n",
    "\n",
    "MY-FILE\n",
    "\n",
    "\n",
    "MY_FILE    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a71edd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51a0e5f1",
   "metadata": {},
   "source": [
    "Variables\n",
    "Which of the following values cannot be assigned to a variable?\n",
    "\n",
    "\n",
    "“HELLO WORLD”\n",
    "\n",
    "\n",
    "12345\n",
    "\n",
    "\n",
    "“hello world”\n",
    "\n",
    "\n",
    "HELLO WORLD   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e931ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f0813cf",
   "metadata": {},
   "source": [
    "## Initialising and Accessing the Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1089158b",
   "metadata": {},
   "source": [
    "Variable Initilisation\n",
    "Which of the following is a correct way of initialising the variable?\n",
    "\n",
    "\n",
    "VAR$=“MY NAME”\n",
    "\n",
    "\n",
    "VAR=MY NAME\n",
    "\n",
    "\n",
    "VAR=12345    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e702617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "672d0e85",
   "metadata": {},
   "source": [
    "Accessing Variables\n",
    "Which of the following commands is used to access the value of a variable?\n",
    "\n",
    "\n",
    "ECHO\n",
    "\n",
    "\n",
    "Echo\n",
    "\n",
    "\n",
    "echo    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8924a4be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2bd61b7",
   "metadata": {},
   "source": [
    "Print the name of the city\n",
    "Description\n",
    "Create a new variable, assign it the value of the city \"Bombay\" and print it on the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1820854",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans:\n",
    "\n",
    "#!/bin/sh\n",
    "\n",
    "CITY=\"Bombay\"\n",
    "echo $CITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855c7912",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7bde10eb",
   "metadata": {},
   "source": [
    "Print name of music genres\n",
    "Description\n",
    "Create two variables, assign them the value \"rock music\" and \"jazz music\" and print them both on the console separated by a comma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f6666d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans:\n",
    "\n",
    "#!/bin/sh\n",
    "\n",
    "MUSIC1=\"rock music\"\n",
    "MUSIC2=\"jazz music\"\n",
    "echo $MUSIC1, $MUSIC2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd4c8bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "202e0e54",
   "metadata": {},
   "source": [
    "## Arithmetic Operators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697566aa",
   "metadata": {},
   "source": [
    "Calculate the savings\n",
    "Description\n",
    "Declare two variables \"income\" and \"expenditure\". The weekly income via my freelancing job is Rs 1000 and I spent Rs 700 from that. Perform arithmetic operation on these two variables after assigning them the values of income & expenditure and print the amount saved.\n",
    "\n",
    "\n",
    "#Read the variable from STDIN\n",
    "read a\n",
    "\n",
    "#!/bin/bash\n",
    "income=1000\n",
    "expenditure=700\n",
    "ans=$(( income - expenditure ))\n",
    "echo $ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9055e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5a63d0c",
   "metadata": {},
   "source": [
    "Arithmetic Operators\n",
    "What will be the output of the following?\n",
    "\n",
    "#!/bin/bash\n",
    "NUM1 = 5\n",
    "NUM2 = 5\n",
    "NUM3 = 11\n",
    "ANS = $((NUM1 + NUM2) * (NUM3/NUM1))\n",
    "echo $ANS\n",
    "\n",
    "20    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3dd3ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "023f4185",
   "metadata": {},
   "source": [
    "Arithmetic Operators\n",
    "In the code below, what will be the value of the remainder variable?\n",
    "\n",
    "#!/bin/bash\n",
    "NUMBER = 11\n",
    "DIVIDE_BYNUM = 5\n",
    "remainder = $((NUMBER % DIVIDE_BYNUM))\n",
    "echo \"Module operation of $NUMBER % $DIVIDE_BYNUM is $remainder\"\n",
    " \n",
    "\n",
    "0\n",
    "\n",
    "\n",
    "1     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14fd28c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "094c6766",
   "metadata": {},
   "source": [
    "Arithmetic Operators\n",
    "Description\n",
    "Take an integer as an input from the user and write a script to print the value of input_number+1 without using extra variables and an addition operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79d6e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans:\n",
    "#Enter your code here. Read input from STDIN. Print output to STDOUT\n",
    " #!/bin/bash\n",
    "read NUMBER\n",
    "((NUMBER++))\n",
    "echo $NUMBER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd13b79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6429a5dc",
   "metadata": {},
   "source": [
    "Rectangle or Square\n",
    "Description\n",
    "Write a program to take the values of length and breadth from the user and print whether the quadrilateral is a rectangle or a square. (You can assume that all angles in the quadrilateral are right angles.)\n",
    "\n",
    "\n",
    "\n",
    "Input format:\n",
    "\n",
    "First line of input contains the value of length.\n",
    "second line of input contains the value of breadth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281a6ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans:\n",
    "\n",
    "#Enter your code here. Read input from STDIN. Print output to STDOUT\n",
    "#!/bin/bash\n",
    "\n",
    "read length\n",
    "read breadth\n",
    "if [ $length -eq $breadth ]\n",
    "then\n",
    "   echo \"The quadrilateral is a square\"\n",
    "else\n",
    "   echo \"The quadrilateral is a rectangle\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94a9345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e92d1d55",
   "metadata": {},
   "source": [
    "## Relational and Logical Operators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cde5a59",
   "metadata": {},
   "source": [
    "Relational Operators\n",
    " \n",
    "\n",
    "Which of the following relational operators is used to check if the value of the left operand is less than the value of the right one?\n",
    "\n",
    "\n",
    "-ne\n",
    "\n",
    "\n",
    "-gt\n",
    "\n",
    "\n",
    "-lt   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdff4d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3345fb0",
   "metadata": {},
   "source": [
    "Relational and Logical Operators\n",
    " \n",
    "\n",
    "Let’s say a football game is being played between Germany and Italy, and you have placed a bet with your friend. The one who loses has to wear the jersey of the team that the other one is supporting. You win the bet if either 1 or 2 happens.\n",
    "\n",
    "1) At least one of the strikers (A & B) scores more than 2 goals\n",
    "\n",
    "2) Both (A and B) score a goal each\n",
    "\n",
    "Which of the following expressions should evaluate to true for you to win?\n",
    "\n",
    "\n",
    "(A goals -gt 2 -o B goals -gt 2) -o (A goal -eq 1 -a B goal -eq 1)   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0db6be9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72787eed",
   "metadata": {},
   "source": [
    "Greater than or equal to (or not?)\n",
    "Description\n",
    "Create two variables a and b, assign value of 3 to a and 4 to b. Compare both of them via ge and print a is is greater than or equal to the b or not. The print statement should look like: \"a is not greater or equal to b\" or \"a is greater or equal to b\"\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e66753",
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "ans:\n",
    "\n",
    "#Read the variable from STDIN\n",
    "read a\n",
    "\n",
    "#Output the variable to STDOUT\n",
    "echo $a\n",
    "#!/bin/sh\n",
    "\n",
    "a=3\n",
    "b=4\n",
    "\n",
    "if [ $a -ge $b ]\n",
    "then\n",
    "   echo \"a is greater or  equal to b\"\n",
    "else\n",
    "   echo \"a is not greater or equal to b\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a391823",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05d6e4c6",
   "metadata": {},
   "source": [
    "Even-Odd\n",
    "Description\n",
    "Write a short program which takes in a number from user-input and tells them if the number is even or odd. If even, print \"\"is an Even Number\" and if odd, print \"is an Odd Number\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d725705",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env bash\n",
    "read n\n",
    "if [ $((n % 2)) -eq 0 ]; then\n",
    "\techo \"is an Even Number\"\n",
    "else\n",
    "\techo \"is an Odd Number\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d359e087",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9be08c27",
   "metadata": {},
   "source": [
    "## File Operators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d21fba",
   "metadata": {},
   "source": [
    "File Operators\n",
    "Which of the following file operators is used to check if the file has write access or not?\n",
    "\n",
    "\n",
    "-e\n",
    "\n",
    "\n",
    "-d\n",
    "\n",
    "\n",
    "-w     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfd9cbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f05cb4a",
   "metadata": {},
   "source": [
    "File Operators\n",
    "What is the function of the -s operator?\n",
    "\n",
    "\n",
    "It is used to check if the given file is character special.\n",
    "\n",
    "\n",
    "It is used to check if the given file is block special.\n",
    "\n",
    "\n",
    "It is used to check if the given file has read access or not.\n",
    "\n",
    "\n",
    "It is used to check the size of a given file.    ✓ Correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef04130",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23c16d40",
   "metadata": {},
   "source": [
    "# Conditionals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde2ba28",
   "metadata": {},
   "source": [
    "## Conditional Statements, If and If Else"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8e79f0",
   "metadata": {},
   "source": [
    "If and If Else\n",
    " \n",
    "\n",
    "Which of the following conditional statements will be the most relevant and precise to use if you want to check if the current date is less than 20 and print 1 if it is and 0 otherwise.\n",
    "\n",
    "\n",
    "if\n",
    "\n",
    "\n",
    "else\n",
    "\n",
    "\n",
    "if else     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3539ed13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91b1289f",
   "metadata": {},
   "source": [
    "If and If Else\n",
    "Which of the following statements is false regarding the ‘If Else’ statement?\n",
    "\n",
    "\n",
    "It is used where only one of the two code blocks needs to be executed at any given point of time.\n",
    "\n",
    "\n",
    "It is a conditional statement.\n",
    "\n",
    "\n",
    "One of the conditions and actions is mentioned in the If block.\n",
    "\n",
    "\n",
    "It can be used in cases where only one code block needs to be executed at any time.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3a32b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53fad973",
   "metadata": {},
   "source": [
    "If and If Else\n",
    "Description\n",
    "Write a script to ask the user to enter a password and store it in a variable called pass. If the password entered by the user matches with the predefined password, which is ‘password’, then the output will be “The password entered is correct” and if the entered password is wrong, then the output will be “The password entered is incorrect”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3214c685",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans:\n",
    "\n",
    "#Enter your code here. Read input from STDIN. Print output to \n",
    "read pass\n",
    "correct_pass=\"password\"\n",
    "if [ $pass == $correct_pass ]\n",
    "then\n",
    "   echo \"The password entered is correct\"\n",
    "else\n",
    "   echo \"The password entered is incorrect\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74206aff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7c08c5e",
   "metadata": {},
   "source": [
    "Single digit number\n",
    "Description\n",
    "Write a program which takes in a user input and calculates whether that number is single digit or not. Use user-input and if else to do this. Based on the number being single digit or not, print \"Not a single digit number\" or \"Single digit number\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbcf184",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans:\n",
    "#!/bin/sh \n",
    "read count\n",
    "if [ \"$count\" -gt 9 ]; then\n",
    "  echo \"Not a single digit number\";\n",
    "else\n",
    "\techo \"Single digit number\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba012de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d036c81",
   "metadata": {},
   "source": [
    "## Else If\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e55d00",
   "metadata": {},
   "source": [
    "Else If\n",
    "Description\n",
    "Write a script to check if a number is odd, even or zero?\n",
    "\n",
    "Note: Number entered should be a non-negative integer.\n",
    "\n",
    "\n",
    "\n",
    "Input Format:\n",
    "\n",
    "The first line of input contains the number that needs to be checked\n",
    "Output Format:\n",
    "\n",
    " Prints if the number entered is even/odd/zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a61946a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans:\n",
    "read num\n",
    "if [ $num == 0 ]\n",
    "then\n",
    "  echo \"number entered is zero\"\n",
    "elif [  $((num%2)) -eq 0 ]\n",
    "then\n",
    "  echo \"number entered is even\"\n",
    "else\n",
    "  echo \"number entered is odd\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c68aa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37548687",
   "metadata": {},
   "source": [
    "Grade of a Student\n",
    "Description\n",
    "Write a bash script to print a student’s grade based on his marks. You will take the student’s name and marks as input and determine the grade based on the following:\n",
    "\n",
    " \n",
    "\n",
    "Marks | Grade\n",
    "\n",
    ">100 | A\n",
    "\n",
    ">80 & <=100 | B\n",
    "\n",
    ">40 & <=80 | C\n",
    "\n",
    "<=40 | D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2721f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans:\n",
    "\n",
    "read name\n",
    "read marks\n",
    "if [ $marks -gt 100 ]\n",
    "then\n",
    "  echo \"The grade of student named $name is A\"\n",
    "elif [ $marks -gt 80 -a $marks -le 100 ]\n",
    "then\n",
    "  echo \"The grade of student named $name is B\"\n",
    "elif [ $marks -gt 40 -a $marks -le 80 ]\n",
    "then\n",
    "  echo \"The grade of student named $name is C\"\n",
    "else\n",
    "  echo \"The grade of student named $name is D\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ae4c25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43905d6f",
   "metadata": {},
   "source": [
    "## Nested If Else"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85468c4",
   "metadata": {},
   "source": [
    "Smallest Number\n",
    "Description\n",
    "Write a script to determine the smallest number out of the three numbers entered by the user. You can take in some numbers as input and calculate the smallest out of them. Print the smallest number as \n",
    "\n",
    "The smallest number entered is <smallest calculated number>.\n",
    "\n",
    "\n",
    "\n",
    "Input Format:\n",
    "\n",
    "The first line of input contains the first number. \n",
    "The second line of input contains the second number. \n",
    "The third line of input contains the third number. \n",
    "Output Format:\n",
    "\n",
    " The output prints the smallest element out of the three input elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90350306",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans:\n",
    "    \n",
    "\n",
    "read a\n",
    "read b\n",
    "read c\n",
    "if [ $a -lt $b ]\n",
    "then\n",
    "  if [ $a -lt $c ]\n",
    "  then \n",
    "      echo \"The smallest number entered is $a\"\n",
    "  fi\n",
    "elif [ $b -lt $a ]\n",
    "then\n",
    "  if [ $b -lt $c ]\n",
    "  then \n",
    "      echo \"The smallest number entered is $b\"\n",
    "  fi\n",
    "else\n",
    "  echo \"The smallest number entered is $c\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce22c8c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf4bf4f2",
   "metadata": {},
   "source": [
    "## Switch Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9210779",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "707be619",
   "metadata": {},
   "source": [
    "Switch Case\n",
    " \n",
    "\n",
    "You have to create a sorting hat program. A student will be asked to enter a random number, based on which they will be allotted a house. The allotment is as follows:\n",
    "\n",
    "1- Hufflepuff\n",
    "\n",
    "2- Gryffindor\n",
    "\n",
    "3- Slytherin\n",
    "\n",
    "4- Ravenclaw\n",
    "\n",
    "Which of the following will be the preferred method to define a student’s grade?\n",
    "\n",
    "\n",
    "Nested If-Else statements\n",
    "\n",
    "\n",
    "Switch case statements   ✓ Correct\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801434c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9275221b",
   "metadata": {},
   "source": [
    "Switch Case\n",
    "Which of the following is true about the Switch case? (More than one option can be correct)\n",
    "\n",
    "\n",
    "A ;; command is used to break out of the entire script.\n",
    "\n",
    "\n",
    "If none of the cases is met, the default statement is used.     ✓ Correct\n",
    "\n",
    "If ;; command is not used between cases, then the switch statement will execute other cases also or it might give a compile error.     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2618091d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c19f2992",
   "metadata": {},
   "source": [
    "## Practice Questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2a1359",
   "metadata": {},
   "source": [
    "Eligibility for Drinking\n",
    "Description\n",
    "Write a program to check eligibility to drink based on the age entered. (Assume the legal drinking age as 21 years.)\n",
    "\n",
    "If the person is eligible, print “You are eligible to consume alcohol”. \n",
    "\n",
    "If the person is not eligible, print “You are not eligible to consume alcohol”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd402a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans:\n",
    "    \n",
    "#Enter your code here. Read input from STDIN. Print output to STDOUT\n",
    "#!/bin/bash\n",
    "read age\n",
    "if [ $age -ge 21 ]\n",
    "then\n",
    "   echo \"You are eligible to consume alcohol\"\n",
    "else\n",
    "   echo \"You are not eligible to consume alcohol\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e0cf0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a0152ac",
   "metadata": {},
   "source": [
    "Rectangle or Square\n",
    "Description\n",
    "Write a program to take the values of length and breadth from the user and print whether the quadrilateral is a rectangle or a square. (You can assume that all angles in the quadrilateral are right angles.)\n",
    "\n",
    "\n",
    "\n",
    "Input format:\n",
    "\n",
    "First line of input contains the value of length.\n",
    "second line of input contains the value of breadth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bea8123",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans:\n",
    "    \n",
    "    \n",
    "#Enter your code here. Read input from STDIN. Print output to STDOUT\n",
    "#!/bin/bash\n",
    "read length\n",
    "read breadth\n",
    "if [ $length -eq $breadth ]\n",
    "then\n",
    "   echo \"The quadrilateral is a square\"\n",
    "else\n",
    "   echo \"The quadrilateral is a rectangle\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c04ee0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94c376fb",
   "metadata": {},
   "source": [
    "Casting a Vote\n",
    "Description\n",
    "Write a program for a person to cast a vote against three possible candidates.\n",
    "\n",
    "The code should first check if the person’s age is above or equal to 18 and print “You are not eligible” if the person is less than 18. \n",
    "\n",
    "There are three possible candidates:\n",
    "\n",
    "Ram\n",
    "Shyam\n",
    "Ghanshyam\n",
    "\n",
    "\n",
    "You should take the number as input and display “You have voted for <name>”.\n",
    "\n",
    "\n",
    "\n",
    "The first line of input will contain the person’s age, and the second line would contain a number which represents the candidate a person wants to vote for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25cd62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans:\n",
    "    \n",
    "#Enter your code here. Read input from STDIN. Print output to STDOUT\n",
    "#!/bin/bash\n",
    "read age\n",
    "if [ $age -lt 18 ]\n",
    "then\n",
    "  echo \"You are not eligible\"\n",
    "else\n",
    "  #reading serial number of candidate\n",
    "  read num\n",
    "fi\n",
    " \n",
    "case $num in\n",
    " \n",
    "  1)\n",
    "  echo \"You have voted for Ram\"\n",
    "  ;;\n",
    "  2)\n",
    "  echo \"You have voted for Shyam\"\n",
    "  ;;\n",
    "  3)\n",
    "  echo \"You have voted for Ghanshyam\"\n",
    "  ;;\n",
    "esac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66a316a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e85df776",
   "metadata": {},
   "source": [
    "## Understanding Loops - For Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cee0850",
   "metadata": {},
   "source": [
    "For Loop\n",
    "#!/bin/bash\n",
    "for value in {10..0..2}\n",
    "do\n",
    "echo $value\n",
    "done\n",
    "How many times will the For loop run in the above code?\n",
    "\n",
    "\n",
    "10\n",
    "\n",
    "\n",
    "2\n",
    "\n",
    "\n",
    "5\n",
    "\n",
    "\n",
    "6    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954a3587",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e59c1ec9",
   "metadata": {},
   "source": [
    "Reverse Order\n",
    "Description\n",
    "Write a bash script to Print first n integers in the reverse order (ending at 0) using the For loop.\n",
    "\n",
    "Note: n should be non negative integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d5af13",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans:\n",
    "    \n",
    "#Enter your code here. Read input from STDIN. Print output to STDOUT\n",
    "read n\n",
    "for((i=$n;i>=0;i--))\n",
    "do\n",
    "    echo $i\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b4c06d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51c84732",
   "metadata": {},
   "source": [
    "## While Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0401072c",
   "metadata": {},
   "source": [
    "While Loop\n",
    "#!/bin/bash\n",
    "a=0\n",
    "while [$a -lt 10]\n",
    "do\n",
    "\techo $a\n",
    "\ta=`expr $a + 1`\n",
    "done\n",
    "How many times will the while loop run in the above code?\n",
    "\n",
    "\n",
    "7\n",
    "\n",
    "\n",
    "10     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519e6c0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "779ba95d",
   "metadata": {},
   "source": [
    "Print Odd Numbers\n",
    "Description\n",
    "Write a bash script that prints all the odd numbers from 1 to 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4484cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans:\n",
    "    \n",
    "#Enter your code here. Read input from STDIN. Print output to STDOUT\n",
    "#!/bin/bash\n",
    "a=1\n",
    "while [ $a -le 15 ]\n",
    "do\n",
    "  echo $a\n",
    "  ((a=a+2))\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858bb278",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92746349",
   "metadata": {},
   "source": [
    "N multiples of a number\n",
    "Description\n",
    "Write a bash script to print n multiples of x, where n and x are integers entered by the user.\n",
    "\n",
    "\n",
    "\n",
    "The first line of input will contain x and the second line will have n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b88d769",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans:\n",
    "    \n",
    "#Enter your code here. Read input from STDIN. Print output to STDOUT\n",
    "read x\n",
    "read n\n",
    "a=1\n",
    "while [ $a -le $n ]\n",
    "do\n",
    "  c=$((x*a))\n",
    "  echo $c\n",
    "  ((a=a+1))\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d775f2d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58570fb0",
   "metadata": {},
   "source": [
    "## Until Loops\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f83cd83",
   "metadata": {},
   "source": [
    "Print N integers\n",
    "Description\n",
    "Write a bash script to Print first n integers starting from 1 using the Until loop.\n",
    "\n",
    "Note: n should be a positive integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5a353e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans:\n",
    "    \n",
    "#Enter your code here. Read input from STDIN. Print output to STDOUT\n",
    "read n\n",
    "a=1\n",
    "until [ ! $a -le $n ]\n",
    "do\n",
    "   echo $a\n",
    "   ((a++))\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a0c576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2b152f3",
   "metadata": {},
   "source": [
    "Count the Numbers\n",
    "Description\n",
    "Take two numbers n and x as an input from the user and write a bash script to count the number of integers starting from 1 that are less than or equal to n and are divisible by x using Until loop.\n",
    "\n",
    "Note: n and x are positive integers.\n",
    "\n",
    "\n",
    "\n",
    "Input Format:\n",
    "\n",
    "The first line of input will contain n.\n",
    "The second line represents the number x.\n",
    "Output Format:\n",
    "\n",
    " The first line prints the count of all the elements satisfying the conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032942f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans:\n",
    "    \n",
    "\n",
    "    #Enter your code here. Read input from STDIN. Print output to STDOUT\n",
    "read n\n",
    "read x\n",
    "a=1\n",
    "count=0\n",
    "until [ $a -gt $n ]\n",
    "do\n",
    "  c=`expr $a % $x`\n",
    "  if [ $c -eq 0 ]\n",
    "  then\n",
    "    ((count=count+1))\n",
    "  fi\n",
    "  ((a=a+1))\n",
    "done\n",
    "echo $count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff336e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6d9bc25",
   "metadata": {},
   "source": [
    "## Break and Continue Statements\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e9ec85",
   "metadata": {},
   "source": [
    "Break and Continue Statements\n",
    "i=0\n",
    "\n",
    "while [[ $i -lt 5 ]]\n",
    "do\n",
    "  echo \"$i\"\n",
    "  ((i++))\n",
    "  if [[ $i -eq 3 ]]; then\n",
    "    break\n",
    "  fi\n",
    "done\n",
    "\n",
    "echo 'Finished!'\n",
    "Can you figure out the output on the console?\n",
    "\n",
    "\n",
    "0\n",
    "1\n",
    "Finished!\n",
    "\n",
    "\n",
    "0\n",
    "1\n",
    "2\n",
    "Finished!     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0108587d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34a8e47f",
   "metadata": {},
   "source": [
    "Print weird\n",
    "Description\n",
    "Print Numbers 1 through 20, but something happens after 12. The loop should break after 12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8bb8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans:\n",
    "    \n",
    "    \n",
    "\n",
    "#Read the variable from STDIN\n",
    "\n",
    "#Output the variable to STDOUT\n",
    "\n",
    "#!/bin/bash\n",
    "\n",
    "LIMIT=19  # Upper limit\n",
    "\n",
    "a=0\n",
    "\n",
    "while [ \"$a\" -le \"$LIMIT\" ]\n",
    "do\n",
    " a=$(($a+1))\n",
    "\n",
    " if [ \"$a\" -gt 12 ]\n",
    " then\n",
    "   break  # Skip entire rest of loop.\n",
    " fi\n",
    "\n",
    " echo -n \"$a \"\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1718d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a5c38a4",
   "metadata": {},
   "source": [
    "# Assessment Questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9606cb22",
   "metadata": {},
   "source": [
    "## Introduction to Linux\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2831291a",
   "metadata": {},
   "source": [
    "Operating System Basics\n",
    "Which of the following OS is not based on Linux?\n",
    "\n",
    "\n",
    "Ubuntu\n",
    "\n",
    "\n",
    "Fedora\n",
    "\n",
    "\n",
    "Windows     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b5bf58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be233280",
   "metadata": {},
   "source": [
    "Linux Architecture\n",
    "Which of the following is the core of the Linux operating system which is also the connecting link between the software and hardware components of the computer?\n",
    "\n",
    "\n",
    "Shell\n",
    "\n",
    "\n",
    "Hardware layer\n",
    "\n",
    "\n",
    "Applications\n",
    "\n",
    "\n",
    "Kernel     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e729093",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69762672",
   "metadata": {},
   "source": [
    "File System in Linux\n",
    "Which of the following statements are true? (Note: More than one option may be correct)\n",
    "\n",
    "\n",
    "Root users cannot access the restricted files in the system.\n",
    "\n",
    "\n",
    "In Linux, files are stored in a tree-like structure.     ✓ Correct\n",
    "\n",
    "In Linux, root is denoted by ‘.’.\n",
    "\n",
    "\n",
    "In Linux, a regular account can be used for browsing the internet.     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44967a8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "959cdbd2",
   "metadata": {},
   "source": [
    "## Linux Commands\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4199b25",
   "metadata": {},
   "source": [
    "Networking Commands\n",
    "Which command is used to get the IP address specific to a given domain name?\n",
    "\n",
    "\n",
    "nslookup    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6c8a61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25e3a8df",
   "metadata": {},
   "source": [
    "Admin Commands\n",
    "By using which of the following commands can you directly move to your parent directory?\n",
    "\n",
    "\n",
    "rmdir\n",
    "\n",
    "\n",
    "cd/\n",
    "\n",
    "\n",
    "cd\n",
    "\n",
    "\n",
    "cd ..    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c4935a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a59d16d",
   "metadata": {},
   "source": [
    "Admin Commands\n",
    "The function of chmod command is\n",
    "\n",
    "\n",
    "It is used to check whether or not a file contains some lines that match the given pattern.\n",
    "\n",
    "\n",
    "It is used to change the access mode of a file.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b55b6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5219d809",
   "metadata": {},
   "source": [
    "Networking Commands\n",
    "'ifconfig' command is a networking command which is used for which of the following tasks?\n",
    "\n",
    "\n",
    "It is used to view and change the configurations of the network interfaces on the system.   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0503215c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa82d21d",
   "metadata": {},
   "source": [
    "## Linux Commands II\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a20189",
   "metadata": {},
   "source": [
    "Admin Commands\n",
    "Which of the following statements is true about kill command?\n",
    "\n",
    "\n",
    "It is used to find out the disk space occupied by a file or a directory.\n",
    "\n",
    "\n",
    "It keeps the processes in a running state even if the user exits the terminal or shell.\n",
    "\n",
    "\n",
    " It is used to terminate the process manually.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2f28a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd67eb5e",
   "metadata": {},
   "source": [
    "Admin Commands\n",
    "Which of the following commands is used to perform operations like addition, subtraction, modulus (on integers), multiplication and division on the given set of expressions and then prints the output.\n",
    "\n",
    "\n",
    "df\n",
    "\n",
    "\n",
    "expr    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6387c86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0eb28f1",
   "metadata": {},
   "source": [
    "Networking Commands\n",
    "Which of the following statements is true about curl command?\n",
    "\n",
    "\n",
    "It is used to transfer data from or to the server without user interaction.   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e644dc4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d202f437",
   "metadata": {},
   "source": [
    "## Variables and Operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f370111",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3ee862e",
   "metadata": {},
   "source": [
    "Variable Naming\n",
    "Which among the following is an invalid variable name?\n",
    "\n",
    "\n",
    "VAR1\n",
    "\n",
    "\n",
    "VAR\n",
    "\n",
    "\n",
    "V_AR\n",
    "\n",
    "\n",
    "VA@R    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd7ec84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29f8c736",
   "metadata": {},
   "source": [
    "Arithmetic Operators\n",
    "What will be the output of the following code if a and b are 3 and 5 respectively?\n",
    "\n",
    "echo \"Enter First Number: \"\n",
    "read a\n",
    "echo \"Enter Second Number: \"\n",
    "read b\n",
    "((a++))\n",
    "((b--))\n",
    "c=$((a+b))\n",
    "echo $c\n",
    " \n",
    "\n",
    "\n",
    "7\n",
    "\n",
    "\n",
    "8     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85b6fb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aefc65c2",
   "metadata": {},
   "source": [
    "Relational and Logical Operators\n",
    "Which of the following is not a relational operator?\n",
    "\n",
    "\n",
    "-ge\n",
    "\n",
    "\n",
    "-lt\n",
    "\n",
    "\n",
    "-a    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd92ec74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af6b852f",
   "metadata": {},
   "source": [
    "File Operators\n",
    "Which of the following file operators is used to check if the file has read access or not?\n",
    "\n",
    "\n",
    "-e\n",
    "\n",
    "\n",
    "-d\n",
    "\n",
    "\n",
    "-w\n",
    "\n",
    "\n",
    "-r    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d55d500",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25d5ddad",
   "metadata": {},
   "source": [
    "## Conditionals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8846b2",
   "metadata": {},
   "source": [
    "Relevant Method\n",
    "Which of the following conditional statements will be the most relevant and precise to use if you want to check if the current score is less than 50 and print 1 if it is and 0 otherwise?\n",
    "\n",
    "\n",
    "Only if statement\n",
    "\n",
    "\n",
    "Only else statement\n",
    "\n",
    "\n",
    "if else    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afdec32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e9826a2",
   "metadata": {},
   "source": [
    "Nested If Else\n",
    "What will be the output of the code if the name entered is ash and the password entered is pwd?\n",
    "\n",
    "echo \"Enter Username: \"\n",
    "read name\n",
    "if [ \"$name\" == \"ash\" ]; then\n",
    " echo \"Enter Password: \"\n",
    " read password\n",
    " if [ \"$password\" == \"pwd\" ]; then\n",
    "  echo \"Login Successful!\"\n",
    " else\n",
    "  echo \"Wrong Password!\"\n",
    " fi\n",
    "else\n",
    " echo \"Invalid Login Attempt!\"\n",
    "fi\n",
    " \n",
    "\n",
    "\n",
    "Login Successful!     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308f941a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "542c3d4a",
   "metadata": {},
   "source": [
    "## Loops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ab0c3b",
   "metadata": {},
   "source": [
    "For Loop\n",
    "#!/bin/bash\n",
    "for value in {10..0..2}\n",
    "do \n",
    "\techo $value\n",
    "done\n",
    "How many times will the For loop run in the above code?\n",
    "\n",
    "\n",
    "10\n",
    "\n",
    "\n",
    "2\n",
    "\n",
    "\n",
    "5\n",
    "\n",
    "\n",
    "6    ✓ Correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe720f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba05ea1f",
   "metadata": {},
   "source": [
    "Break and Continue Statements\n",
    "a=0\n",
    "while [[ $a -lt 10 ]]\n",
    "do\n",
    "  echo \"Number: $a\"\n",
    "  ((a++))\n",
    "  if [[ $a -eq 5 ]]; then\n",
    "    break\n",
    "  fi\n",
    "done\n",
    "How many times is the echo command executed inside the loop?\n",
    "\n",
    "\n",
    "4   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52a82ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0f0f3ea",
   "metadata": {},
   "source": [
    "Until Loop\n",
    "Description\n",
    "Write a bash script to Print first n integers starting from 1 using the Until loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce9b8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans:\n",
    "    \n",
    "#Enter your code here. Read input from STDIN. Print output to STDOUT\n",
    "#!/bin/bash\n",
    "read n\n",
    "a=1\n",
    "until [ ! $a -le $n ]\n",
    "do\n",
    "   echo $a\n",
    "   ((a++))\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedcf2ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2803e6d7",
   "metadata": {},
   "source": [
    "# Introduction to Hadoop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7284c501",
   "metadata": {},
   "source": [
    "## Introduction to Distributed Systems\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ee71c4",
   "metadata": {},
   "source": [
    "Distributed Systems\n",
    "Which of the following statements is correct?\n",
    " \n",
    "\n",
    "\n",
    "Distributed systems can take multiple requests at the same time.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759a4b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd736703",
   "metadata": {},
   "source": [
    "Distributed Systems\n",
    "Suppose a local supermarket needs a data management system. What type of file system implementation would suffice their needs?\n",
    "\n",
    "\n",
    "A horizontally scalable cluster system with multiple commodity machines.\n",
    "\n",
    "\n",
    "A central-local server architecture for ease of managing a central node.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71bfd8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2b5a2b1",
   "metadata": {},
   "source": [
    "Distributed Systems\n",
    "How are distributed systems able to maintain data availability?\n",
    " \n",
    "\n",
    "\n",
    "Data is stored on a reliable central node.\n",
    "\n",
    "\n",
    "Data is stored and replicated over many nodes for maintaining fault tolerance.     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b054a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d6d79b9",
   "metadata": {},
   "source": [
    "## Introduction to GFS and MapReduce\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e493d16",
   "metadata": {},
   "source": [
    "Google File System\n",
    "Which of the following statements is correct?\n",
    "\n",
    "\n",
    "GFS comprised specialised enterprise-grade servers for the slave nodes.\n",
    "\n",
    "\n",
    "GFS can be easily scaled up by upgrading the existing servers with more RAM and disk space.\n",
    "\n",
    "\n",
    "If one server in the GFS system goes down, the whole system can still continue operating without any interruption to data availability.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42d5b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5fc80428",
   "metadata": {},
   "source": [
    "MapReduce\n",
    "Which of the following statements is correct?\n",
    "\n",
    "\n",
    "Computations done using MapReduce are faster in nature than computations using other programming models.\n",
    "\n",
    "\n",
    "MapReduce can work on both unstructured and structured data sets.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d03cc4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "016036fc",
   "metadata": {},
   "source": [
    "## Introduction to Hadoop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e6519c",
   "metadata": {},
   "source": [
    "MapReduce\n",
    "State whether the following statement is true or false.\n",
    "\n",
    "\"In MapReduce tasks, some slots are reserved for the Map phase and some for the Reduce phase.\"\n",
    "\n",
    "\n",
    "True    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537af0cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "242217f3",
   "metadata": {},
   "source": [
    "HDFS\n",
    "Which of the following is the Secondary NameNode not responsible for?\n",
    "\n",
    "\n",
    "Keeping a log of all file edits\n",
    "\n",
    "\n",
    "Acting as a checkpoint for the NameNode\n",
    "\n",
    "\n",
    "Acting as the NameNode in case of active NameNode failure    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c01e54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4072847",
   "metadata": {},
   "source": [
    "Hadoop\n",
    "State whether the following statement is true or false.\n",
    "\n",
    "\"In a Hadoop cluster, a few nodes are used for storage and run HDFS only and the remaining nodes are used for processing and these run MapReduce only.\"\n",
    "\n",
    "\n",
    "True\n",
    "\n",
    "\n",
    "False   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b02e90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d473e9a8",
   "metadata": {},
   "source": [
    "## Hadoop 2.x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6b99e7",
   "metadata": {},
   "source": [
    "Hadoop 2.x\n",
    "State whether the following statement is true or false.\n",
    "\n",
    "\"Because of programmable slots, Hadoop 2.x is not limited to only the MapReduce programming model\"\n",
    "\n",
    "\n",
    "True   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11f7ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a37e784",
   "metadata": {},
   "source": [
    "Hadoop 2.x\n",
    "With Hadoop 2.x, a high number of jobs could be monitored better, because:\n",
    "\n",
    "\n",
    "More RAM was provided to the Master Node.\n",
    "\n",
    "\n",
    "YARN distributes the work of the Job Tracker to the Application Masters and the Resource Manager.     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a17cb8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3cfcefc8",
   "metadata": {},
   "source": [
    "Improvements in Hadoop 3.x\n",
    "Which of the following are not advantages or improvements of Hadoop 3.x over Hadoop 2.x?\n",
    "\n",
    "\n",
    "GPU support\n",
    "\n",
    "\n",
    "Erasure coding support\n",
    "\n",
    "\n",
    "Support for other frameworks like Spark, Tez, etc.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1595be8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51655044",
   "metadata": {},
   "source": [
    "## YARN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7ac159",
   "metadata": {},
   "source": [
    "Hadoop 2.x\n",
    "Read the article(Introduction section) and answer the question that follows: ResourceManagerHA\n",
    "\n",
    "How does Hadoop 2.x solve the problem of a Single Point of Failure (SPOF) at the ResourceManager after Hadoop 2.4?\n",
    "\n",
    "\n",
    "It maintains a Standby Resource Manager Server.   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a6ebd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dcc81edf",
   "metadata": {},
   "source": [
    "YARN\n",
    "Which of the following statements are true with respect to an Application Master? (Note: Multiple options may be correct.)\n",
    "\n",
    "\n",
    "It is responsible for monitoring the jobs of the slave nodes.     ✓ Correct\n",
    "\n",
    "Application Masters are present in the slave nodes for each individual job and are separate from the Resource Manager.     ✓ Correct\n",
    "\n",
    "It coordinates with the Node Manager for maintaining jobs in the Data Nodes.     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3feb0ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b87652e",
   "metadata": {},
   "source": [
    "YARN\n",
    "Which aspect of YARN has helped in enhancing the scalability, flexibility and fault tolerance of Hadoop? (Note: Multiple options may be correct.)\n",
    "\n",
    "\n",
    "Having a dedicated Application Master for each job.    ✓ Correct\n",
    "\n",
    "Decoupling the resource management and scheduling components of Hadoop.    ✓ Correct\n",
    "\n",
    "Having multiple containers in the same Data Node.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f3afac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b243a2b",
   "metadata": {},
   "source": [
    "## Task Processing in Hadoop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6df0e5",
   "metadata": {},
   "source": [
    "Task Processing in Hadoop\n",
    "What are the responsibilities of the Resource Manager in task processing in Hadoop? (Note: Multiple options may be correct.)\n",
    "\n",
    "\n",
    "Managing cluster’s resources   ✓ Correct\n",
    "\n",
    "Checking on the Application Master’s status   ✓ Correct\n",
    "\n",
    "Checking on the health of each individual node and container\n",
    "\n",
    "\n",
    "Receiving jobs from the clients   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2709fbb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d556e68",
   "metadata": {},
   "source": [
    "Task Processing in Hadoop\n",
    "State whether the following statement is true or false.\n",
    "\n",
    "\"The Resource Manager assumes that a node is dead if it does not receive a heartbeat signal in the designated period of time.\"\n",
    "\n",
    "\n",
    "True    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b25029b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3e6dbf1",
   "metadata": {},
   "source": [
    "## Tools for Hadoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb7c6b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2c3cc5f",
   "metadata": {},
   "source": [
    "Tools for Hadoop\n",
    "Which of the following tools provides a command-line interface for transferring data between relational databases and Hadoop?\n",
    "\n",
    "\n",
    "HBase\n",
    "\n",
    "\n",
    "Hive\n",
    "\n",
    "\n",
    "Sqoop   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded785cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45867956",
   "metadata": {},
   "source": [
    "ools for Hadoop\n",
    "State whether the following statement is true or false.\n",
    "\n",
    "\"Oozie is a tool that allows automating the data pipelines.\"\n",
    "\n",
    "\n",
    "True    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3521891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "918ee1a6",
   "metadata": {},
   "source": [
    "Tools for Hadoop\n",
    "What are the differences between MapReduce and Spark? (Note: Multiple options may be correct.)\n",
    "\n",
    "\n",
    "Spark is a lot faster than MapReduce.     ✓ Correct\n",
    "\n",
    "Spark is harder to code than MapReduce, and it requires installing hardware.\n",
    "\n",
    "\n",
    "Spark provides low-latency computing, whereas MapReduce provides high-latency computing.     ✓ Correct\n",
    "\n",
    "Spark can also process real-time data, unlike MapReduce, which only supports batch processing.      ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263c1916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eed7a947",
   "metadata": {},
   "source": [
    "# Introduction to HDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb800a6",
   "metadata": {},
   "source": [
    "## File Storage in HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2309a96e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8261e92a",
   "metadata": {},
   "source": [
    "File Storage in HDFS\n",
    "Which of the following is incorrect about block size in Hadoop?\n",
    "\n",
    "\n",
    "The block size is 128 MB, as it helps in reducing metadata storage.\n",
    "\n",
    "\n",
    "The block size is 128 MB because the internet connection is sufficient for this block size.   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353270f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d56e712",
   "metadata": {},
   "source": [
    "Distributed Systems\n",
    "Which of the following are features of horizontal scaling? (Note: Multiple options may be correct.)\n",
    "\n",
    "\n",
    "Can be done on the fly in Distributed Systems.    ✓ Correct\n",
    "\n",
    "Has no system downtime in Distributed Systems.    ✓ Correct\n",
    "\n",
    "Easily adds to the existing storage by adding new machines.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e81a66c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43d343fe",
   "metadata": {},
   "source": [
    "Hadoop\n",
    "State whether the following statement is true or false.\n",
    "\n",
    "\"Hadoop is preferred to RDBMSs for real-time storage and querying critical data such as financial transactions.\"\n",
    "\n",
    "\n",
    "True\n",
    "\n",
    "\n",
    "False   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdef6750",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4251b7e",
   "metadata": {},
   "source": [
    "HDFS\n",
    "State whether the following statement is true or false.\n",
    "\n",
    "\"HDFS is a distributed storage system for structured data only.\"\n",
    "\n",
    "\n",
    "True\n",
    "\n",
    "\n",
    "False   ✓ Correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3b26bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c0fda7f",
   "metadata": {},
   "source": [
    "Hadoop\n",
    "State whether the following statement is true or false.\n",
    "\n",
    "\"Unstructured and semi-structured data cannot be stored in an RDBMS at all.\"\n",
    "\n",
    "\n",
    "True\n",
    "\n",
    "False    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c876705",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a253624",
   "metadata": {},
   "source": [
    "## Basic Commands in HDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749334d0",
   "metadata": {},
   "source": [
    "Basic Commands in HDFS\n",
    "Which command is used to transfer a file from the local file system[of the EMR instance] to HDFS?\n",
    "\n",
    "\n",
    "cp\n",
    "\n",
    "\n",
    "put   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936169c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0a6f73c",
   "metadata": {},
   "source": [
    "Basic Commands in HDFS\n",
    "State whether the following statement is true or false.\n",
    "\n",
    "\"We need to change the owner of the directory in HDFS to which a file is being sent, to the user who will be sending the file\"\n",
    "\n",
    "\n",
    "True   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dafcc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e01bbfb0",
   "metadata": {},
   "source": [
    "Basic Commands in HDFS\n",
    "State whether the following statement is true or false.\n",
    "\n",
    "\"The replication factor cannot be changed in HDFS.\" \n",
    "\n",
    "\n",
    "True\n",
    "\n",
    "\n",
    "False    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba57458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e19c81a",
   "metadata": {},
   "source": [
    "## Write Operation in HDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb2aa2c",
   "metadata": {},
   "source": [
    "Write Operation in HDFS\n",
    "State whether the following statement is true or false.\n",
    "\n",
    "\"The lease given by the NameNode is important, as, without it, the client cannot write to HDFS.\"\n",
    "\n",
    "\n",
    "True    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98a7e7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7faeac72",
   "metadata": {},
   "source": [
    "Write Operation in HDFS\n",
    "Which of the following messages is not a part of the Write operation in HDFS?\n",
    "\n",
    "\n",
    "Write Complete\n",
    "\n",
    "\n",
    "Ack\n",
    "\n",
    "\n",
    "Create\n",
    "\n",
    "\n",
    "None of the above     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f851814",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b840fd1",
   "metadata": {},
   "source": [
    "## Rack Awareness in Hadoop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f3ae2c",
   "metadata": {},
   "source": [
    "Rack Awareness in Hadoop\n",
    "State whether the following statement is true or false.\n",
    "\n",
    "\"It is not recommended to store all the replicas in different data centres even though this maximises the probability that at least one replica is available at all times.\n",
    "\n",
    "\n",
    "True    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb646fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c142e1f",
   "metadata": {},
   "source": [
    "## Read Operation in HDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74e1bb4",
   "metadata": {},
   "source": [
    "Read Operation in HDFS\n",
    "State whether the following statement is true or false.\n",
    "\n",
    "\"HDFS client first verifies the checksum before sending the received packets to the client.\"\n",
    "\n",
    "\n",
    "True   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3881938f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61b3876e",
   "metadata": {},
   "source": [
    "## Features and Limitations of HDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a377f127",
   "metadata": {},
   "source": [
    "Limitations of HDFS\n",
    "State whether the following statement is true or false.\n",
    "\n",
    "\"HDFS can directly retrieve(low latency access) a portion of the data blocks from the DataNodes if you only need information from that part.\" \n",
    "\n",
    "\n",
    "True\n",
    "\n",
    "\n",
    "False   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047a97d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68215154",
   "metadata": {},
   "source": [
    "Limitations of HDFS\n",
    "State whether the following statement is true or false.\n",
    "\n",
    "\"HDFS is not optimised to handle small files efficiently because the metadata created will be too much to handle for the NameNode.\"\n",
    "\n",
    "\n",
    "True   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d3fc9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87f39f18",
   "metadata": {},
   "source": [
    "# MapReduce Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6f3f49",
   "metadata": {},
   "source": [
    "## Introduction to MapReduce Framework\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e58cfb",
   "metadata": {},
   "source": [
    "MapReduce Framework\n",
    "State whether the following statement is true or false.\n",
    "\n",
    "\"The Mapper is responsible for reading the data and then forming key-value pairs according to the task that needs to be performed.\"\n",
    "\n",
    "\n",
    "True    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfc86f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a40782c",
   "metadata": {},
   "source": [
    "MapReduce Framework\n",
    "State whether the following statement is true or false.\n",
    "\n",
    "\"The key-value pairs that have the same value in all the fields are treated as equal in the Map phase.\"\n",
    "\n",
    "\n",
    "True\n",
    "\n",
    "\n",
    "False    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff848f6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46295c40",
   "metadata": {},
   "source": [
    "## Basic Implementation of MapReduce using Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67e69e5",
   "metadata": {},
   "source": [
    "Basic Implementation of MapReduce using Python\n",
    "What is the purpose of using the ‘sys’ library of Python in MapReduce scripts?\n",
    "\n",
    "\n",
    "It is used for taking the inputs from the data set and the print statements used in the scripts.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a5fb51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96fd4849",
   "metadata": {},
   "source": [
    "Basic Implementation of MapReduce using Python\n",
    "State whether the following statement is true or false.\n",
    "\n",
    "\"The Mapper script outputs the data in the form of tuples.\"\n",
    "\n",
    "\n",
    "True\n",
    "\n",
    "\n",
    "False   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8015a41d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ffc6ea97",
   "metadata": {},
   "source": [
    "Basic Implementation of MapReduce using Python\n",
    "Why is a dictionary data structure used in the Reducer script?\n",
    "\n",
    "\n",
    "It is used for creating separate lists for different keys and their corresponding values.\n",
    "\n",
    "\n",
    "It is used for aggregating the data and performing the required functions and jobs efficiently.\n",
    "\n",
    "\n",
    "Both of the above options.   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad572d3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57cf6380",
   "metadata": {},
   "source": [
    "## Hadoop Streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e39c38",
   "metadata": {},
   "source": [
    "Hadoop Streaming\n",
    "State whether the following statement is true or false.\n",
    "\n",
    "\"The input data set should be moved into the HDFS before using the Hadoop Streaming command.\"\n",
    "\n",
    "\n",
    "True    ✓ Correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6799c05b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "befa2d71",
   "metadata": {},
   "source": [
    "Hadoop Streaming\n",
    "State whether the following statement is true or false.\n",
    "\n",
    "\"When viewing the result of a MapReduce job in HDFS, the ‘cat’ command is used to print out the content from all the files in the output directory whose names start with ‘part’, thereby printing out the entire result of the corresponding MapReduce program.\"\n",
    "\n",
    "\n",
    "True   ✓ Correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9184f7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f61a5b63",
   "metadata": {},
   "source": [
    "Hadoop Streaming\n",
    "What will happen if the output directory already exists for a MapReduce job?\n",
    "\n",
    "\n",
    "The job will throw an error stating that the output directory already exists.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8962fd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "327c645a",
   "metadata": {},
   "source": [
    "## The Combiner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0048d2",
   "metadata": {},
   "source": [
    "Combiner\n",
    "Recall the example from the previous segment, where you had to find the maximum age corresponding to each gender in the Customer Age data set and answer the following questions:\n",
    "\n",
    "Will a Combiner help in such a case?\n",
    " \n",
    "\n",
    "\n",
    "Yes  ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdc3d2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ef6904b",
   "metadata": {},
   "source": [
    "Combiner\n",
    "Recall the example from the previous segment, where you had to find the maximum age corresponding to each gender in the Customer Age data set and answer the following questions:\n",
    "\n",
    "How will a Combiner help in performing this job? (Note: Multiple options may be correct.)\n",
    "\n",
    "\n",
    "By finding the max for all the key-value pairs in each output of a Map task and, thus, improving the performance of the MapReduce job.    ✓ Correct\n",
    "\n",
    "By reducing memory usage of the Reduce task.    ✓ Correct\n",
    "\n",
    "By reducing the Network I/O latency.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f9efdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "867f6bad",
   "metadata": {},
   "source": [
    "Combiner\n",
    "Recall the example from the previous segment, where you had to find the maximum age corresponding to each gender in the Customer Age data set and answer the following questions:\n",
    "\n",
    "State whether the following statement is true or false.\n",
    "\n",
    "\"The Reducer, with a few small modifications, can be taken as reference for implementing the Combiner for this job.\"\n",
    "\n",
    "\n",
    "True     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0b5180",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aeb56c6f",
   "metadata": {},
   "source": [
    "## The Partitioner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012c9263",
   "metadata": {},
   "source": [
    "Partitioner\n",
    "State whether the following statement is true or false.\n",
    "\n",
    "\"By enabling similar data to be present and processed in the same job, the Partitioner helps in reducing the time taken for processing a job.\"\n",
    "\n",
    "\n",
    "True    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc807556",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0224e4eb",
   "metadata": {},
   "source": [
    "## Job Scheduling and Fault Tolerance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f583f253",
   "metadata": {},
   "source": [
    "HDFS\n",
    "State whether the following statement is true or false.\n",
    "\n",
    "\"Each node in a cluster has multiple containers that are running a Map or a Reduce task.\"\n",
    "\n",
    "\n",
    "True    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41abdbfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc6cf069",
   "metadata": {},
   "source": [
    "MapReduce Framework\n",
    "Is it possible to increase the number of Map tasks for a MapReduce job?\n",
    "\n",
    "\n",
    "Yes    ✓ Correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92972240",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "406b64aa",
   "metadata": {},
   "source": [
    "MapReduce Framework\n",
    "The number of Map tasks equals the number of input file splits, and it may be increased by the user by reducing the input split size. This leads to ____.\n",
    "\n",
    "\n",
    "Improved resource utilisation    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e991892a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be912eaa",
   "metadata": {},
   "source": [
    "YARN\n",
    "Which of the following has not improved due to the decoupling of resource management and scheduling components of Hadoop?\n",
    "\n",
    "\n",
    "Flexibility\n",
    "\n",
    "\n",
    "Fault Tolerance\n",
    "\n",
    "\n",
    "None of the above    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d3cf99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bff3eaee",
   "metadata": {},
   "source": [
    "# MapReduce Programming Coding Questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f439663d",
   "metadata": {},
   "source": [
    "MapReduce Programming-01\n",
    "Download this data set containing the complete works of William Shakespeare and then write MapReduce programs to find the following:\n",
    "\n",
    "Which word has the highest frequency of occurrence in the document?\n",
    "\n",
    "\n",
    "‘the’ (30,086 times)    ✓ Correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc5700a",
   "metadata": {},
   "source": [
    "MapReduce Programming-02\n",
    "Download this data set containing the complete works of William Shakespeare and then write MapReduce programs to find the following:\n",
    "\n",
    "What is the frequency of occurrence of the word ‘Romeo’? (Ignore cases and don't remove punctuation marks from any words.)\n",
    "\n",
    "\n",
    "48\n",
    "\n",
    "\n",
    "49      ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e4d2b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17cbed39",
   "metadata": {},
   "source": [
    "MapReduce Programming-03\n",
    "Download this data set containing the complete works of William Shakespeare and then write MapReduce programs to find the following:\n",
    "\n",
    "What is the frequency of the phrase \"circumference.\" in the data set? (You do not need to remove the punctuation marks from the words.)\n",
    "\n",
    "\n",
    "1\n",
    "\n",
    "\n",
    "2    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f46aba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6bad557d",
   "metadata": {},
   "source": [
    "MapReduce Programming-04\n",
    "Download this airline data set and then create MapReduce programs to find the following:\n",
    "\n",
    "Count the number of unique ordered pairs of origin and destination (Origin, Destination) present in the dataset, i.e., for two flights, either the origin or the destination differs.\n",
    "\n",
    "\n",
    "1024\n",
    "\n",
    "\n",
    "1023\n",
    "\n",
    "\n",
    "1403\n",
    "\n",
    "\n",
    "1404     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452f7a2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6faef632",
   "metadata": {},
   "source": [
    "MapReduce Programming-05\n",
    "Download this airline data set and then create MapReduce programs to find the following:\n",
    "\n",
    "What is the airport code and the number of flights corresponding to that airport, with the maximum number of outgoing flights in the year 2004?\n",
    "\n",
    "\n",
    "ORD, 5320    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febd0d1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6d8583f",
   "metadata": {},
   "source": [
    "MapReduce Programming-06\n",
    "Download this ODI batting data set and then create MapReduce programs to find the following:\n",
    "\n",
    "Which player scored the highest number of centuries?\n",
    "\n",
    "\n",
    "Sachin R Tendulkar (49 centuries)\n",
    "\n",
    "\n",
    "Sachin R Tendulkar (48 centuries)    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dd67a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4f4250a",
   "metadata": {},
   "source": [
    "MapReduce Programming-07\n",
    "Download this ODI batting data set and then create MapReduce programs to find the following:\n",
    "\n",
    "In which year did Indian players score the maximum number of centuries?\n",
    "\n",
    "\n",
    "1992\n",
    "\n",
    "\n",
    "2011\n",
    "\n",
    "\n",
    "1999\n",
    "\n",
    "\n",
    "1998   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349deb70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bdeb1c5",
   "metadata": {},
   "source": [
    "# Graded Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d5f943",
   "metadata": {},
   "source": [
    "Q1 Hadoop\n",
    "Suppose Ram has to implement an alternative server architecture in his organisation, as its single server system is no longer capable of satisfying the growing needs and is also limited in terms of scalability. Ram decides to use conventional desktop systems to implement a Distributed Hadoop Cluster System. What do you think would be the primary reason behind Ram deciding to use this kind of implementation?\n",
    "\n",
    "\n",
    "Commodity machines are cheap and available easily.    ✓ Correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4432707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbd893b0",
   "metadata": {},
   "source": [
    "Q2 Hadoop Ecosystem\n",
    "Consider the case of a children’s hospital. This hospital is completely digitised, in the sense that all reports, such as scan reports, blood test reports, etc, are stored as digital data, which is then stored in a Hadoop Cluster implementation. The hospital uses a lot of machines connected over a network, and, hence, a large volume of structured as well as unstructured real-time data is streamed to its Hadoop cluster. The hospital is not able to understand how to process this data. Which specific tool of the Hadoop ecosystem can help the hospital in this situation?\n",
    "\n",
    "\n",
    "Flume\n",
    "\n",
    "\n",
    "Sqoop\n",
    "\n",
    "\n",
    "Spark Streaming    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867d4c56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f309156",
   "metadata": {},
   "source": [
    "Q3 MapReduce Framework\n",
    "Which of the following takes (key-value) pairs as input and produces output that is also in the form of (key-value) pairs?\n",
    "\n",
    "\n",
    "Mapper\n",
    "\n",
    "\n",
    "Reducer\n",
    "\n",
    "\n",
    "Both Mapper and Reducer    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e81ca7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a996b6f6",
   "metadata": {},
   "source": [
    "Q4 HDFS\n",
    "A client wants to read a block that is available in three DataNodes present across multiple geographical locations. The distances between the client and the DataNodes are as follows:\n",
    "\n",
    "DataNode 1: 5 units\n",
    "\n",
    "DataNode 2: 4 units\n",
    "\n",
    "DataNode 3: 7 units\n",
    "\n",
    "What would be the order of preference followed by the NameNode to access the block?\n",
    "\n",
    "\n",
    "1-2-3\n",
    "\n",
    "\n",
    "2-1-3   ✓ Correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21752af4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ed53267",
   "metadata": {},
   "source": [
    "Q5 MapReduce Job\n",
    "Consider a MapReduce problem where we need to find out the average of the marks scored by different students corresponding to each class. The data is in the form of a CSV file with each entry corresponding to a particular student and has two comma-separated columns, the first one containing the class of a student and the second one containing their marks.\n",
    "\n",
    "The code for the Mapper script is as follows:\n",
    "\n",
    "import sys\n",
    "#input comes from STDIN (standard input)\n",
    "for line in sys.stdin:\n",
    "    line = line.strip()\n",
    "    line = line.split(\";\")\n",
    "\n",
    "    if len(line) <=2:\n",
    "        key = line[0]\n",
    "        value = line[1]\n",
    "\n",
    "        print ('%s\\t%s' % (key, value))\n",
    "Is there any problem with the code above?\n",
    "\n",
    "If Yes, then what is the problem with this code with respect to the problem at hand?\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "The code needs no change.\n",
    "\n",
    "\n",
    "There is a problem in assigning the key and value variables.\n",
    "\n",
    "\n",
    "There is a problem in the split statement.   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f88d39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c9ff4c2",
   "metadata": {},
   "source": [
    "Q6 Hadoop Architecture\n",
    "In a Hadoop cluster, if the NameNode (master node) fails, which of the following nodes takes up its responsibilities?\n",
    "\n",
    "\n",
    "Secondary NameNode\n",
    "\n",
    "\n",
    "DataNode\n",
    "\n",
    "\n",
    "Passive/Standby NameNode    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7de749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d5ed063",
   "metadata": {},
   "source": [
    "Q7 Rack Awareness in Hadoop\n",
    "Allen has access to three data centres, and he has stored his data in such a way that for each block of data, 2 out of the 3 replicas are stored in a single data centre.\n",
    "\n",
    "What would be the major benefit of this approach?\n",
    "\n",
    "\n",
    "It reduces the network I/O for read and write operations.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658c773f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2eb8eb1e",
   "metadata": {},
   "source": [
    "Q8 HDFS\n",
    "Suppose there is a Hadoop Cluster that contains 1,000 files of size 2 MB each, with the chunk size equal to the file size, i.e., 2 MB. The size of the metadata for storing information for a single chunk in the system is 10 KB. Suppose there is another Hadoop cluster where the same data has been stored in larger chunks of size 200 MB each. What would be the respective storage space occupied for storing the metadata of these files in each of these clusters?\n",
    "\n",
    "Note: The size of the metadata for a single chunk is the same for both systems.\n",
    "\n",
    "\n",
    "9.76 MB, 500 KB\n",
    "\n",
    "\n",
    "9.76 MB, 1,000 KB\n",
    "\n",
    "\n",
    "9.76 MB, 100 KB    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3971001a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78063d8e",
   "metadata": {},
   "source": [
    "Q9 MapReduce Framework\n",
    "Determine whether the following statement is True or False.\n",
    "\n",
    "“The final outputs of Reduce tasks are stored on the local file system of the data nodes running them”.\n",
    "\n",
    "\n",
    "True\n",
    "\n",
    "\n",
    "False    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988671b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7aa2dc78",
   "metadata": {},
   "source": [
    "Q10 MapReduce Framework\n",
    "Determine whether the following statement is True or False?\n",
    "\n",
    "“The final outputs of Map tasks are stored on the local file system of the data nodes running them”.\n",
    "\n",
    "\n",
    "True    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1bae93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e225be65",
   "metadata": {},
   "source": [
    "# Introduction to NoSQL Databases and Apache HBase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5ede61",
   "metadata": {},
   "source": [
    "## Why NoSQL Databases?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75417e57",
   "metadata": {},
   "source": [
    "RDBMS\n",
    "Which of the following statements about RDBMSes is/are correct?\n",
    "\n",
    "\n",
    "New columns can be dynamically added to the table schema in SQL tables.\n",
    "\n",
    "\n",
    "Relational databases are vertically scalable.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09040065",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a38d11a6",
   "metadata": {},
   "source": [
    "Structured and Unstructured Data\n",
    "Which of the following is not a type of unstructured data?\n",
    "\n",
    "\n",
    "Satellite imagery\n",
    "\n",
    "\n",
    "Excel files    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf07052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9feec618",
   "metadata": {},
   "source": [
    "NoSQL\n",
    "Which of the following data format can be stored and processed efficiently using RDBMSes?\n",
    "\n",
    "\n",
    "Images\n",
    "\n",
    "\n",
    "Videos\n",
    "\n",
    "\n",
    "Data arranged in rows and columns    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e345cb3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b35c07a2",
   "metadata": {},
   "source": [
    "NoSQL\n",
    "Which of the following statements about NoSQL databases is correct? (Multiple options may be correct).\n",
    "\n",
    "\n",
    "NoSQL databases can store structured, semi-structured and unstructured data.    ✓ Correct\n",
    "\n",
    "NoSQL databases follow a strict schema.\n",
    "\n",
    "\n",
    "NoSQL databases are horizontally scalable.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8521f4af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12190363",
   "metadata": {},
   "source": [
    "NoSQL\n",
    "In which of the following scenarios should NoSQL databases be used? (Multiple options may be correct).\n",
    "\n",
    "\n",
    "When the retrieval speed of the data is a concern     ✓ Correct\n",
    "\n",
    "When data security is the topmost priority\n",
    "\n",
    "\n",
    "When massive amounts of data need to be stored and processed     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d900b8d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e466c7e",
   "metadata": {},
   "source": [
    "## How Are NoSQL Databases Designed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cbcff5",
   "metadata": {},
   "source": [
    "CAP Theorem\n",
    "According to the CAP theorem, a system can satisfy at most two of three guarantees, Consistency, Availability and Partition tolerance. Which guarantee cannot be sacrificed in a distributed system in the case of NoSQL databases?\n",
    "\n",
    "\n",
    "Consistency\n",
    "\n",
    "\n",
    "Availability\n",
    "\n",
    "\n",
    "Partition Tolerance     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98141a7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5fcfb427",
   "metadata": {},
   "source": [
    "CAP Theorem\n",
    "Which of the following use cases must prioritise consistency over availability?\n",
    "\n",
    "\n",
    "Prices of air tickets on a travel portal\n",
    "\n",
    "\n",
    "Notifications on Facebook\n",
    "\n",
    "\n",
    "A customer’s bank account details that include all the latest transactions     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61b4652",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a59b3a4a",
   "metadata": {},
   "source": [
    "CAP Theorem\n",
    "Select the correct statement from those given below.\n",
    "\n",
    "\n",
    "The 'A' in CAP refers to 'Accuracy'.\n",
    "\n",
    "\n",
    "RDBMSes do not guarantee partition tolerance.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425fe810",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b8f8def",
   "metadata": {},
   "source": [
    "CAP Theorem\n",
    "A social networking website needs to store data of users and their friends in a data store. Assume that the data is stored in a distributed storage system. In case of a system outage, if the latest count of friends for a user is not available, the portal can still be available and reflect older stats. According to the CAP theorem, which type of datastore can be used here?\n",
    "\n",
    "\n",
    "CA\n",
    "\n",
    "\n",
    "CP\n",
    "\n",
    "\n",
    "AP    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679df46b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06e30ecc",
   "metadata": {},
   "source": [
    "## Types of NoSQL Databases and Use Cases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c9082f",
   "metadata": {},
   "source": [
    "Types of NoSQL Databases\n",
    "Which of the following is an example of a key-value datastore?\n",
    "\n",
    "\n",
    "HBase\n",
    "\n",
    "\n",
    "CouchDB\n",
    "\n",
    "Neo4j\n",
    "\n",
    "\n",
    "Redis    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d19d6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38b6c5cd",
   "metadata": {},
   "source": [
    "Types of NoSQL Databases\n",
    "Which type of consistency is provided by HBase?\n",
    "\n",
    "\n",
    "Immediate    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d27465",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "592c95bd",
   "metadata": {},
   "source": [
    "## Introduction to HBase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6a8bdd",
   "metadata": {},
   "source": [
    "HBase\n",
    "Using which of the following keys are HBase tables sorted?\n",
    "\n",
    "\n",
    "Primary key\n",
    "\n",
    "\n",
    "Super key\n",
    "\n",
    "\n",
    "Candidate key\n",
    "\n",
    "\n",
    "Row key   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d8afed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6c885c7",
   "metadata": {},
   "source": [
    "HBase\n",
    "Can HBase leverage all the features that are offered by HDFS and Hadoop?\n",
    "\n",
    "\n",
    "Yes   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1286a812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd6c072c",
   "metadata": {},
   "source": [
    "HBase\n",
    "Which of the following does not define HBase?\n",
    "\n",
    "\n",
    "Schema-oriented   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82971d8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc542b36",
   "metadata": {},
   "source": [
    "HBase\n",
    "Which of the following statements about HBase is/are not true? (Multiple options may be correct).\n",
    "\n",
    "\n",
    "HBase is optimised for operations such as joins and groupby.    ✓ Correct\n",
    "\n",
    "HBase is an open-source implementation of Google's Bigtable.\n",
    "\n",
    "\n",
    "HBase is suitable for storing structured, semi-structured and unstructured data.\n",
    " \n",
    "\n",
    "HBase is not a part of the Hadoop ecosystem.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4652c3a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "628de994",
   "metadata": {},
   "source": [
    "HBase\n",
    "Which of the following statements is not true about HBase? \n",
    "\n",
    "\n",
    "HBase is a database built on top of the HDFS.\n",
    "\n",
    "\n",
    "HBase provides sequential access to data.     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3211f27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ddd35c52",
   "metadata": {},
   "source": [
    "## Data Model of HBase\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4b1316",
   "metadata": {},
   "source": [
    "HBase Data Model\n",
    "State whether the following statement is true or false.\n",
    "\n",
    "HBase tables are stored in row format in the memory.\n",
    "\n",
    "\n",
    "True \n",
    "\n",
    "\n",
    "False    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c001438",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8d67a9f",
   "metadata": {},
   "source": [
    "HBase Data Model\n",
    "Which of the following statements is true about the HBase data model?\n",
    "\n",
    "\n",
    "HBase is governed by its schema, which describes the whole structure of tables.\n",
    "\n",
    "\n",
    "HBase is schema-less, it doesn't have the concept of fixed columns schema; defines only column families.   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21426bb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "887838a9",
   "metadata": {},
   "source": [
    "HBase Data Model\n",
    "Choose whether the following statement is true or false.\n",
    "\n",
    "A column qualifier when integrated with the column family name is used to identify a single column.\n",
    "\n",
    "\n",
    "True    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a177c780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7eb451ab",
   "metadata": {},
   "source": [
    "RDBMS\n",
    "Which of the following statements about the data model of RDBMSs is true?\n",
    "\n",
    "\n",
    "RDBMSes provide all the available versions of the data values.\n",
    "\n",
    "\n",
    "The data cells in an RDBMS can remain empty.\n",
    "\n",
    "\n",
    "RDBMSes store only the latest version of the data values.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aace1c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9fc66721",
   "metadata": {},
   "source": [
    "## HBase Shell Commands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0510813",
   "metadata": {},
   "source": [
    "Shell Commands\n",
    "Which of the commands given below is the first command used to create the following table ‘Student’?\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "create 'Student', ('Personal Details:Name', 'Personal Details:Age', 'Personal Details:Phone'), ('Scores:Semester1', 'Scores:Semester 2')\n",
    "\n",
    "create 'Student', 'Name', 'Age', 'Semester 1', 'Semester 2'\n",
    "\n",
    "create 'Student', 'Personal Details', 'Scores'     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24011db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f31d6a4",
   "metadata": {},
   "source": [
    "Shell Commands\n",
    "Which of the following commands can be used to change the version of the column family ‘Personal Details’ to '2' in the table given below?\n",
    "\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "\n",
    "put 'Student', 'Personal Details', 'Version=2'\n",
    "\n",
    "create 'Student', 'Personal Details', Version=2\n",
    "\n",
    "alter 'Student', NAME=> 'Personal Details', VERSIONS=>2     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a820e060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7d18f37",
   "metadata": {},
   "source": [
    "Shell Commands\n",
    "State whether the following statement is true or false.\n",
    "\n",
    "To be dropped, a table should be enabled first.\n",
    "\n",
    "\n",
    "True\n",
    "\n",
    "False    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de94a1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97664292",
   "metadata": {},
   "source": [
    "Shell Commands\n",
    "Which of the following filter commands allows you to fetch a key-value pair from a specified column family?\n",
    "\n",
    "\n",
    "Value filter\n",
    "\n",
    "\n",
    "Family filter    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a386248b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92bd4771",
   "metadata": {},
   "source": [
    "Shell Commands\n",
    "Which of the following options describes the correct order in which the ‘Truncate’ command works?\n",
    "\n",
    "\n",
    "Disable, Delete, Enable\n",
    "\n",
    "\n",
    "Disable, Drop, Enable\n",
    "\n",
    "\n",
    "Delete, Create, Enable\n",
    "\n",
    "\n",
    "Disable, Drop, Recreate    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ffac83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2792e4a3",
   "metadata": {},
   "source": [
    "# Programming in HBase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac1c5fd",
   "metadata": {},
   "source": [
    "## HappyBase - HBase Python API\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8f4013",
   "metadata": {},
   "source": [
    "HappyBase\n",
    "Which of the following commands can be used to verify the installation of HappyBase in a Python shell?\n",
    "\n",
    "\n",
    "import happybase   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a030bd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9ec726b",
   "metadata": {},
   "source": [
    "HappyBase\n",
    "Which of the following should be used to open a connection in a Python script?\n",
    "\n",
    "\n",
    "connection(open)\n",
    "\n",
    "\n",
    "connection.open()    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790bf142",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f691ef17",
   "metadata": {},
   "source": [
    "HappyBase\n",
    "What of the following statements is true about the following lines of code?\n",
    "\n",
    "connection.create_table(\n",
    "    'test',\n",
    "    {'cf1': dict(),\n",
    "     'cf2': dict(max_versions=1),\n",
    "     'cf3': dict(max_versions=10), \n",
    "    }\n",
    ")\n",
    " \n",
    "\n",
    "\n",
    "The ‘cf1’ can store only a single version of data in the table.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6e7b47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eddae369",
   "metadata": {},
   "source": [
    "HappyBase\n",
    "State whether the following statement is true or false.\n",
    "\n",
    "print(connection.tables()) will print all the existing tables in HBase.\n",
    "\n",
    " \n",
    "\n",
    "True   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a0aae5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb556581",
   "metadata": {},
   "source": [
    "HappyBase\n",
    "What is the function of the following line of code in a Python script?\n",
    "\n",
    "mtable = connection.table('employee')\n",
    " \n",
    "\n",
    "\n",
    "It will change the name of the table from ‘employee’ to ‘mtable’.\n",
    "\n",
    "\n",
    "It will print the description of the table ‘employee’.\n",
    "\n",
    "\n",
    "It is used to get the reference to the table ‘employee’.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a8fbed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df266ab5",
   "metadata": {},
   "source": [
    "## HappyBase - Use case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa744d09",
   "metadata": {},
   "source": [
    "HappyBase\n",
    "Which of the following functions should be used to create a connection with the localhost?\n",
    "\n",
    "\n",
    "connection = happybase.Connection('localhost', port=9090)     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43464576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5e17f1c",
   "metadata": {},
   "source": [
    "HappyBase\n",
    "Complete the following line of code that is used to delete an HBase table.\n",
    "connection._________(‘mytable’,_____=True)\n",
    "\n",
    "\n",
    "delete, disable\n",
    "\n",
    "\n",
    "delete, enable\n",
    "\n",
    "\n",
    "delete_table, enable\n",
    "\n",
    "\n",
    "delete_table, disable   ✓ CorrectHappyBase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f12af1",
   "metadata": {},
   "source": [
    "What could be the most suitable name for the following function?\n",
    "\n",
    "def_____(table_name, key):\n",
    "\tmtable=connection.table(table_name)\n",
    "\tconnection.open()\n",
    "\tdata= mtable.row(key)\n",
    "\tconnection.close()\n",
    "\treturn data\n",
    " \n",
    "\n",
    "\n",
    "scan_table\n",
    "\n",
    "\n",
    "get_rowkey\n",
    "\n",
    "\n",
    "get_data    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a0f2e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89ba1148",
   "metadata": {},
   "source": [
    "# How HBase Works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92731a34",
   "metadata": {},
   "source": [
    "## HBase Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c677cb3a",
   "metadata": {},
   "source": [
    "HMaster\n",
    "Which of the following features is/are provided by an HMaster? (Multiple options may be correct).\n",
    "\n",
    "\n",
    "Load balancing     ✓ Correct\n",
    "\n",
    "Location of the meta-table\n",
    "\n",
    "\n",
    "Data recovery     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cb907f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ea46df1",
   "metadata": {},
   "source": [
    "Zookeeper\n",
    "Which of the following statements about the Zookeeper is/are correct? (Multiple options may be correct).\n",
    "\n",
    "\n",
    "Zookeeper stores the location of the meta-table.     ✓ Correct\n",
    "\n",
    "Zookeeper provides server failure notifications.     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc0d42a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5208562a",
   "metadata": {},
   "source": [
    "## Read Operation in HBase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ef0ca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93b688a9",
   "metadata": {},
   "source": [
    "Meta-Table\n",
    "Which of the following is the correct structure of the meta-table key?\n",
    "\n",
    "\n",
    "<Start rowkey of the region, end rowkey of the region, region ID>\n",
    "\n",
    "\n",
    "<Table name, start rowkey of the region, end rowkey of the region>\n",
    "\n",
    "\n",
    "<Table name, start rowkey of the region, Region ID>    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219132a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1fecbfab",
   "metadata": {},
   "source": [
    "Fetching Region Server Location\n",
    "Which of the following steps is not followed while fetching the location of a region server?\n",
    "\n",
    "\n",
    "The information of the identified region server and the location of the meta-table are cached by the client for further interactions.\n",
    "\n",
    "\n",
    "The client contacts the HMaster to know the location of the region server where the region is present.   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955b5b31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5615cfb",
   "metadata": {},
   "source": [
    "Fetching Region Server Location\n",
    "Choose whether the following statement is true or false:\n",
    "\n",
    "‘A client can connect directly with both the HMaster and the region servers.’\n",
    "\n",
    "\n",
    "True\n",
    "\n",
    "\n",
    "False   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1f13a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "419bff18",
   "metadata": {},
   "source": [
    "Read Operation\n",
    "When a read operation is performed, which of the following is scanned first?\n",
    "\n",
    "\n",
    "Regions\n",
    "\n",
    "\n",
    "HFiles\n",
    "\n",
    "\n",
    "MemStore\n",
    "\n",
    "\n",
    "Block Cache   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88189319",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92ad80d8",
   "metadata": {},
   "source": [
    "Read Operation\n",
    "State whether the following statement is true or false.\n",
    "\n",
    "The Bloom filter is used to search the HFile that contains the required key-value pair.\n",
    "\n",
    "\n",
    "True    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56aada7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "370ff145",
   "metadata": {},
   "source": [
    "## Write Operation in HBase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec749d4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0ec1c2d",
   "metadata": {},
   "source": [
    "Write Operation\n",
    "Which of the following is the first step in a write operation?\n",
    "\n",
    "\n",
    "The data from the MemStore is flushed to the HDFS, creating a new HFile.\n",
    "\n",
    "\n",
    "The data is written to the block cache where frequently accessed data is stored.\n",
    "\n",
    "\n",
    "The data is written to the WAL (Write Ahead Log).     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02373515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d833b72f",
   "metadata": {},
   "source": [
    "Write Operation\n",
    "Fill in the blank.\n",
    "\n",
    "Once the data is written to the WAL, it is next written to the ____.\n",
    "\n",
    "\n",
    "Block cache\n",
    "\n",
    "\n",
    "MemStore    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7464e5a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c1b13ab",
   "metadata": {},
   "source": [
    "Compactions\n",
    "Which type of compaction is used to remove deleted and expired data from tables?\n",
    "\n",
    "\n",
    "Minor compaction\n",
    "\n",
    "\n",
    "Major compaction    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6a8730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0873a461",
   "metadata": {},
   "source": [
    "Write Operation\n",
    "Which of the following statements is/are correct? (Multiple options may be correct).\n",
    "\n",
    "\n",
    "The read efficiency becomes low as the number of write operations increases.     ✓ Correct\n",
    "\n",
    "Minor compactions are more resource intensive than major compactions.\n",
    "\n",
    "\n",
    "Every MemStore flush creates a new HFile, and data is stored as documents.\n",
    "\n",
    "\n",
    "Data is not deleted using a delete operation because HFiles are immutable.     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dac5bb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41cbb9f3",
   "metadata": {},
   "source": [
    "## HBase Schema Design\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793852a9",
   "metadata": {},
   "source": [
    "Schema Design\n",
    "What should be the time complexity if the data to be read is found in MemStore?\n",
    "\n",
    "\n",
    "O(log(b/e)), where b is the number of blocks and e is the number of key-value pairs\n",
    "\n",
    "\n",
    "O(c) where c is number of columns - Constant Time\n",
    "\n",
    "\n",
    "O(log(e)) where e is the number of key-value pairs    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfe0755",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a5d1f8e",
   "metadata": {},
   "source": [
    "Schema Design\n",
    "Fill in the blank.\n",
    "\n",
    "When a single node is overwhelmed by huge amounts of read/write requests, this phenomenon is known as _______.\n",
    "\n",
    "\n",
    "Salting\n",
    "\n",
    "\n",
    "Normalisation\n",
    "\n",
    "\n",
    "Hotspotting    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef31dce0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c15eb1f6",
   "metadata": {},
   "source": [
    "# Graded Questions - HBase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279ce2b6",
   "metadata": {},
   "source": [
    "01 Database Design\n",
    "Which of the following are characteristics of a good database?\n",
    "\n",
    "\n",
    "High latency, low throughput\n",
    "\n",
    "\n",
    "Low latency, low throughput\n",
    "\n",
    "\n",
    "High latency, high throughput\n",
    "\n",
    "\n",
    "Low latency, high throughput     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df28f7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "145f2b13",
   "metadata": {},
   "source": [
    "02 HappyBase\n",
    "Which library does HappyBase use to connect to HBase?\n",
    "\n",
    "\n",
    "Node.js\n",
    "\n",
    "\n",
    "Thrift     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4483cb0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4d1e2cf",
   "metadata": {},
   "source": [
    "03 HBase Architecture\n",
    "Should the region server be located on all the DataNodes?\n",
    "\n",
    "\n",
    "Yes    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4450c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "490186d0",
   "metadata": {},
   "source": [
    "04 Schema Design\n",
    "Which of the following techniques adds a random prefix to the start of a rowkey?\n",
    "\n",
    "\n",
    "Hashing\n",
    "\n",
    "\n",
    "Salting    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f79509b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5daac9d4",
   "metadata": {},
   "source": [
    "05 Schema Design\n",
    "What is the time complexity if you want to find the required data block in an HFile?\n",
    "\n",
    "\n",
    "O(log(b)), where b is the number of blocks    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75d9b0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e62f259",
   "metadata": {},
   "source": [
    "06 NoSQL Database\n",
    "State whether the following statement is true or false.\n",
    "\n",
    "NoSQL was designed because SQL systems were incompetent in processing transactional data.\n",
    "\n",
    "\n",
    "True\n",
    "\n",
    "\n",
    "False     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaa0055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50d85782",
   "metadata": {},
   "source": [
    "07 HBase Data Model\n",
    "Which of the following statements is not true for column families?\n",
    "\n",
    "\n",
    "Column families consist of more than one column.\n",
    "\n",
    "\n",
    "The number of columns present in a column family is fixed.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d92318",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a398037",
   "metadata": {},
   "source": [
    "08 HBase Data Model\n",
    "Suppose you are working for XYZ Corp. You have created an HBase table named EMPLOYEE that stores the records of the employees in the following column families along with their current columns:\n",
    "Personal details: Name, Personal details: Age\n",
    "Contact details: Email, Contact details: Phone number\n",
    "You want to insert a record for a new employee who has recently joined the organisation. The details provided by the new employee are as follows:\n",
    "\n",
    "Name: Aloysia Turner\n",
    "Age: 30 years\n",
    "Email: Aloysia@abc.com\n",
    "Phone number: 9876912345\n",
    "Landline number: 022-25432100\n",
    "You are expected to store as much information as possible provided by this employee. How will you proceed?\n",
    " \n",
    "\n",
    "\n",
    "You need to first update the schema of the EMPLOYEE table using the alter command, and only then you will be able to insert the record that contains all the employee details, including her landline number.\n",
    "\n",
    "\n",
    "You do not need to make any change in the schema of the EMPLOYEE table; you can directly insert the record that contains all the details of this employee, including her landline number.     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43e8a9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "231d36ad",
   "metadata": {},
   "source": [
    "09 HBase Shell Commands\n",
    "Which of the following is not true regarding the ‘put’ command in HBase?\n",
    "\n",
    "\n",
    "The put command is used to add data to an HBase table.\n",
    "\n",
    "\n",
    "The put command is used to update the existing values.\n",
    "\n",
    "\n",
    "A single put command can be used to add multiple cell values.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44a606d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d203d5a",
   "metadata": {},
   "source": [
    "10 NoSQL Database\n",
    "Which one of the following is not a reason for the popularity of NoSQL?\n",
    "\n",
    "\n",
    "Enables better scalability\n",
    "\n",
    "\n",
    "Enables faster data lookup\n",
    "\n",
    "\n",
    "Allows data to be stored across multiple nodes\n",
    "\n",
    "\n",
    "Enables the storage of consistent data eternally    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e8b72c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d4f4ec5",
   "metadata": {},
   "source": [
    "# Introduction to Data Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b3c3d8",
   "metadata": {},
   "source": [
    "## Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8366a8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d9b23e0",
   "metadata": {},
   "source": [
    "Data Ingestion\n",
    "Select the option that best describes data ingestion.\n",
    "\n",
    "\n",
    "It is the process of absorbing something.\n",
    "\n",
    "\n",
    "It is the process of absorbing data for immediate use or storage.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99201657",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1c9be5b",
   "metadata": {},
   "source": [
    "Data Ingestion\n",
    "Why can’t big data systems ingest all types of data at once? (Note: More than one option may be correct.)\n",
    "\n",
    "\n",
    "In the big data ecosystem, different types of data have different methods of storage.    ✓ Correct\n",
    "\n",
    "Different types of data are often used for different types of analysis.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9b81be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5b33e48",
   "metadata": {},
   "source": [
    "## Challenges in Data Ingestion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd18ae5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1266226f",
   "metadata": {},
   "source": [
    "Network challenges\n",
    "Which of the following could be some of the network challenges in data ingestion? (Note: More than one option may be correct.)\n",
    "\n",
    "\n",
    "Network bandwidth and speed should be satisfactory according to your needs.     ✓ Correct\n",
    "\n",
    "Network security is a major aspect that you should consider while ingesting data from unknown sources.     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a00de14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa85419c",
   "metadata": {},
   "source": [
    "Challenges in Data Ingestion\n",
    "How does data being generated at high speed affect the performance of data ingestion?\n",
    "\n",
    "\n",
    "It does not affect data ingestion.\n",
    "\n",
    "\n",
    "Data has to be managed properly so that it does not impose too much load on the systems at the destination.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf037c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e724658",
   "metadata": {},
   "source": [
    "## Key Steps of Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa77e94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86eb0449",
   "metadata": {},
   "source": [
    "Data Collection\n",
    "State whether the following statement is true or false:\n",
    "\n",
    "'You need to prioritise the data sources that you use for importing data according to your requirement in order to ensure optimal use of processing power, storage and time.'\n",
    "\n",
    "\n",
    "True     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ef8e98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c084bfd",
   "metadata": {},
   "source": [
    "Data Validation\n",
    "State whether the following statement is true or false:\n",
    "\n",
    "'For a recommender system, you should prioritise user identification information, such as user name and user ID, for data ingestion.'\n",
    "\n",
    "\n",
    "True\n",
    "\n",
    "\n",
    "False    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a287d9fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d93ee7e",
   "metadata": {},
   "source": [
    "## Tools for Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699bbfc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3de572e",
   "metadata": {},
   "source": [
    "Tools for Data Ingestion\n",
    "Which of the following commands is used for data ingestion tasks in Hadoop?\n",
    "\n",
    "\n",
    "cd\n",
    "\n",
    "\n",
    "mv\n",
    "\n",
    "\n",
    "put    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4eaef0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e596e5f",
   "metadata": {},
   "source": [
    "Tools for Data Ingestion\n",
    "State whether the following statement is true or false:\n",
    "\n",
    "'Kafka enables programmers to pass messages from one point to another'\n",
    "\n",
    "\n",
    "True   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a67a01e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09bfa883",
   "metadata": {},
   "source": [
    "## Types of Data and File Formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ddfbc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4e54075",
   "metadata": {},
   "source": [
    "Types of Data\n",
    "Which of the following types of data has the majority in terms of the volume of production in the industry?\n",
    "\n",
    "\n",
    "Structured data\n",
    "\n",
    "\n",
    "Unstructured data   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20701550",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec4fda5b",
   "metadata": {},
   "source": [
    "File Formats\n",
    "Which of the following file formats does not support block compression?\n",
    "\n",
    "\n",
    "Text/CSV files   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892b5b7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "112b0bae",
   "metadata": {},
   "source": [
    "# Apache Sqoop - I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851530be",
   "metadata": {},
   "source": [
    "## Introduction to Sqoop and its Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95e30c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82473091",
   "metadata": {},
   "source": [
    "Apache Sqoop\n",
    "State whether the following state is true or false:\n",
    "\n",
    "'Sqoop allows data transfer in only one direction, i.e., from RDBMSes to the HDFS.'\n",
    "\n",
    "\n",
    "True\n",
    "\n",
    "\n",
    "False   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d2b54a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fcd0604",
   "metadata": {},
   "source": [
    "Apache Sqoop\n",
    "Which of the following is/are advantages of using Sqoop?\n",
    "\n",
    "\n",
    "Cost-efficient   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c650497",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9e939ce",
   "metadata": {},
   "source": [
    "Apache Sqoop\n",
    "State whether the following statement is true or false:\n",
    "\n",
    "'All Sqoop jobs are map-only. They do not require the ‘reduce’ phase.'\n",
    "\n",
    "\n",
    "True   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6458e885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6bd9357",
   "metadata": {},
   "source": [
    "## Apache Sqoop Set-Up and Database Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be52fc99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c544eb3a",
   "metadata": {},
   "source": [
    "Apache Sqoop Set-Up and Database Set-Up\n",
    "Which of the following is the correct command to access MySQL in the EMR instance(post setting up MySQL on EMR instance)?\n",
    "\n",
    "\n",
    "mysql -u admin - p, Password - 123\n",
    "\n",
    "\n",
    "mysql -u root - p, Password - pass\n",
    "\n",
    "\n",
    "mysql -u root - p, Password - 123   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dec4dcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72bda619",
   "metadata": {},
   "source": [
    "Apache Sqoop Set-Up and Database Set-Up\n",
    "Which of the following commands can be used to download a file from the internet?\n",
    "\n",
    "\n",
    "put\n",
    "\n",
    "\n",
    "ls\n",
    "\n",
    "\n",
    "hadoop\n",
    "\n",
    "\n",
    "wget    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5c0a30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f1d2466",
   "metadata": {},
   "source": [
    "## Exporting Data - Sqoop Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a0a6da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e57d73b",
   "metadata": {},
   "source": [
    "Sqoop Export\n",
    "What is the function of the ‘--connect’ argument in the Sqoop export command?\n",
    "\n",
    "\n",
    "It gives the JDBC url where the MySQL table is located.    ✓ Correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e567149",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24d167fa",
   "metadata": {},
   "source": [
    "Sqoop Export\n",
    "State whether the following statement is true or false:\n",
    "\n",
    "'Before exporting data to MySQL tables, you need to ensure that the corresponding tables are already present in the RDBMS.'\n",
    "\n",
    "\n",
    "True   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3015c55c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d96457dc",
   "metadata": {},
   "source": [
    "## Importing Data - Sqoop Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59167e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12b38c75",
   "metadata": {},
   "source": [
    "Sqoop Import\n",
    "What will happen if you do not use the ‘--target-dir’ argument in the Sqoop import command?\n",
    "\n",
    "\n",
    "The table will be imported to an arbitrary location in the HDFS.\n",
    "\n",
    "\n",
    "An error will be thrown, with a message saying no target directory was provided.\n",
    "\n",
    "\n",
    "The table will be imported to a folder with the same name as that of the table in the home directory of the HDFS.    ✓ Correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e71f74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc20699b",
   "metadata": {},
   "source": [
    "Sqoop Import\n",
    "State whether the following statement is true or false:\n",
    "\n",
    "'Before running the Sqoop import command, you need to ensure that the target directory does not already exist in HDFS.'\n",
    "\n",
    "\n",
    "True    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa5ad66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "902b42a3",
   "metadata": {},
   "source": [
    "## Importing Data - Importing All Tables Using Sqoop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a63abd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55dd73c4",
   "metadata": {},
   "source": [
    "Sqoop Import\n",
    "State whether the following statement is true or false:\n",
    "\n",
    "'All the tables to be imported from MySQL should have a primary key defined.'\n",
    "\n",
    "\n",
    "True    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12230688",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3913833b",
   "metadata": {},
   "source": [
    "## Importing Data - Handling NULL Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8963831f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65d0b535",
   "metadata": {},
   "source": [
    "Handling NULL values\n",
    "State whether the following statement is true or false:\n",
    "\n",
    "'By default, Sqoop encodes a missing value to ‘null’ in lowercase.'\n",
    "\n",
    "\n",
    "True   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40955f5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e13abe1",
   "metadata": {},
   "source": [
    "Handling NULL values\n",
    "Why is the default ‘null’ string not enough for dealing with missing values?\n",
    "\n",
    "\n",
    "The data itself may have NULL as a string/regular value instead of a missing value.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5a9a5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6bd335e3",
   "metadata": {},
   "source": [
    "## Importing Data - Handling Mappers for a Sqoop Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc2d6fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ba059db",
   "metadata": {},
   "source": [
    "Handling Mappers\n",
    "State whether the following statement is true or false:\n",
    "\n",
    "'Increasing the number of Mappers will always lead to an increase in performance of the Sqoop job due to an increase in parallelism.'\n",
    " \n",
    "\n",
    "\n",
    "True\n",
    "\n",
    "\n",
    "False     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0354fa4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5475e90f",
   "metadata": {},
   "source": [
    "## Importing Data - Importing in various File Formats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e52e8fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0be021e4",
   "metadata": {},
   "source": [
    "Sqoop Import\n",
    "Which of the following commands is used for storing data as a parquet file?\n",
    "\n",
    "\n",
    "--as-pfile\n",
    "\n",
    "\n",
    "--as-parquet\n",
    "\n",
    "\n",
    "--as-parquetfile    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ce7fdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6796fdb3",
   "metadata": {},
   "source": [
    "Parquet Files\n",
    "State whether the following statement is true or false:\n",
    "\n",
    "'Parquet files enhance performance in big-data-related tasks by 10x in all kinds of workflows.'\n",
    "\n",
    "\n",
    "True\n",
    "\n",
    "\n",
    "False     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52c4c15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cfcfc93b",
   "metadata": {},
   "source": [
    "## Importing Data - Compression using Sqoop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c233c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f330585",
   "metadata": {},
   "source": [
    "Compression in Sqoop Import\n",
    "State whether the following statement is true or false:\n",
    "\n",
    "'Using the ‘--compress’ argument is strictly better than using the SnappyCodec for compression purposes in terms of the size of the final file generated.'\n",
    "\n",
    "\n",
    "True\n",
    "\n",
    "\n",
    "False    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367bd3e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a546bca8",
   "metadata": {},
   "source": [
    "## Extra Coding Questions - Sqoop - I\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164583e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a060bb3a",
   "metadata": {},
   "source": [
    "Sqoop - I\n",
    "Import all the records from the ‘movies’ table and find out the number of records that are imported by the Sqoop job. Use ‘/user/root/MovieLens/movies’ as the target directory for the import.\n",
    "\n",
    "\n",
    "1,682    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f52898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc4f5c85",
   "metadata": {},
   "source": [
    "Sqoop - I\n",
    "Import the records from all the tables of the MovieLens data set and find out the total number of records that are imported by the Sqoop job. Use ‘/user/root/MovieLens/All_tables’ as the warehouse directory for the import.\n",
    "\n",
    "\n",
    "1,00,000\n",
    "\n",
    "\n",
    "1,05,555    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc972c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a301c410",
   "metadata": {},
   "source": [
    "Sqoop - I\n",
    "Type the following commands in MySQL to insert some NULL records into the ‘Users’ table of the MovieLens database.\n",
    "\n",
    "mysql> insert into users values(944, null, \"M\", null, null);\n",
    "mysql> insert into users values(945, null, \"M\", null, null);\n",
    "mysql> insert into users values(946, null, \"F\", null, null);\n",
    "Import the records from the ’Users’ table and find out the number of records imported by the Sqoop job. Use ‘/user/root/MovieLens/users_NULL’ as the target directory for the import. Also, while importing, the string values where null is present are to be replaced with ‘\\\\N’ and non-string values with ‘\\\\N’.\n",
    "\n",
    "\n",
    "946      ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769dbcdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ea0cc7a",
   "metadata": {},
   "source": [
    "Sqoop - I\n",
    "Import the records from the 'Genres' table. Use three mappers for this task and find out the number of part files generated by the Sqoop import command. Use ‘/user/root/MovieLens/genres’ as the target directory for the import.\n",
    "\n",
    "\n",
    "1\n",
    "\n",
    "\n",
    "3     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fdd5ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e27fdd45",
   "metadata": {},
   "source": [
    "Sqoop - I\n",
    "Import the records from the 'Users' table and store them as a parquet file and a sequence file. Also, find out the number of records imported by the Sqoop job for both the file formats. Use ‘/user/root/MovieLens/users_parquet’ and ‘/user/root/MovieLens/users_sequence’ as the target directories for the parquet and sequence files, respectively, for the import.\n",
    "\n",
    "\n",
    "945\n",
    "\n",
    "\n",
    "942\n",
    "\n",
    "\n",
    "946    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487fc2e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9d1681c",
   "metadata": {},
   "source": [
    "Sqoop - I\n",
    "Import the records from the 'Movies' table and store them in a compressed format using SnappyCodec. Also, find out the space occupied by the output files when they are compressed and when they are not. Use ‘/user/root/MovieLens/movies_compressed’ as the target directory for the import.\n",
    "\n",
    "\n",
    "69 KB, 40 KB\n",
    "\n",
    "\n",
    "65 KB, 36 KB    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1521b472",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd748678",
   "metadata": {},
   "source": [
    "# Apache Sqoop - II"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754be753",
   "metadata": {},
   "source": [
    "## Importing Data - Importing Specific rows in Sqoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bc42aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a74cd28",
   "metadata": {},
   "source": [
    "Importing specific rows in Sqoop\n",
    "Let’s suppose that there is a Customer Data table in MySQL and we need to import only those records from the table which has the ID greater than 300. Which of the following ‘--where’ arguments will satisfy this requirement? Assume that the name of the ID column is ‘id’\n",
    "\n",
    "\n",
    "--where “id > 300”    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d27576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "505c8d41",
   "metadata": {},
   "source": [
    "## Importing Data - SQL Queries in Sqoop Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367b7c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6699ad41",
   "metadata": {},
   "source": [
    "Sqoop Import\n",
    "State whether the following statement is true or false:\n",
    "\n",
    "'The '--split-by' parameter is not mandatory while using free-form query import (--query parameter).'\n",
    "\n",
    "\n",
    "True\n",
    "\n",
    "\n",
    "False   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f3e2c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b55bc89f",
   "metadata": {},
   "source": [
    "## Importing Data - Using Incremental Import in Sqoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c126350",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd0faab4",
   "metadata": {},
   "source": [
    "Incremental Import\n",
    "State whether the following statement is true or false:\n",
    "\n",
    "'If there is no new record in the tables in MySQL, then the incremental append command will throw an error.'\n",
    "\n",
    "\n",
    "True\n",
    "\n",
    "\n",
    "False    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499332b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1323ae8",
   "metadata": {},
   "source": [
    "Incremental Import\n",
    "State whether the following statement is true or false:\n",
    "\n",
    "'The ‘--last--modified’ parameter can be used to import all the rows that have been updated.'\n",
    "\n",
    "\n",
    "True   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26470be1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27a22afc",
   "metadata": {},
   "source": [
    "## Sqoop Jobs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b97b051",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f95d5291",
   "metadata": {},
   "source": [
    "Sqoop Jobs\n",
    "State whether the following statement is true or false:\n",
    "\n",
    "'You can use the ‘--list’ option with Sqoop jobs to retrieve the list of all the tables stored in a database.'\n",
    "\n",
    "\n",
    "True\n",
    "\n",
    "\n",
    "False   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dce18f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "988b88b8",
   "metadata": {},
   "source": [
    "Sqoop Jobs\n",
    "Which of the following is a valid Sqoop job argument?\n",
    "\n",
    "\n",
    "--exec\n",
    "\n",
    "\n",
    "--list\n",
    "\n",
    "\n",
    "--create\n",
    "\n",
    "\n",
    "All of the above    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1f6179",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aff7824b",
   "metadata": {},
   "source": [
    "## Tuning Sqoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f962593",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cca541eb",
   "metadata": {},
   "source": [
    "Tuning Sqoop\n",
    "State whether the following statement is true or false:\n",
    "\n",
    "'You need to ensure that there is no ‘\\n’ character in the password text file that you use for authenticating Sqoop commands.'\n",
    "\n",
    "\n",
    "True    ✓ Correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a171e40a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f7b2d8f",
   "metadata": {},
   "source": [
    "Tuning Sqoop\n",
    "Why do we provide 'chmod 400' permissions to the password file for Sqoop commands?\n",
    "\n",
    "\n",
    "The 'chmod 400' permissions allow the user to only read the password, and other users or the group of the original user do not have permission to the file.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6f5f21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c952cfc5",
   "metadata": {},
   "source": [
    "## Extra Coding Questions - Sqoop - II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861502da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d595ac68",
   "metadata": {},
   "source": [
    "Sqoop - II\n",
    "From the ‘genres_movies’ table, import all the records in which the genre_id is equal to 1 and find out the number of records that are imported by the Sqoop job. Use ‘/user/root/MovieLens/genres_movies_1’ as the target directory for the import.\n",
    "\n",
    "\n",
    "255\n",
    "\n",
    "\n",
    "256\n",
    "\n",
    "\n",
    "251     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82ae126",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04772a04",
   "metadata": {},
   "source": [
    "Sqoop - II\n",
    "Write a Sqoop import command to import the data, which comes after the join between the ‘users’ and ‘occupations’ tables. You have to import this data so that you can determine the occupation id and name of a particular user. Also, find out the number of records imported by the Sqoop job.\n",
    " \n",
    "\n",
    "\n",
    "946\n",
    "\n",
    "\n",
    "942\n",
    "\n",
    "\n",
    "943     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfceced6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba7f1604",
   "metadata": {},
   "source": [
    "Sqoop - II\n",
    "In the ‘genres’ table present in the ‘/user/root/MovieLens/genres directory’, calculate the size of the files imported into HDFS. Now, add five more records to the MySQL table as follows:\n",
    "\n",
    "mysql>insert into movielens.genres values (19,'Cat1');\n",
    "mysql>insert into movielens.genres values (20,'Cat2');\n",
    "mysql>insert into movielens.genres values (21,'Cat3');\n",
    "mysql>insert into movielens.genres values (22,'Cat4');\n",
    "mysql>insert into movielens.genres values (23,'Cat5');\n",
    "Import the ‘genres’ table into HDFS such that only newly added records are imported. Use ‘/user/root/MovieLens/genres_new’ as the target directory for the import. Find out the approximate size of the output files generated after the Sqoop job.\n",
    "\n",
    "\n",
    "35–45 bytes    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6af2dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4bf78fc",
   "metadata": {},
   "source": [
    "Sqoop - II\n",
    "Create a Sqoop job that imports all the records from the ‘genres_movies’ table in which genre_id is equal to 2. Also, ensure that the password that is passed to the job is secured in a separate text file. Use ‘/input/MovieLens/genres_movies_job’ as the target directory for the import. Execute the Sqoop job and find out the number of records that it retrieved.\n",
    "\n",
    "\n",
    "135    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d262b877",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d213cd8f",
   "metadata": {},
   "source": [
    "# Apache Flume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92935ed6",
   "metadata": {},
   "source": [
    "## Introduction to Apache Flume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4aef13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4745c79f",
   "metadata": {},
   "source": [
    "Data Ingestion\n",
    "State whether the following statement is true or false:\n",
    "\n",
    "'When multiple servers access the HDFS cluster simultaneously, it poses a major challenge to the process of Data Ingestion.'\n",
    "\n",
    "\n",
    "True     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990b6a06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee72d7a2",
   "metadata": {},
   "source": [
    "Data Ingestion\n",
    "Which of the following is not a type of unstructured data?\n",
    "\n",
    "\n",
    "Log files generated by an API\n",
    "\n",
    "\n",
    "Videos and images\n",
    "\n",
    "\n",
    "Employee data in the form of SQL tables    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef02659",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0ee8a9c",
   "metadata": {},
   "source": [
    "## Components of Flume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25593a55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa05a034",
   "metadata": {},
   "source": [
    "Components of Flume\n",
    "Which of the following is not a function of the header of an event in Flume?\n",
    "\n",
    "\n",
    "Routing events to an appropriate channel\n",
    " \n",
    "\n",
    "Uniquely identifying an event\n",
    "\n",
    "\n",
    "None of the above   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e873ced",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2cdc6927",
   "metadata": {},
   "source": [
    "Components of Flume\n",
    "State whether the following statement is true or false:\n",
    "\n",
    "'Sources receive data from an application by listening to its ports or file system.'\n",
    "\n",
    "\n",
    "True    ✓ Correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179b25d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d686ec49",
   "metadata": {},
   "source": [
    "Components of Flume\n",
    "State whether the following statement is true or false:\n",
    "\n",
    "'You are limited to the pre-existing types of components of a Flume agent.'\n",
    "\n",
    "\n",
    "True\n",
    "\n",
    "\n",
    "False    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0654e15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b898ebf6",
   "metadata": {},
   "source": [
    "## Characteristics and Use Cases of Flume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67819a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a03a1642",
   "metadata": {},
   "source": [
    "Characteristics of Flume\n",
    "Which of the following is/are characteristic(s) of Flume? (Note: More than one option may be correct.)\n",
    "\n",
    "\n",
    "Automatic fault tolerance     ✓ Correct\n",
    "\n",
    "Scales by itself     ✓ Correct\n",
    "\n",
    "Extendable nature     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8829e2c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1ef99b5",
   "metadata": {},
   "source": [
    "## Flume Configuration Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9c39a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1da65b8",
   "metadata": {},
   "source": [
    "Flume Configuration Files\n",
    "State whether the following statement is true or false:\n",
    "\n",
    "'It is important to define a flow for sources to be connected to their corresponding sinks.'\n",
    "\n",
    "\n",
    "True    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf16ba12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e479eb6",
   "metadata": {},
   "source": [
    "Flume Configuration Files\n",
    "Which of the following is a source property? (Note: More than one option may be correct.)\n",
    "\n",
    "\n",
    "type    ✓ Correct\n",
    "\n",
    "bind    ✓ Correct\n",
    "\n",
    "port    ✓ Correct\n",
    "\n",
    "hostname    ✓ Correc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6847d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1ebf039",
   "metadata": {},
   "source": [
    "## Flume Flows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4aa3e5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f885be3",
   "metadata": {},
   "source": [
    "Flume Flows\n",
    "State whether the following statement is true or false:\n",
    "\n",
    "A single set of channel, source and sink connected together can form a Flume flow.\n",
    "\n",
    "\n",
    "True    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a675dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4bd15a1",
   "metadata": {},
   "source": [
    "Flume Flows\n",
    "Which of the following is an advantage of using a tiered data collection flow?\n",
    "\n",
    "\n",
    "It reduces the load on the sink connected to the HDFS.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957bde3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "946cae40",
   "metadata": {},
   "source": [
    "## Tuning Flume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f886d819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96833946",
   "metadata": {},
   "source": [
    "Tuning Flume\n",
    "State whether the following statement is true or false:\n",
    "\n",
    "'The batch size directly affects throughput, latency and duplication under failure.'\n",
    "\n",
    "\n",
    "True    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2516d79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3208ab68",
   "metadata": {},
   "source": [
    "Tuning Flume\n",
    "State whether the following statement is true or false:\n",
    "\n",
    "'A channel's transaction capacity must always be higher than its capacity.'\n",
    "\n",
    "\n",
    "True\n",
    "\n",
    "\n",
    "False   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e3e1f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95953aae",
   "metadata": {},
   "source": [
    "## Sqoop vs. Flume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97923c07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3630eda",
   "metadata": {},
   "source": [
    "Sqoop vs. Flume\n",
    "State whether the following statement is true or false: \n",
    "\n",
    "'Sqoop and Flume are event-driven data ingestion tools.'\n",
    "\n",
    "\n",
    "True\n",
    "\n",
    "\n",
    "False    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac51f04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6eac9e04",
   "metadata": {},
   "source": [
    "Sqoop vs. Flume\n",
    "State whether the following statement is true or false: \n",
    "\n",
    "'Flume can scale horizontally with the help of multiple Flume agents.'\n",
    "\n",
    "\n",
    "True    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a53cef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8175de5",
   "metadata": {},
   "source": [
    "## Flume Practice Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cac572",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f1179aa",
   "metadata": {},
   "source": [
    "1 Apache Flume\n",
    "What are the names of the sources, channels and sinks used in the Flume agent specified in the spool.conf configuration file?\n",
    "\n",
    "\n",
    "spoolsource, sachnl, avrosink\n",
    "\n",
    "\n",
    "spoolsrc, sachnl, avrosnk    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e0367f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b5a8984",
   "metadata": {},
   "source": [
    "2 Apache Flume\n",
    "What is the type of source specified in the spool.conf configuration file for the Flume agent?\n",
    "\n",
    "\n",
    "spooldir    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a42a851",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "acd03193",
   "metadata": {},
   "source": [
    "3 Apache Flume\n",
    "What is the directory from where the Flume agent defined in the spool.conf configuration file imports the logs?\n",
    "\n",
    "\n",
    "/tmp/UpGradLogs     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecf84a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1616e9b",
   "metadata": {},
   "source": [
    "4 Apache Flume\n",
    "What is the type of sink of the Flume agent specified in the spool.conf configuration file?\n",
    "\n",
    "\n",
    "avro      ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220ed48f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68cf1d82",
   "metadata": {},
   "source": [
    "5 Apache Flume\n",
    "What is the type of channel of the Flume agent specified in the spool.conf configuration file?\n",
    "\n",
    "\n",
    "avro\n",
    "\n",
    "\n",
    "file    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ed290f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "107e6189",
   "metadata": {},
   "source": [
    "6 Apache Flume\n",
    "What are the names of the sources, channels and sinks used in the Flume agent specified in the hdfssink.conf configuration file?\n",
    "\n",
    "\n",
    "avrosrc, hachnl, hdfssnk     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed8a0c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "439e5aec",
   "metadata": {},
   "source": [
    "7 Apache Flume\n",
    "What is the port number to which the source of the Flume agent specified in the hdfssink.conf configuration file, connects to?\n",
    "\n",
    "\n",
    "12345          ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bbff23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0899e1fd",
   "metadata": {},
   "source": [
    "8 Apache Flume\n",
    "What is the channel capacity of the channel specified in the hdfssink.conf configuration file for the Flume agent?\n",
    "\n",
    "\n",
    "100000    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ffdc13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f9ee56e",
   "metadata": {},
   "source": [
    "9 Apache Flume\n",
    "What is the type of channel of the Flume agent specified in the hdfssink.conf configuration file?\n",
    "\n",
    "\n",
    "memory    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2534ce0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "140f8ff6",
   "metadata": {},
   "source": [
    "10 Apache Flume\n",
    "What is the directory where the Flume agent specified in the hdfssink.conf configuration file dumps its data?\n",
    "\n",
    "\n",
    "/test/flume/data/part-00000\n",
    "\n",
    "\n",
    "/test/flume/data    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c36b57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ea85016",
   "metadata": {},
   "source": [
    "# Graded Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d72f3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73745ee0",
   "metadata": {},
   "source": [
    "1 Incremental Import\n",
    "Which of the following statements is true about the --incremental append clause in Sqoop?\n",
    "\n",
    "\n",
    "It imports only newly added rows.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaa4586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63aa5dbb",
   "metadata": {},
   "source": [
    "2 Apache Sqoop\n",
    "State whether the following statement is true or false.\n",
    "\n",
    "'All Sqoop jobs are map-only. They do not require the reduce phase.'\n",
    "\n",
    "\n",
    "True   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613edac7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef1470f8",
   "metadata": {},
   "source": [
    "3 Importing Specific Rows Using Sqoop\n",
    "Does using the --where parameter of the Sqoop import command lead to significant performance issues?\n",
    "\n",
    "\n",
    "Using the --where parameter does not lead to a significant performance loss, as Sqoop directly processes the data imported without any latency issues.\n",
    "\n",
    "\n",
    "Using the --where parameter always leads to a significant performance loss, as it imposes a significant burden on the database server.\n",
    "\n",
    "\n",
    "If complex function calls are specified, then the --where parameter has a significant impact on performance.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd1354f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4eb6be8",
   "metadata": {},
   "source": [
    "4 Flume Configuration Files\n",
    "A Flume agent can be configured by writing a Flume configuration file. Which of the following is a vital component of a configuration file?\n",
    "\n",
    "\n",
    "Source\n",
    "\n",
    "\n",
    "Channel\n",
    "\n",
    "\n",
    "Sink\n",
    "\n",
    "\n",
    "All of the above   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55ef41a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45e68ac5",
   "metadata": {},
   "source": [
    "5 Flume Configuration Files\n",
    "Consider the following snippet from a Flume configuration file:\n",
    "\n",
    "agent1.sources = src1\n",
    "agent1.channels = ch1 ch2 ch3\n",
    "agent1.sources.src1.channels = ch1 ch2\n",
    "agent1.sources.src1.selector.type = replicating\n",
    "agent1.sources.src1.type = spooldir \n",
    "agent1.sources.src1.spoolDir = /tmp/UpGradLogs\n",
    "Which of the following statements is true about this configuration?\n",
    "\n",
    "\n",
    "All events are written in either of the two channels: ch1 and ch2.\n",
    "\n",
    "The type of the source is spooldir.    ✓ Correct\n",
    "\n",
    "All events are written in both the channels: ch1 and ch2.     ✓ Correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdde9712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9f69b97",
   "metadata": {},
   "source": [
    "6 Apache Flume\n",
    "State whether the following statement is true or false.\n",
    "\n",
    "'A source can be connected to multiple channels and a sink can be connected to only one channel.'\n",
    "\n",
    "\n",
    "True     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656f6858",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "175aec9c",
   "metadata": {},
   "source": [
    "7 Key Steps of Data Ingestion\n",
    "Assume that you have to build a recommender system for YouTube videos. Which of the following types of data will you take into consideration for data ingestion for this particular use case?\n",
    "\n",
    "\n",
    "User watch history    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b7ceb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43822d24",
   "metadata": {},
   "source": [
    "8 Challenges of Data Ingestion\n",
    "Which of the following are challenges in the process of data ingestion? \n",
    "\n",
    "Note: Multiple options may be correct.\n",
    "\n",
    "\n",
    "Multiple different types of data and their sources     ✓ Correct\n",
    "\n",
    "Processing power for ingesting data     ✓ Correct\n",
    "\n",
    "Processing power for performing analysis on data\n",
    "\n",
    "\n",
    "Network challenges     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacaa6a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0a6469c",
   "metadata": {},
   "source": [
    "9 Types of Data\n",
    "Classify the following as structured, unstructured and semi-structured:\n",
    "\n",
    "i. YouTube videos\n",
    "\n",
    "ii. Aadhaar card data of people living in a village\n",
    "\n",
    "iii. Weather data set stored in a JSON file\n",
    "\n",
    "\n",
    "i - Structured, ii - Unstructured, iii - Semi-structured\n",
    " \n",
    "\n",
    "ii - Structured, iii - Unstructured, i - Semi-structured\n",
    "\n",
    "\n",
    "ii - Structured, i - Unstructured, iii - Semi-structured     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e77732",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b9778ac",
   "metadata": {},
   "source": [
    "10 Tools for Data Ingestion\n",
    "Suppose you are a part of a company that has recently opened a new branch and you have been tasked with the responsibility of ingesting critical data from the company’s central repository, which is composed of SQL tables. Which of the following tools will you use for this purpose?\n",
    "\n",
    "\n",
    "Sqoop    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d3b040",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45bbd07a",
   "metadata": {},
   "source": [
    "# Introduction to Hive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32910c84",
   "metadata": {},
   "source": [
    "## Introduction to Hive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b069e138",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f77e2d13",
   "metadata": {},
   "source": [
    "Hive Origins\n",
    "What's the main reason behind the development of Hive? More than one options may be correct.\n",
    "\n",
    "\n",
    "Programmers, especially data analysts, were less familiar with MapReduce programming     ✓ Correct\n",
    "\n",
    "Writing MapReduce programs for processing data is time taking     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a0d75b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a10ff64",
   "metadata": {},
   "source": [
    "## Hive at Ola & Pinterest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaae579",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0738ed05",
   "metadata": {},
   "source": [
    "Usage of Hive in Ola and Pinterest\n",
    "Why is Hive used by Ola for analysing data using the ad-hoc interactive queries? \n",
    "\n",
    "\n",
    "Hive is a data warehousing tool      ✓ Correct\n",
    "\n",
    "Hive is a product created and owned by OLA. Hence, OLA uses it extensively for performing all its ad-hoc interactive analytical tasks\n",
    "\n",
    "\n",
    "Tools such as Qubole and Hue provide an excellent user-friendly interface for running ad-hoc interactive queries on Hive.      ✓ Correct\n",
    "\n",
    "Hive is well suited for processing historical data in batches.       ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069cb0e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cdb484b9",
   "metadata": {},
   "source": [
    "Pros and Cons in Hive\n",
    "Select the option which is not an advantage of Hive.\n",
    "\n",
    "\n",
    "Queries data using a SQL-like language called HiveQL (HQL). \n",
    "\n",
    "\n",
    "Hive supports direct updates, deletes and overwriting or apprehending data.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3417399a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be7944fa",
   "metadata": {},
   "source": [
    "## Use Cases of Hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6139693e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64126218",
   "metadata": {},
   "source": [
    "Hive Feature\n",
    "Which of the following can best describe Hive?\n",
    "\n",
    "\n",
    "Hive is a job scheduler\n",
    "\n",
    "\n",
    "Data warehouse software   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76c7f01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a28e7a6",
   "metadata": {},
   "source": [
    "## Architecture of Hive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914a6675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99949d11",
   "metadata": {},
   "source": [
    "Hive Architecture: Metastore\n",
    "Now that you are aware that Metastore is an important component of Hive, what are its main functions? More than one option may be correct.\n",
    "\n",
    "\n",
    "Metastore stores information regarding the Hive tables in a central repository     ✓ Correct\n",
    "\n",
    "Metastore is highly essential for interpreting flat files stored in the HDFS as tables.     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba816aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f26890d",
   "metadata": {},
   "source": [
    "Hive QL Process Engine\n",
    "Which of the following statements describes the main function of the Hive QL Process Engine?\n",
    "\n",
    "\n",
    "It stores the schema of all the tables that you have defined in Hive.\n",
    "\n",
    "\n",
    "Instead of writing queries in Java, you can write the query in a language that is similar to SQL and process it.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce63fafc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c891eb85",
   "metadata": {},
   "source": [
    "Hive Architecture\n",
    "Consider the following statements and choose the correct one:\n",
    "\n",
    "Deleting the data or the schema from the Metastore also deletes the data from the HDFS.\n",
    "\n",
    "Using Metastore, you can create a schema or structured tables in the HDFS.\n",
    "\n",
    "The Hive Metastore stores each and every entry of the tables that you have called from HQL.\n",
    "\n",
    "\n",
    "1, 2\n",
    "\n",
    "\n",
    "2, 3\n",
    "\n",
    "\n",
    "1, 3\n",
    "\n",
    "\n",
    "None of the statements are true      ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1145fb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "782a4912",
   "metadata": {},
   "source": [
    "Hive Architecture\n",
    "Which of the following statements are correct?\n",
    "\n",
    "\n",
    "Hive works on the HDFS and all the Hive queries fetch the data directly from the HDFS.\n",
    "\n",
    "\n",
    "All the Hive queries are converted into MapReduce jobs in order to read the data from the HDFS. This job is performed by the Hive QL Process Engine.\n",
    "\n",
    "\n",
    "All the Hive queries are converted into MapReduce jobs in order to read the data from the HDFS. This job is performed by the Execution Engine.     ✓ Correct\n",
    "\n",
    "Hive Metastore provides information about the relational tables to the Hive QL Process Engine in order to read the data from the HDFS.     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7a837e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "942e7fe9",
   "metadata": {},
   "source": [
    "## Hive vs Relational Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bbe89b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57388276",
   "metadata": {},
   "source": [
    "Hive Vs RDBMS\n",
    "Based on your understanding of Hive and RDBMS, which of the following statements is correct:\n",
    "\n",
    "In Hive, you can delete or update/change the data from the HDFS multiple times.\n",
    "\n",
    "In RDBMS, you can only append the data but cannot delete or update it from the databases.\n",
    "\n",
    "\n",
    "1, 2\n",
    "\n",
    "\n",
    "Only 1\n",
    "\n",
    "\n",
    "only 2\n",
    "\n",
    "\n",
    "None of the above    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b5a071",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1f83a49",
   "metadata": {},
   "source": [
    "Hive Vs RDBMS\n",
    "Choose the correct statements from the options given below\n",
    "\n",
    "\n",
    "Hive is used to perform static data analysis, which means you cannot perform transactional level operations on Hive.     ✓ Correct\n",
    "\n",
    "In RDBMS, you can perform both OLTP and OLAP operations.     ✓ Correct\n",
    "\n",
    "In RDBMS, every time you want to read the data, you have to define the schema of the tables.\n",
    "\n",
    "\n",
    "Predefined schemas are available in the HDFS. All you need to do is read those schemas into the metastore and perform the query into the HDFS.\n",
    "\n",
    "\n",
    "Data integrity is essential in RDBMS systems.     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a1066e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85e8e51e",
   "metadata": {},
   "source": [
    "## Hive Data Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83465a10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23d78520",
   "metadata": {},
   "source": [
    "Characteristics of External Table\n",
    "Determine if the statement is True/False\n",
    "\n",
    "\"The metadata of the external table is not stored in Hive metastore and is instead stored in HDFS.\"\n",
    "\n",
    "\n",
    "True\n",
    "\n",
    "\n",
    "False    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f02d564",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "003d4549",
   "metadata": {},
   "source": [
    "Usage of Internal and External Table\n",
    "For an ad-hoc analysis, you will have to pull 50GB data from a data source. You will have to transform and process the data using Hive. After the analysis, the entire 50GB data is useless and can be deleted. Which table is well suited for such tasks.  \n",
    "\n",
    "\n",
    "Internal    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1a3487",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e95e00a8",
   "metadata": {},
   "source": [
    "## Data Types in Hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad30404d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b024e99a",
   "metadata": {},
   "source": [
    "Hive Data Types\n",
    "If you have gone through the additional reading then 29Y is\n",
    "\n",
    "\n",
    "SMALLINT\n",
    "\n",
    "\n",
    "BIGINT\n",
    "\n",
    "\n",
    "LONGINT\n",
    "\n",
    "\n",
    "TINYINT    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e1fcac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "067404b7",
   "metadata": {},
   "source": [
    "Hive String\n",
    "Hive supports which type of escaping within strings? (Please refer to the Strings section in the Additional reading page)\n",
    "\n",
    "\n",
    "L-Type\n",
    "\n",
    "C-Type   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09e7318",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9014f0b3",
   "metadata": {},
   "source": [
    "# Basic Hive Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324648c5",
   "metadata": {},
   "source": [
    "## Internal and External Tables I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fdb2fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7b6500e",
   "metadata": {},
   "source": [
    "Internal vs External Table\n",
    "Choose the correct statements from the options below.\n",
    "\n",
    "\n",
    "When you create an internal table, the table schema as well as the table data get stored in the Hive metastore.\n",
    "\n",
    "\n",
    "Only the table schema gets stored in the Hive metastore when you create an external table; the actual table data gets stored in the HDFS itself.    ✓ Correct\n",
    "\n",
    "When you create an internal table, the data gets stored in the HDFS itself.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f5adfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f79fd6b6",
   "metadata": {},
   "source": [
    "Table creation\n",
    "Suppose you defined a table as follows:\n",
    "\n",
    "create table if not exists user_info (id int, profession string, age int, gender string, reviews int) row format delimited fields terminated by ‘|’ lines terminated by ‘\\n’ stored as textfile ; \n",
    "The data is: Movies_Rating_Data \n",
    "\n",
    "Now, once you have written the above DDL statement, you load the data into the table that is created. Which of the following statements would be correct based on the above query?\n",
    "\n",
    "\n",
    "Hive will display an error message when you load the data.\n",
    "\n",
    "\n",
    "The ‘profession’ column will get the values of ‘age’ .    ✓ Correct\n",
    "\n",
    "The ‘age’ column will get NULL values.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bb0247",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "095d717e",
   "metadata": {},
   "source": [
    "## Internal and External Tables II\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cd7d20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d64f6da",
   "metadata": {},
   "source": [
    "Internal and External Tables\n",
    "Which of the following statements about dropping internal and external tables is correct?\n",
    "\n",
    "\n",
    "When you drop an internal table, both the metadata and the table data get deleted.     ✓ Correct\n",
    "\n",
    "When you drop an internal table, only the actual table data gets deleted from the HDFS; you can find the schema information of that table in the Hive metastore.\n",
    "\n",
    "\n",
    "When you drop an external table, only the schema gets deleted from the Hive metastore.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb010c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94033f14",
   "metadata": {},
   "source": [
    "Internal and External Tables\n",
    "Which of the following tables will be created if you do not specify any keyword such as “INTERNAL” or “EXTERNAL” while creating the table DDL statement?\n",
    "\n",
    "\n",
    "An Internal/managed table     ✓ Correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dd2cc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4cb1c71",
   "metadata": {},
   "source": [
    "Internal and External Tables\n",
    "Suppose you are the branch manager at a particular branch of a bank. You want to perform an analysis on your customers and want to find out those who have not paid their loan instalments for 6 months. You create a table of the customers, which contains information such as name, loan amount, date of payment of the last instalment, amount remaining, loan type, etc. Suppose this data is also relevant to the marketing team for contacting the customers for promoting various banking schemes.\n",
    "\n",
    "Based on the scenario above, which table type you would prefer creating?\n",
    "\n",
    "\n",
    "An Internal table\n",
    "\n",
    "\n",
    "An External table     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bb6e58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0baf2822",
   "metadata": {},
   "source": [
    "## Distribute By and Cluster By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b5d6e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52248f42",
   "metadata": {},
   "source": [
    "Sorting\n",
    "Choose the correct statement from the options given below:\n",
    "\n",
    "\n",
    "The SORT BY clause may use multiple reducers and provide the sorted data at the reducer level.   ✓ Correct\n",
    "\n",
    "The SORT BY clause uses only a single reducer and sorts the whole data.\n",
    "\n",
    "\n",
    "The ORDER BY clause does not guarantee the sorting of the total data.\n",
    "\n",
    "\n",
    "The ORDER BY clause guarantees the sorting of the total data.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72c9ab4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9338a63",
   "metadata": {},
   "source": [
    "Sorting\n",
    "Which of the following clauses does not sort the data but divides it into multiple reducers.\n",
    "\n",
    "\n",
    "SORT BY\n",
    "\n",
    "\n",
    "ORDER BY\n",
    "\n",
    "\n",
    "DISTRIBUTE BY     ✓ Correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3204cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce741504",
   "metadata": {},
   "source": [
    "Sorting\n",
    "Which of the following methods may provide overlapped data in the multiple reducers.\n",
    "\n",
    "\n",
    "ORDER BY\n",
    "\n",
    "\n",
    "SORT BY    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd5c815",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ae52ca1",
   "metadata": {},
   "source": [
    "## Indexing II\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1eebf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee5e5d7c",
   "metadata": {},
   "source": [
    "Indexing\n",
    "Choose the correct statement from the options given below:\n",
    "\n",
    "\n",
    "Indexing is great for write-heavy applications.\n",
    "\n",
    "\n",
    "Indexing is great for read-heavy applications         ✓ Correct\n",
    "\n",
    "You can assign a single index to a group of multiple columns         ✓ Correct\n",
    "\n",
    "Indexing reduces the latency of the queries         ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8604bb6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2cca1756",
   "metadata": {},
   "source": [
    "Indexing\n",
    "Which of the following statements is correct? You can refer to the following article on the types of indexing - Link\n",
    "\n",
    "A. Bitmap indexing stores the pair of indexed column’s value and its block id.\n",
    "\n",
    "B. Compact indexing stores the combination of indexed column value and list of rows as a bitmap.\n",
    "\n",
    "\n",
    "A\n",
    "\n",
    "\n",
    "B\n",
    "\n",
    "\n",
    "Both\n",
    "\n",
    "\n",
    "None of the above      ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f2cc14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b5429b7",
   "metadata": {},
   "source": [
    "## Practice Question\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227c63c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c429758",
   "metadata": {},
   "source": [
    "Order by\n",
    "In which year, an airport has maximum bookings?\n",
    "\n",
    "\n",
    "Airport: JAX, Year: 2001\n",
    "\n",
    "\n",
    "Airport: ORD, Year: 2004        ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a320604c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8927c6b5",
   "metadata": {},
   "source": [
    "Order by\n",
    "In which year the maximum airline bookings were cancelled?\n",
    "\n",
    "\n",
    "2008\n",
    "\n",
    "\n",
    "2002\n",
    "\n",
    "\n",
    "2005          ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4939a4ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6b3b7c3",
   "metadata": {},
   "source": [
    "Aggregation\n",
    "Choose the correct SQL query for finding the average of an early arrival (i.e. an average of negative values of “ArrDelay”) for the year 2008?\n",
    "\n",
    "\n",
    "SELECT avg(ArrTime) as avg_Arr_Time\n",
    "from airlines\n",
    "WHERE Year = 2008 and ArrDelay < 0;       ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5173d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93792566",
   "metadata": {},
   "source": [
    "Distance\n",
    "Which airports have minimum distance?\n",
    "\n",
    "\n",
    "Origin:OGG, Destination: PHX\n",
    "\n",
    "\n",
    "Origin:CLT, Destination:RDU\n",
    "\n",
    "\n",
    "Origin:PHL, Destination:BWI\n",
    "\n",
    "\n",
    "Origin: STT,\tDestination: SJU        ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83207b06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e61e95c",
   "metadata": {},
   "source": [
    "Delay\n",
    "Which flight(ID) get late to depart due to weather and waited for 6.35 hours?\n",
    "\n",
    "\n",
    "1901\n",
    "\n",
    "\n",
    "555     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed4bd4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20672a75",
   "metadata": {},
   "source": [
    "Flight Bookings\n",
    "What is the count of bookings in 2004, for flight number 749?\n",
    "\n",
    "\n",
    "121\n",
    "\n",
    "\n",
    "112    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ebae0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2e3e4be",
   "metadata": {},
   "source": [
    "# Advanced Hive Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2ea00f",
   "metadata": {},
   "source": [
    "## Static Partitioning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f741a6ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cfcd4835",
   "metadata": {},
   "source": [
    "Partitioning\n",
    "Consider a table has a column 'year', which includes the years from 2001 to 2010. Now, suppose you create partitions on the 'year' column. How many partitions will be created when you use static partitioning?\n",
    "\n",
    "\n",
    "A total of 10 partitions will be created in which you have to put the data manually.\n",
    "\n",
    "\n",
    "If you put data for only 2005 and 2006 manually in static partitioning, then only two partitions will be created.    ✓ Correct\n",
    "\n",
    "If a new year is included in the list, say 2011, then in static partitioning, a new partition will be created automatically.\n",
    "\n",
    "\n",
    "If a new year is included in the list, say 2011, then unless you enter the data manually in the 2011 partition, no data will be allocated automatically.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe214d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5519f338",
   "metadata": {},
   "source": [
    "Partitioning\n",
    "Which type of partitioning is allowed by default in Hive?\n",
    "\n",
    "\n",
    "Static partitioning     ✓ Correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e4ba91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b307b361",
   "metadata": {},
   "source": [
    "Partitioning\n",
    "Select the correct statement below.\n",
    "\n",
    "\n",
    "In static partitioning, suppose you create partitions for a doctor, an engineer and an artist as demonstrated in the above videos. Then, it will create folders for all the professions in Hadoop, but the data will go only into the defined folders of doctor, engineer and artist.\n",
    "\n",
    "\n",
    "In static partitioning, suppose you create partitions for a doctor, an engineer and an artist as demonstrated in the above videos. Then, it will create files for all the professions in Hadoop, but the data will go only into the defined files of doctor, engineer and artist.\n",
    "\n",
    "\n",
    "In static partitioning, suppose you create partitions for a doctor, an engineer and an artist as demonstrated in the above videos. Then, it will create three folders in Hadoop to store such partitions.      ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47dfdc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "862f1635",
   "metadata": {},
   "source": [
    "## Practice Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66af234a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17ad9baa",
   "metadata": {},
   "source": [
    "01 Partitioning Key\n",
    "Which of the following columns should you not use as a partition key? (Note: More than one option may be correct.)\n",
    "\n",
    "\n",
    "DepTime     ✓ Correct\n",
    "\n",
    "Month\n",
    "\n",
    "\n",
    "TaxiIn    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f7c10e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d8fee32",
   "metadata": {},
   "source": [
    "02 Partitioning\n",
    "How many partitions will be created when you use 'Year' as a partition key in the dynamic partition?\n",
    "\n",
    "\n",
    "12\n",
    "\n",
    "\n",
    "6\n",
    "\n",
    "\n",
    "5         ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d14ec20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af1eca45",
   "metadata": {},
   "source": [
    "03 Bucketing\n",
    "Let’s say you created partitions using 'FlightNum' as the partition key. You notice that even after partitioning, queries such as ‘fetch the flight history of a particular FlightNum’, which you need to write very often, are too slow. Which one of the options given below will help you make such queries faster?\n",
    "\n",
    "\n",
    "Create another level of partitioning using ‘Year’ as the key.\n",
    "\n",
    "\n",
    "Create about 50 buckets using the column ‘Entry_id'.\n",
    "\n",
    "✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8ac979",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42df6101",
   "metadata": {},
   "source": [
    "04 Bucketing\n",
    "Suppose you have created 50 buckets using the column ‘Entry_id’. Now, as the database grows with time, which one of the results below will you see?\n",
    "\n",
    "\n",
    "The number of buckets will increase automatically to create space for additional entries.\n",
    "\n",
    "\n",
    "Both the number of buckets and the entries in each bucket will increase automatically.\n",
    "\n",
    "\n",
    "The number of entries in each bucket will increase automatically. But the number of buckets will remain the same.\n",
    "\n",
    "✓ Correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17856d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b250936",
   "metadata": {},
   "source": [
    "05 Querying in Hive\n",
    "Which year has the maximum average taxi-out time, and what is its value?\n",
    "\n",
    "\n",
    "2004, 18.5         ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021fafc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23566e6f",
   "metadata": {},
   "source": [
    "06 Querying in Hive\n",
    "If you explore the data, you will find that there are some negative values in the 'ArrDelay' column, which signifies that the flight had arrived before time on that day. What will be the average of an early arrival (i.e., the average of the negative values of 'ArrDelay') for the year 2008?\n",
    "\n",
    "\n",
    "10.79 min\n",
    "\n",
    "\n",
    "8.08 min\n",
    "\n",
    "\n",
    "9.53 min\n",
    "\n",
    "\n",
    "9.08 min     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cc6108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c2740a2",
   "metadata": {},
   "source": [
    "07 Querying in Hive\n",
    "Consider the following statement:\n",
    "\n",
    "Bucketing does not ensure that the table is properly populated. Hence, to ensure uniformity of data in each bucket, you need to load the data manually.\n",
    "\n",
    "Is this statement true or false?\n",
    "\n",
    "\n",
    "True    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b575b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50b65754",
   "metadata": {},
   "source": [
    "08 Querying in Hive\n",
    "Suppose you want to partition the 'Airlines' data using 'Year' as the partition key, bucket it into seven buckets by 'DayofWeek', and sort each bucket in ascending order of 'Distance'. What will be the right code to do this operation?\n",
    "\n",
    "\n",
    "CREATE TABLE airlines_bucketed(\n",
    "-- Information about the data types of each columns\n",
    ")\n",
    "SORTED BY (Distance) INTO 7 BUCKETS\n",
    "CLUSTERED BY (DayofWeek) \n",
    "PARTITIONED BY (Year int)\n",
    "STORED AS SEQUENCEFILE;\n",
    "\n",
    "CREATE TABLE airlines_bucketed(\n",
    "-- Information about the data types of each columns\n",
    ")\n",
    "CLUSTERED BY (DayofWeek) SORTED BY (Distance) INTO 7 BUCKETS\n",
    "PARTITIONED BY (Year int)\n",
    "STORED AS SEQUENCEFILE;\n",
    "\n",
    "CREATE TABLE airlines_bucketed(\n",
    "-- Information about the data types of each columns\n",
    ")\n",
    "PARTITIONED BY (Year int)\n",
    "SORTED BY (Distance) INTO 7 BUCKETS\n",
    "CLUSTERED BY (DayofWeek)\n",
    "STORED AS SEQUENCEFILE;\n",
    "\n",
    "CREATE TABLE airlines_bucketed(\n",
    "-- Information about the data types of each columns\n",
    ")\n",
    "PARTITIONED BY (Year int)\n",
    "CLUSTERED BY (DayofWeek) SORTED BY (Distance) INTO 7 BUCKETS\n",
    "STORED AS SEQUENCEFILE;                                               ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32285482",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ad1cd0f",
   "metadata": {},
   "source": [
    "09 Querying in Hive\n",
    "What is the count of the diverted flights that flew on Fridays in the year 2005?\n",
    "\n",
    "\n",
    "3\n",
    "\n",
    "\n",
    "7    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5115ca0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d823d436",
   "metadata": {},
   "source": [
    "10 Partition Query\n",
    "Choose correct syntax for finding count of partitioned table will be created if you partitioned the table on \"year\" for airlines data set\n",
    "\n",
    "\n",
    "SELECT year , count(distinct Year) as unique_years\n",
    "from airlines_partitioned group by year, count(*);\n",
    "\n",
    "SELECT distinct (count (Year)) as unique_years\n",
    "from airlines_partitioned;\n",
    "\n",
    "SELECT count(distinct Year) as unique_years\n",
    "from airlines_partitioned;                 ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fe73d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9178bcdc",
   "metadata": {},
   "source": [
    "# Data Analysis using Hive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f574b221",
   "metadata": {},
   "source": [
    "## Practice Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbd8101",
   "metadata": {},
   "source": [
    "01 Second Highest\n",
    "Which product has the second-highest review?\n",
    "\n",
    "\n",
    "B003ES5ZUU     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f132ddfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be4c2c57",
   "metadata": {},
   "source": [
    "02 Helpful Rate\n",
    "What is the fourth-maximum count of the product review on the basis of the helpful rating?\n",
    "\n",
    "\n",
    "637.49\n",
    "\n",
    "\n",
    "637.477\n",
    "\n",
    "\n",
    "637.479           ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb09015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f42f37a",
   "metadata": {},
   "source": [
    "03 Partition\n",
    "Why did we use only the Year & Month columns for partitioning? \n",
    "\n",
    "\n",
    "High Cardinality\n",
    "\n",
    "\n",
    "Less Cardinality      ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f7f88f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d9a7315",
   "metadata": {},
   "source": [
    "04 Word count\n",
    "In reviewText column, what is the count of the occurrences of the word 'my'?\n",
    "\n",
    "\n",
    "1937891\n",
    "\n",
    "\n",
    "1938791        ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdff075",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c2c98cf",
   "metadata": {},
   "source": [
    "05 Word count\n",
    "Which of the following word has the maximum count in reviewtext column?\n",
    "\n",
    "\n",
    "the      ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44cd546",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2b9a849",
   "metadata": {},
   "source": [
    "06 Ranking\n",
    "On the month of Feb and the year 2006, which 'overall rating' has the third-highest count?\n",
    "\n",
    "\n",
    "1\n",
    "\n",
    "\n",
    "2\n",
    "\n",
    "\n",
    "3    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a37af3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "253887d8",
   "metadata": {},
   "source": [
    "# Graded Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ba29de",
   "metadata": {},
   "source": [
    "## Graded Questions I\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d79797",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09a19ccf",
   "metadata": {},
   "source": [
    "1 Introduction to Hive\n",
    "Which of the following is not one of the features of Hive?\n",
    "\n",
    "\n",
    "Hive stores the processed data in HDFS and the schema in the Hive Metastore.\n",
    "\n",
    "\n",
    "The Hive infrastructure provides an SQL-like query language called the Hive Query Language.\n",
    "\n",
    "\n",
    "The Hive infrastructure consists of a metastore storage, which stores information about the data, including the schema and location of the data. This metastore is created in the HDFS system itself.        ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a53e85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05b6dd90",
   "metadata": {},
   "source": [
    "2 Hive vs RDBMS\n",
    "Which of the following statements is correct about Hive and the RDBMS infrastructure? \n",
    "\n",
    "\n",
    "Hive enables us to write into the HDFS.\n",
    "\n",
    "\n",
    "We cannot write to the HDFS using Hive. Only the append feature is supported in the Hive infrastructure.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4354ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eec8f047",
   "metadata": {},
   "source": [
    "3 Hive\n",
    "Select the correct statement from the following based on the fact that “Hive works upon schema on read”. (Note: Multiple options may be correct.)\n",
    "\n",
    "\n",
    "Data of varying sizes and shapes is dumped into the HDFS and can be retrieved by creating the schema according to the requirement.      ✓ Correct\n",
    "\n",
    "Information on the schema is available in the HDFS when you are dumping data into the HDFS.\n",
    "\n",
    "\n",
    "The schema is created when data is required for a particular purpose. It is called a schema on read because the schema is defined at the time of reading the data.      ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d06f01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4fc9456",
   "metadata": {},
   "source": [
    "4 Internal and External Tables\n",
    "Select the correct statement about internal and external tables. (Note: Multiple options may be correct.)\n",
    "\n",
    "\n",
    "When you drop an internal table in Hive, it simply deletes the metadata information as well as the table data.     ✓ Correct\n",
    "\n",
    "When you drop an external table, it drops the metadata information of that table; it does not touch the table data at all. This means that it keeps the table data present in the HDFS untouched, but Hive is ignorant of that data now.     ✓ Correct\n",
    "\n",
    "The data of both the internal and external tables is moved into the Hive Metastore.\n",
    "\n",
    "\n",
    "'Internal tables’ data is stored in the Hive warehouse directory.     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dd7c51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4eeffd13",
   "metadata": {},
   "source": [
    "5 Data Types in Hive\n",
    "Which of the following data type is not supported in Hive:\n",
    "\n",
    "\n",
    "timestamp\n",
    "\n",
    "\n",
    "enum     ✓ Correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb8311d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c27cffb6",
   "metadata": {},
   "source": [
    "6 HQL\n",
    "Identify the correct statement below.\n",
    "\n",
    "\n",
    "Hive is optimized for row-level insert/delete/update operations\n",
    "\n",
    "\n",
    "A Hive table can be renamed using the ALTER TABLE <table name> RENAME TO <new table name> statement     ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c06fd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bacbf47d",
   "metadata": {},
   "source": [
    "## Graded Questions-II\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dced6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8be877b0",
   "metadata": {},
   "source": [
    "7 Hive Graded Questions\n",
    "Select the appropriate query to create an external table named OrderDelivery.\n",
    "\n",
    "\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS OrderDelivery(\n",
    "OrderID VARCHAR(6),\n",
    "CustomerID VARCHAR(7),\n",
    "Details  MAP<VARCHAR(5), INT>,\n",
    "CustomerName  STRING,\n",
    "HouseNo INT,\n",
    "Street STRING,\n",
    "City STRING,\n",
    "State STRING,\n",
    "PostalCode VARCHAR(8))\n",
    "ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY ','\n",
    "COLLECTION ITEMS TERMINATED BY '#'\n",
    "MAP KEYS TERMINATED BY '|'\n",
    "LINES TERMINATED BY '\\n'\n",
    "STORED AS TEXTFILE;                           ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc880c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c42a774",
   "metadata": {},
   "source": [
    "8 Hive Graded Questions\n",
    "Given that data is available at location “/test/iceCreamOrders” in multiple files, select the query to point the “OrderDelivery” table to the correct data files.\n",
    "\n",
    "\n",
    "ALTER TABLE OrderDelivery SET LOCATION ‘/test/iceCreamOrders/’;          ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d5f461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd158b29",
   "metadata": {},
   "source": [
    "9 Hive Graded Questions\n",
    "Out of the listed columns, identify the one suitable for bucketing:\n",
    "\n",
    "\n",
    "City\n",
    "\n",
    "\n",
    "Customer ID\n",
    "\n",
    "\n",
    "Order ID    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58606fc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d492075",
   "metadata": {},
   "source": [
    "10 Hive Graded Questions\n",
    "Consider that the data is specifically used to address delivery issues and also promote delivery offers in the different cities. For such a use case, out of the listed pairs, identify the suitable combination and order for partitioning to improve query performance.\n",
    "\n",
    "\n",
    "Postal Code, State\n",
    "\n",
    "\n",
    "City, State\n",
    "\n",
    "\n",
    "State, City    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2541e092",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d86cb82a",
   "metadata": {},
   "source": [
    "# Traditional Warehouse Vs. Amazon Redshift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e6856b",
   "metadata": {},
   "source": [
    "## Recap: Data Warehousing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59446fb",
   "metadata": {},
   "source": [
    "OLTP\n",
    "Which of the following strategies are followed by OLTP (relational databases) systems for a large database?\n",
    "\n",
    "\n",
    "Normalisation   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af54cd70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c71053d5",
   "metadata": {},
   "source": [
    "Big Data\n",
    "Why do we need specialised Big Data storing/processing tools in the first place?\n",
    "\n",
    "\n",
    "To provide more security to data\n",
    "\n",
    "\n",
    "To store a bulk amount of data    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2974e95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0bed3ab",
   "metadata": {},
   "source": [
    "## On-Premise vs Cloud Data Warehouses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9377f9f",
   "metadata": {},
   "source": [
    "Fill in the blank\n",
    "Data warehouse databases use a different type of architecture both from a ________ perspective and ________layer.\n",
    "\n",
    "\n",
    "End-user, administrativ   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b908b24b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0405f62f",
   "metadata": {},
   "source": [
    "Not a kind\n",
    "A data warehouse is NOT used for?\n",
    "\n",
    "\n",
    "Transaction Processing   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c795cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30c8abc2",
   "metadata": {},
   "source": [
    "## Why Amazon Redshift?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1b20b5",
   "metadata": {},
   "source": [
    "Redshift Origin\n",
    "Redshift is a customised form of which database?\n",
    "\n",
    "\n",
    "PostgreSQL  ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a178fc96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43064208",
   "metadata": {},
   "source": [
    "Redshift Database Service\n",
    "Amazon Redshift is a _________database service.\n",
    "\n",
    "\n",
    "Relational   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f638cb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3dfd2964",
   "metadata": {},
   "source": [
    "Scaling Redshift\n",
    "Why Amazon Redshift using concurrency scaling?\n",
    "\n",
    "\n",
    "To increase workload\n",
    "\n",
    "\n",
    "To increase performance   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cba09d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15809ae2",
   "metadata": {},
   "source": [
    "Integration with Redshift\n",
    "Which type of tool can be integrated with Redshift?\n",
    "\n",
    "\n",
    "Artificial Intelligence\n",
    "\n",
    "\n",
    "Business Intelligence   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7e571f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83e139fa",
   "metadata": {},
   "source": [
    "# Redshift: Introduction and Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca182323",
   "metadata": {},
   "source": [
    "## Introduction to Amazon Redshift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6a37fc",
   "metadata": {},
   "source": [
    "Redshift Architecture\n",
    "What are the key reasons for choosing a data warehouse solution such as Redshift?\n",
    "(Note: More than one option may be correct.)\n",
    "\n",
    "\n",
    "High volume   ✓ Correct\n",
    "\n",
    "Supports stored procedures   ✓ Correct\n",
    "\n",
    "Massive parallel processing   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9df1ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a76839d3",
   "metadata": {},
   "source": [
    "Redshift Performance\n",
    "Which of the following features is/are the reason(s) for Redshift’s fast performance?\n",
    "\n",
    "\n",
    "Columnar data stores\n",
    "\n",
    "\n",
    "Massively Parallel processing (MPP)\n",
    "\n",
    "\n",
    "Data compression\n",
    "\n",
    "\n",
    "All of the above  ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d56abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c934413d",
   "metadata": {},
   "source": [
    "Redshift Feature\n",
    "Which feature was added by Amazon to Postgres, so that it will become a cloud-based data warehouse?\n",
    "\n",
    "\n",
    "Infrastructure as a Service (IaaS)\n",
    "\n",
    "\n",
    "Software as a Service (SaaS)\n",
    "\n",
    "\n",
    "Platform as a Service (PaaS)   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b44e622",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "214926df",
   "metadata": {},
   "source": [
    "## Redshift Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9e109c",
   "metadata": {},
   "source": [
    "Redshift Architecture\n",
    "Which of the following nodes is responsible for managing client connections?\n",
    "\n",
    "\n",
    "Client node\n",
    "\n",
    "\n",
    "Leader node  ✓ Correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90236cd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7fdda57a",
   "metadata": {},
   "source": [
    "Redshift Architecture\n",
    "Select the correct statement from below.\n",
    "\n",
    "\n",
    "The leader node computes and executes queries and compute nodes calculate these queries.\n",
    "\n",
    "\n",
    "The leader node handles connections, &  compute nodes stores data and performs calculations.   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbb7c33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e75f0a77",
   "metadata": {},
   "source": [
    "Connection\n",
    "How do the end-users applications connect with Redshift? \n",
    " \n",
    "\n",
    "\n",
    "Spring DAO\n",
    "\n",
    "\n",
    "ODBC  ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfc7320",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "144dc2eb",
   "metadata": {},
   "source": [
    "## Key Performance Features of Redshift\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd879fb6",
   "metadata": {},
   "source": [
    "Key Performance Features of Redshift\n",
    "Why is Redshift built with columnar based storage and not row-based storage?\n",
    "\n",
    "\n",
    "It optimises hardware.\n",
    "\n",
    "\n",
    "It gives proficiency in queries.\n",
    "\n",
    "\n",
    "It is the only way for Redshift.\n",
    "\n",
    "\n",
    "It reduces disk I/O for analytical queries.  ✓ Correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4366e638",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "734255c2",
   "metadata": {},
   "source": [
    "Columnar Database\n",
    "A columnar database is best suited for _________ \n",
    "\n",
    "\n",
    "Transactional processing\n",
    "\n",
    "\n",
    "Analytical query processing   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6812f37c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c1b67cc",
   "metadata": {},
   "source": [
    "## SORT Key II & ZONE Maps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc9aa21",
   "metadata": {},
   "source": [
    "Sort Keys\n",
    "Which of the following is the default Sort key type in Amazon Redshift?\n",
    "\n",
    "\n",
    "Compound sort key  ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d18b2a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d607ee81",
   "metadata": {},
   "source": [
    "Fill in the blank.\n",
    "______________sort key gives equal weightage to each column.\n",
    "\n",
    "\n",
    "Compound\n",
    "\n",
    "\n",
    "Interleaved  ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88b1f2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3113e09a",
   "metadata": {},
   "source": [
    "System Table\n",
    "Which of the following system tables contains information about the Sort key?\n",
    "Note: Please go through this Additional Reading link to answer this question. \n",
    "\n",
    "\n",
    "ALL_OBJ_TABLE\n",
    "\n",
    "\n",
    "CONST_KEY_TABLE\n",
    "\n",
    "\n",
    "SVV_TABLE_INFO  ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecc57f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67f0ec4c",
   "metadata": {},
   "source": [
    "Sort key\n",
    "Which of the following types of the column will be the most efficient when it comes to choosing one as the SORT key? \n",
    "\n",
    "\n",
    "TIMESTAMP ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8524e24b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d25aa318",
   "metadata": {},
   "source": [
    "## Data Distribution: DIST Key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c80568e",
   "metadata": {},
   "source": [
    "Distribution Key\n",
    "Select the condition for using the EVEN distribution key from below.\n",
    "\n",
    "\n",
    "Tables should not participate in Joins. ✓ Correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866dd6d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df935f8b",
   "metadata": {},
   "source": [
    "Distribution Key\n",
    "What are the conditions for choosing DISTKEY/SORTKEY?\n",
    "\n",
    "\n",
    "The nature of data\n",
    "\n",
    "\n",
    "The nature of the query\n",
    "\n",
    "\n",
    "Both (A) and (B)  ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efc1160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b044c60",
   "metadata": {},
   "source": [
    "# Redshift Administration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309561bd",
   "metadata": {},
   "source": [
    "## Redshift Cluster: Node Types & Maintenance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe842b3",
   "metadata": {},
   "source": [
    "Redshift Cluster\n",
    "What is the default port of Redshift Database cluster?\n",
    "\n",
    "\n",
    "5431\n",
    "\n",
    "\n",
    "5432\n",
    "\n",
    "\n",
    "5439  ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07f5dd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "857c666a",
   "metadata": {},
   "source": [
    "Redshift Cluster\n",
    "If you have selected the dc2.large(Take the hourly rates for this instance type as 0.25$ per hour) as a node type and created a two-node Redshift cluster, then what will be the cost for a year. \n",
    "Consider the region as US East (N. Virginia)\n",
    "\n",
    "$4380 ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf1d569",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "469b98ce",
   "metadata": {},
   "source": [
    "## Workload Management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacce643",
   "metadata": {},
   "source": [
    "Redshift WLM\n",
    "Workload of the compute nodes can be configured using __________________\n",
    "\n",
    "\n",
    "Workload Management  ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba5bbcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5357c59d",
   "metadata": {},
   "source": [
    "Redshift WLM\n",
    "What does Automatic Workload Management do? Select from the following options:\n",
    "\n",
    "\n",
    "Automatically pauses cluster after a certain period of time\n",
    "\n",
    "\n",
    "Automatically cleans all caches from Redshift memory\n",
    "\n",
    "\n",
    "Automatically calculates the percentage of memory assign to the default queue  ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59509b70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b05efdb",
   "metadata": {},
   "source": [
    "Redshift WLM\n",
    "Which node is best for performance-intensive workloads?\n",
    "\n",
    "\n",
    "Dense Leader Node\n",
    "\n",
    "\n",
    "Dense Cluster Node\n",
    "\n",
    "\n",
    "Dense Storage Node\n",
    "\n",
    "\n",
    "Dense Compute Node  ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b90c2e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2b1feac",
   "metadata": {},
   "source": [
    "## Fault Tolerance and Security"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557561e6",
   "metadata": {},
   "source": [
    "Feature\n",
    "Which of the following node types would you suggest to store the data for the use case having data growing rapidly day by day?\n",
    "\n",
    "\n",
    "RA3   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6915ae8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "709ffd1e",
   "metadata": {},
   "source": [
    "Feature\n",
    "Your company is currently using Oracle database and you will get a bulk amount of blob type data daily. This is very tough to handle in a traditional data warehouse. So, as a solution architect, you proposed Amazon Redshift to your organisation which is fully scalable, offers robust query performance and is cost-effective. Why did you choose Redshift?\n",
    "\n",
    "\n",
    "Redshift built on top of Postgres which is helpful to Oracle developers for easy adaption.  ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324e9afc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5fbeb3d5",
   "metadata": {},
   "source": [
    "Workload Management\n",
    "One of the queries you are running on a Redshift cluster needs more resources to run. What is the correct way to allocate more resources to a query?\n",
    "Note: Please go through this additional reading link before answering this question. \n",
    "\n",
    "\n",
    "Set wlm_query_slot_count to 3;  ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22944351",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7bc0762",
   "metadata": {},
   "source": [
    "# Redshift Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f460592",
   "metadata": {},
   "source": [
    "## Getting Started With Redshift Queries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dc4621",
   "metadata": {},
   "source": [
    "Primary key\n",
    "Does Redshift have a primary key and foreign key constraints?\n",
    " \n",
    "\n",
    "\n",
    "Yes\n",
    "\n",
    "\n",
    "No ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7137359c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9b57753",
   "metadata": {},
   "source": [
    "Schema\n",
    "Suppose you are a database developer and have good experience in Redshift. Now a task is assigned to you to find a schema of a table from Redshift Database cluster. That table name is finscheduledetail under schema finance. Select possible option(s) for correct query.\n",
    "\n",
    "\n",
    "select * from information_schema.columns where table_name='finscheduledetail'\n",
    "And table_schema='finance'   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc0621b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1ee0254",
   "metadata": {},
   "source": [
    "## Loading Data Into Redshift Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e08d238",
   "metadata": {},
   "source": [
    "Copy Command\n",
    "Suppose a table named student is present in a Redshift cluster inside a schema named school. You have been asked to load data into this student table from a 10GB text file present in a S3 bucket. Which of the following formats of the Copy command will you be making use of? Note: We don't know the format of the text file.\n",
    "\n",
    "\n",
    "copy student from “s3://<path>” iam_role ‘<roleid> ‘ delimiter ‘|’ region ‘us-east-1’;\n",
    "\n",
    "\n",
    "copy student from “s3://<path>” iam_role ‘<roleid> ‘ delimiter ‘,’ region ‘us-east-1’;\n",
    "\n",
    "\n",
    "copy school.student from “s3://<path>” iam_role ‘<roleid> ‘ delimiter ‘|’ region ‘us-east-1’;\n",
    "\n",
    "\n",
    "Inadequate information   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6dd305",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef0a16a5",
   "metadata": {},
   "source": [
    "Copy Command\n",
    "Does CSV or TSV file formats provide significant performance improvements while using the Copy command?\n",
    "\n",
    "\n",
    "Yes\n",
    "\n",
    "\n",
    "No   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d998f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0472ea09",
   "metadata": {},
   "source": [
    "COPY Command\n",
    "Should the number of input files to COPY command always be in the multiple of the number of node slices?\n",
    "\n",
    "Consider an optimal case. \n",
    "\n",
    "\n",
    "Yes   ✓ Correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a1f4e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1035071f",
   "metadata": {},
   "source": [
    "Data Loading\n",
    "Your daily activity is to monitor the COPY command which is loading data into your Redshift database cluster and to provide analytic insights.  During a routine monitoring exercise suppose you have found one of the COPY commands showing success but data is not present in the respective table. What is/are the possible reason/s?\n",
    " \n",
    "\n",
    "\n",
    "IAM role associated with your Redshift cluster has invalid policy attached    ✓ Correct\n",
    "\n",
    "S3 bucket name may be incorrect at policy    ✓ Correct\n",
    "\n",
    "File which you have mentioning in COPY command is not available at S3 bucket    ✓ Correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c048cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fffd316f",
   "metadata": {},
   "source": [
    "# Practice Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969d9d53",
   "metadata": {},
   "source": [
    "Q1 Age-group\n",
    "How many people are suspected of COVID-19 and belong to the 20-49 year age group?\n",
    "\n",
    "\n",
    "62.14 %  ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb429dc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e01cdaea",
   "metadata": {},
   "source": [
    "Q2 Maximum Case\n",
    "Which state has the maximum confirmed case of COVID-19?\n",
    "\n",
    "\n",
    "Delhi\n",
    "\n",
    "\n",
    "Maharashtra  ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baa6e4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73844a14",
   "metadata": {},
   "source": [
    "Q3 Individual Details\n",
    "According to our data set, how many people have travelled from Wuhan to India and got recovered from COVID-19?\n",
    "\n",
    "\n",
    "3  ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396742fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7218311c",
   "metadata": {},
   "source": [
    "Q4 Death Count\n",
    "Which state has the second maximum death count?\n",
    "\n",
    "\n",
    "Telangana\n",
    "\n",
    "\n",
    "Uttar Pradesh\n",
    "\n",
    "\n",
    "Delhi  ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9662fce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6411c9b0",
   "metadata": {},
   "source": [
    "Q5 Recovered\n",
    "How many people recovered whose age is equal to 55?\n",
    "\n",
    "\n",
    "21\n",
    "\n",
    "\n",
    "15\n",
    "\n",
    "\n",
    "10\n",
    "\n",
    "\n",
    "12  ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e127c7e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "657365cf",
   "metadata": {},
   "source": [
    "Q6 State Cure Count\n",
    "Which State has cured the minimum number of people?\n",
    "\n",
    "\n",
    "Dadra & Nagar Haveli \n",
    "\n",
    "\n",
    "Sikkim   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12da18cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fcd535ea",
   "metadata": {},
   "source": [
    "# Advanced Features and Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a72d3a",
   "metadata": {},
   "source": [
    "## Redshift Spectrum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f372ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2d7be7f",
   "metadata": {},
   "source": [
    "Redshift Spectrum\n",
    "Redshift spectrum layer query the data which is present on ____________________\n",
    "\n",
    "\n",
    "Simple Storage Service(Amazon S3)  ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c35c6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "486123d0",
   "metadata": {},
   "source": [
    "File Format\n",
    "Which one of the following file formats is NOT supported by Redshift Spectrum?\n",
    "\n",
    "\n",
    "CSV\n",
    "\n",
    "\n",
    "TIFF ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f535345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f5f9232",
   "metadata": {},
   "source": [
    "Redshift Query\n",
    "What is the maximum size of a file for processing by Redshift Spectrum in Amazon S3?\n",
    "\n",
    "\n",
    "Exabyte ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487d0a3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d723c1e",
   "metadata": {},
   "source": [
    "Redshift Spectrum\n",
    "Your company is using an on-premise data warehouse and wants to move to AWS. They have 10 years of data (about 2 Petabytes) currently. They have complex analytical dashboards which queries most recent 1-year data. Though they should be able query data older than 1-year as well (very rarely). What solution would you recommend?\n",
    "\n",
    "\n",
    "Migrate all data to Amazon S3. Query all data using Athena \n",
    "\n",
    "\n",
    "Migrate the data to Amazon S3. Move the latest 1-year data into the Amazon Redshift cluster and use it for analysis. For older data, use Amazon Redshift Spectrum to query data which is present on S3. ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1f8912",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f21f8c1",
   "metadata": {},
   "source": [
    "## RA3 and AQUA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba63c44",
   "metadata": {},
   "source": [
    "AQUA\n",
    "In AQUA, cache is_________________.\n",
    " \n",
    "\n",
    "\n",
    "Distributed   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb677cf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dbd040bf",
   "metadata": {},
   "source": [
    "AQUA\n",
    "How does AQUA boost the performance of queries while executing in the Redshift cluster?\n",
    "\n",
    "\n",
    "Using hardware-accelerated cache\n",
    "\n",
    "\n",
    "Using distributed cache\n",
    "\n",
    "\n",
    "Using distributed and hardware-accelerated cache  ✓ Correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2977a038",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2828a182",
   "metadata": {},
   "source": [
    "AQUA\n",
    "AQUA provides additional boosting performance to query execution. Which of the following types of disk drive is recommended for storing & querying bulk amounts of data in Redshift cluster?\n",
    "\n",
    "\n",
    "HDD\n",
    "\n",
    "\n",
    "SSD   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068cab56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9cd0afcc",
   "metadata": {},
   "source": [
    "AQUA\n",
    "You are managing a Redshift cluster with one database which is being used by multiple teams within an organization. Currently, all tables/views reside in the public schema. Over time, the data has become cluttered and you have received a lot of complaints from some teams that some other team deleted their data. \n",
    "\n",
    "What is the quickest and cost-efficient to implement governance around the data, such that one team cannot access data that belongs to another team?\n",
    " \n",
    "\n",
    "\n",
    "Create separate WLM queues for different teams\n",
    "\n",
    "\n",
    "Create separate schemas for each team   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448f59a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b5fc985",
   "metadata": {},
   "source": [
    "# Graded Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c54d362",
   "metadata": {},
   "source": [
    "Q1 COPY command\n",
    "You are working for a Pharma company which receives data from multiple external vendors for processing. You are receiving the data in large files (several GBs) stored on S3. Each night, COPY command runs to load data into a 5-node DC2.large Redshift cluster. You found that the COPY command is taking a long time to complete.\n",
    "\n",
    "How would you optimise the data load process?\n",
    "\n",
    "\n",
    "Split the data files into 1 GB each, compress them and load them using a COPY command with GZIP   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f97b68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f77a6f7",
   "metadata": {},
   "source": [
    "Q2 Redshift Query Optimisation\n",
    "The Redshift cluster you are managing for your company has a variety of workloads. There are users who run long, complex analytical queries as well as some automated jobs which run short, read-only queries. You are observing that during high workload, these short-running queries are timing out and the related jobs are failing.\n",
    "Which solution is the simplest one to remediate this problem?\n",
    " \n",
    "\n",
    "\n",
    "Use automated Workload Management with concurrency scaling\n",
    "\n",
    "\n",
    "Add more nodes to your Redshift cluster using Elastic Resize\n",
    "\n",
    "\n",
    "Use manual Workload Management with concurrency scaling\n",
    "\n",
    "\n",
    "Use Short Query Acceleration   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2268e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a31ce17",
   "metadata": {},
   "source": [
    "Q3 DW Use Case\n",
    "You have large volumes of structured data in the form of comma-delimited (CSV) files on your on-premise shared storage drive. You have been asked to migrate the data to AWS. The data must be queried using standard SQL. \n",
    "\n",
    "Which solution will meet the requirements?\n",
    " \n",
    "\n",
    "\n",
    "Use COPY command to load data in parallel into Hive on an EMR cluster from S3\n",
    "\n",
    "\n",
    "Use INSERT command to load data in parallel into Redshift cluster from S3\n",
    "\n",
    "\n",
    "Use COPY command to load in parallel into Redshift cluster from S3   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab2dbf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31282403",
   "metadata": {},
   "source": [
    "Q4 Monitoring Redshift\n",
    "You are managing the Redshift database for a company and you have a requirement to set up monitoring on the Redshift cluster and send email notifications whenever the CPU Utilization for your cluster crosses 90%. \n",
    "\n",
    "Which of the following services would you use to meet this requirement? \n",
    "\n",
    "\n",
    "Amazon CloudWatch   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497c78ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "324718b1",
   "metadata": {},
   "source": [
    "Q5 Redshift Performance\n",
    "You are working for an insurance company which uses 3-node DS2.XLARGE Redshift cluster to store claims data. There are some BI dashboards which query this data and show some key metrics such as total claim value and the number of claims. These dashboards are updated every hour through SQL queries. There is also a group of data scientists who query the database intermittently to analyse risks of some claims. Recently, the data scientists have complained of slow queries.\n",
    "\n",
    "What will be the most cost-effective solution to increase the performance of your Redshift cluster?\n",
    "\n",
    "\n",
    "Change the Redshift storage to provisioned IOPS(Input/Output Operations per Second) to increase the I/O \n",
    "\n",
    "\n",
    "Create separate Redshift cluster for data scientists and ask them to use that for their queries\n",
    "\n",
    "\n",
    "Change node type of Redshift cluster to DC2.XLARGE using Elastic Resize.\n",
    "\n",
    "\n",
    "Create separate WLM queue for data scientists and the BI dashboards and configure Automatic WLM   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1d8cf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49cf07c2",
   "metadata": {},
   "source": [
    "Q6 EXPLAIN Command\n",
    "You are working on tuning the performance on an SQL query on Redshift cluster. You generated an EXPLAIN plan for this query and see the following output:\n",
    "\n",
    "Query:\n",
    "\n",
    "explain select eventid, eventname, event.venueid, venuename from event, venue where event.venueid = venue.venueid\n",
    "Output:\n",
    "\n",
    "XN Hash Join DS_DIST_OUTER  (cost=2.52..58653620.93 rows=8712 width=43)\n",
    "Hash Cond: (\"outer\".venueid = \"inner\".venueid)\n",
    "->  XN Seq Scan on event  (cost=0.00..87.98 rows=8798 width=23)\n",
    "->  XN Hash  (cost=2.02..2.02 rows=202 width=22)\n",
    "->  XN Seq Scan on venue  (cost=0.00..2.02 rows=202 width=22)\n",
    "(519 rows)\n",
    "How would you tune this query?\n",
    "\n",
    "\n",
    "Change the distribution style of event table to ALL\n",
    "\n",
    "\n",
    "Change the distribution style of venue table to ALL   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a128908",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c909869e",
   "metadata": {},
   "source": [
    "Q7 Redshift Fault Tolerance\n",
    "You are running a single-node Redshift cluster. What happens to the durability when one of the drives on this node fails due to a hardware issue?\n",
    "\n",
    "\n",
    "The node with failed drive will get replaced automatically and the cluster will be available for read and write immediately. The data on the failed drive will be recovered using backups.\n",
    "\n",
    "\n",
    "The failed drive will get replaced automatically and the cluster will be available for read and write immediately. The data on failed drive will be lost and cannot be recovered\n",
    "\n",
    "\n",
    "The failed drive will get replaced automatically and the cluster will be available for read and write immediately. The data on failed drive will recovered using backups on S3\n",
    "\n",
    "\n",
    "You will have to manually create a new cluster from one of the prior snapshots. The data lost will not be recovered.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882a2119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1880368e",
   "metadata": {},
   "source": [
    "Q8 Node Type\n",
    "You are working for an organization who were using a Redshift cluster with 3 ds2.xlarge nodes to store about 5 TB of raw data. They expect the data to grow further at a rate of 2 TB every month. They have a BI dashboard which makes use of all data present on the Redshift cluster. \n",
    "\n",
    "\n",
    "They are looking for an optimal solution to meet their increased data growth and storage requirement. Which solution will be the most efficient and cost-optimised? \n",
    "\n",
    "\n",
    "Add a new node to the Redshift cluster every month to store additional data.\n",
    "\n",
    "\n",
    "Offload some data to S3 and query using Redshift Spectrum\n",
    "\n",
    "\n",
    "Upgrade to RA3 node types using Elastic Resize   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f16ca9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7af1f9cf",
   "metadata": {},
   "source": [
    "Q9 DIST Key\n",
    "You are using a Redshift cluster of 2-node ds2.xlarge type nodes (with 2 slices each). When you use DISTSTYLE ALL for a Redshift table, how is the data stored on compute nodes?\n",
    "\n",
    "\n",
    "Data is stored on the Master Node\n",
    "\n",
    "\n",
    "Data is stored on Compute Node-1 only\n",
    "\n",
    "\n",
    "Data is stored on all slices of all compute nodes\n",
    "\n",
    "\n",
    "Data is stored on first slice of all compute node   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bb6c63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e79620df",
   "metadata": {},
   "source": [
    "Q10 Redshift Cluster\n",
    "Your organization has just started using AWS Redshift for their data warehousing needs. They have determined that they will be using it for the next 3 years as per the current business plan. As a solutions architect, which of the following solutions would you suggest for saving on Redshift costs?\n",
    "\n",
    "\n",
    "Use on-demand Redshift instances for the cluster\n",
    "\n",
    "\n",
    "Use RA3 node types for the Redshift cluster\n",
    "\n",
    "\n",
    "Reserve Redshift nodes for 3 years using Redshift instance reservation  ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549efe31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f05b1c9d",
   "metadata": {},
   "source": [
    "# Getting Started with Apache Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25efbc04",
   "metadata": {},
   "source": [
    "## Spark Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b94f28a",
   "metadata": {},
   "source": [
    "Apache Spark\n",
    "Which of the following is not a key functionality of Spark?\n",
    "\n",
    "\n",
    "High Speed\n",
    "\n",
    "\n",
    "Ease of use\n",
    "\n",
    "\n",
    "Ability to build databases    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837e1389",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17076253",
   "metadata": {},
   "source": [
    "Apache Spark\n",
    "Which of the following statements is not correct?\n",
    "\n",
    "\n",
    "MapReduce is a data-processing framework.\n",
    "\n",
    "\n",
    "Apache Spark is a data-processing framework.\n",
    "\n",
    "\n",
    "HDFS is a data-processing framework.   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc0d4cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77a1afaa",
   "metadata": {},
   "source": [
    "Apache Spark\n",
    "Which of the following cluster managers is/are supported by Spark?\n",
    "\n",
    "\n",
    "Apache Mesos    ✓ Correct\n",
    "\n",
    "YARN    ✓ Correct\n",
    "\n",
    "Standalone Cluster Manager    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6122e235",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cfbc2c39",
   "metadata": {},
   "source": [
    "## Spark vs. MapReduce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb306fce",
   "metadata": {},
   "source": [
    "Spark vs MapReduce\n",
    "Choose whether the following statement is True or False:\n",
    "\n",
    "“Disk-based processing systems are cheaper and, hence, they can be scaled to a greater extent at a lower price when compared with in-memory processing”.\n",
    "\n",
    "\n",
    "True    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66390f8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "949f13e9",
   "metadata": {},
   "source": [
    "Spark vs MapReduce\n",
    "Which of the following tools will be more suitable to host a ticket booking portal for a travel company website?\n",
    "\n",
    "\n",
    "Hadoop MapReduce\n",
    "\n",
    "\n",
    "Apache Spark    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e32a198",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8a33975",
   "metadata": {},
   "source": [
    "Spark vs MapReduce\n",
    "Choose whether the following statement is True or False.\n",
    "\n",
    "\n",
    "“To run Spark on an HDFS system, you need to perform some modification to the HDFS architecture”.\n",
    "\n",
    "\n",
    "True\n",
    "\n",
    "\n",
    "False   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4597ebef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be5d5542",
   "metadata": {},
   "source": [
    "When to use Spark\n",
    "Which of the following sizes of a data set is Spark most ideally suited for? (Choose the most appropriate answer.)\n",
    "\n",
    "\n",
    "200–300 MB\n",
    "\n",
    "\n",
    "1–10 GB\n",
    "\n",
    "\n",
    "600–700 GB   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c101d18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01c199b7",
   "metadata": {},
   "source": [
    "Spark vs MapReduce\n",
    "Which of the following has higher latency?\n",
    "\n",
    "\n",
    "Spark\n",
    "\n",
    "\n",
    "MapReduce   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6552d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94a91fb1",
   "metadata": {},
   "source": [
    "## Spark Ecosystem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c267c3f",
   "metadata": {},
   "source": [
    "Apache Spark Ecosystem\n",
    "Which of the following provides an execution platform for Spark applications?\n",
    "\n",
    "\n",
    "Spark MLlib\n",
    "\n",
    "\n",
    "Spark Streaming\n",
    "\n",
    "\n",
    "Spark Core  ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a2a0c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "392bde3a",
   "metadata": {},
   "source": [
    "Apache Spark Ecosystem\n",
    "In which form does the Spark Core engine process data?\n",
    "\n",
    "\n",
    "DataFrames\n",
    "\n",
    "\n",
    "Datasets\n",
    "\n",
    "\n",
    "RDDs  ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ef740a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44e41cfa",
   "metadata": {},
   "source": [
    "Apache Spark Ecosystem\n",
    "Is the following statement True or False?\n",
    "\n",
    "“The Dataframe API in Spark stores data in the form of rows and columns”.\n",
    "\n",
    "\n",
    "True  ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff242dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c1c99dd",
   "metadata": {},
   "source": [
    "Apache Spark Ecosystem\n",
    "Which of the following is a library that comes bundled with Spark?\n",
    "\n",
    "\n",
    "Spark MLlib   ✓ Correct\n",
    "\n",
    "Spark JavaScript\n",
    "\n",
    "\n",
    "Spark SQL   ✓ Correct\n",
    "\n",
    "Spark R  ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf757d45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ecb0834",
   "metadata": {},
   "source": [
    "## Spark Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191ab52a",
   "metadata": {},
   "source": [
    "Master–Slave Architecture\n",
    "Which of the following processes runs over the slave node?\n",
    "\n",
    "\n",
    "Driver program\n",
    "\n",
    "\n",
    "Executor  ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd2ff45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fff82fd8",
   "metadata": {},
   "source": [
    "Master–Slave Architecture\n",
    "Which of the following statements about the Driver node is/are true?\n",
    "\n",
    "\n",
    "Driver node is the entry point of the Spark Shell environment.   ✓ Correct\n",
    "\n",
    "Driver node performs all the data processing involved in each task.\n",
    "\n",
    "\n",
    "Driver node is responsible for allocating the resources that are required to execute a task.\n",
    "\n",
    "\n",
    "Driver node stores the metadata of all the RDDs and their partitions.   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10213fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "faa8f2db",
   "metadata": {},
   "source": [
    "Spark Architecture\n",
    "Which of the following components of Spark runtime architecture provides resources to execute a task?\n",
    "\n",
    "\n",
    "Spark Context\n",
    "\n",
    "\n",
    "Driver program\n",
    "\n",
    "\n",
    "Cluster manager   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fa3ee7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c9bebdd",
   "metadata": {},
   "source": [
    "Spark Architecture\n",
    "Choose whether the following statement is True or False:\n",
    "\n",
    "“A cluster manager is necessary to launch Spark.”\n",
    "\n",
    "\n",
    "True\n",
    "\n",
    "\n",
    "False   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c648bff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "59dc1c66",
   "metadata": {},
   "source": [
    "Spark Architecture\n",
    "“The final output of a Spark job is sent from the executors to the ____.”\n",
    "\n",
    "\n",
    "Cluster manager\n",
    "\n",
    "\n",
    "Driver node   ✓ Correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f535844",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0874a9f6",
   "metadata": {},
   "source": [
    "Spark Architecture\n",
    "Can we deploy Spark over Hadoop architecture?\n",
    "\n",
    "\n",
    "Yes   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c067f71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c37e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Spark APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dfa676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9915c07e",
   "metadata": {},
   "source": [
    "Spark APIs\n",
    "Which of the following APIs is useful for dealing with image or text files?\n",
    "\n",
    "\n",
    "Unstructured or low-level APIs   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcc9ecf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "176b4790",
   "metadata": {},
   "source": [
    "# Programming with Spark RDD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8406482d",
   "metadata": {},
   "source": [
    "## Introduction to Spark RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7212b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Spark RDDs\n",
    "Can you change the data in an RDD once the RDD is created?\n",
    "\n",
    "\n",
    "Yes\n",
    "\n",
    "\n",
    "No   ✓ Correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6d2e34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37880b47",
   "metadata": {},
   "source": [
    "Spark RDDs\n",
    "Can Spark RDDs be used to store and analyse structured data?\n",
    "\n",
    "\n",
    "Yes   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623c76d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3016dc0",
   "metadata": {},
   "source": [
    "## Creating RDDs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c134d5",
   "metadata": {},
   "source": [
    "Creating RDDs\n",
    "Suppose you have a data set loaded in the Spark environment in the form of an array. Which of the following methods would be the most suitable to convert the data set into an RDD?\n",
    "\n",
    "\n",
    "textFile() method\n",
    "\n",
    "\n",
    "parallelize() method  ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33bfaa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8188f083",
   "metadata": {},
   "source": [
    "SparkSession\n",
    "What are the two necessary parameters to be specified at the time of initialising a SparkContext?\n",
    "\n",
    "\n",
    "Application name    ✓ Correct\n",
    "\n",
    "Number of executors provided for a Spark application\n",
    "\n",
    "\n",
    "The memory allocated to each executor\n",
    "\n",
    "\n",
    "Cluster mode    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce1bd56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1b2c22e",
   "metadata": {},
   "source": [
    "Spark Programming\n",
    "Identify the correct syntax for saving an RDD externally on the disk.\n",
    "\n",
    "\n",
    "saveastextfile()\n",
    "\n",
    "\n",
    "SaveAsTextFile()\n",
    "\n",
    "\n",
    "saveAsTextFile()   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1b5c80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "436be462",
   "metadata": {},
   "source": [
    "## Transformation Operations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c6e164",
   "metadata": {},
   "source": [
    "RDD Operations\n",
    "The input and output of a program are given below. Select the most appropriate function.\n",
    "\n",
    "input1=[1,2,3,4,5]\n",
    "rdd=spark.sparkContext.parallelize(input1)\n",
    "op1= (Select the correct option)\n",
    "op1.collect()\n",
    "OUTPUT: [(1,1),(2,1),(3,1),(4,1),(5,1)]\n",
    "\n",
    "\n",
    "op1=rdd.map(lambda x: (x,1))    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79b8717",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "600b2f4d",
   "metadata": {},
   "source": [
    "Apache Spark\n",
    "Which of the following statements is correct?\n",
    "\n",
    "\n",
    "The glom() function stores data inside RDDs as an external file.\n",
    "\n",
    "\n",
    "The glom() function creates a nested structure that stores data in each partition separately.  ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b43851",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "053a271b",
   "metadata": {},
   "source": [
    "RDD Operations\n",
    "Suppose there is an RDD ‘rdd1’, which represents a list of places where company A has its branches. There is another RDD ‘rdd2’, which represents a list of places where company B has its branches. Which of the following statements is correct?\n",
    "\n",
    "\n",
    "rdd1.subtract(rdd2) results in an RDD that contains a list of places where company A has its branches but company B does not.   ✓ Correct\n",
    "\n",
    "rdd1.subtract(rdd2) results in an RDD that contains a list of places where company B has its branches but company A does not.\n",
    "\n",
    "\n",
    "rdd1.intersection(rdd2) results in an RDD that contains a list of places where both company A and company B have their branches.   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f873e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2949a1d3",
   "metadata": {},
   "source": [
    "RDD Operations\n",
    "Suppose there is an RDD ‘rdd1’, which represents a list of places where company A has its branches. There is another RDD ‘rdd2’, which represents a list of places where company B has its branches. Which of the following codes results in an RDD that contains all those places where company A and company B may have their branches?\n",
    "\n",
    "\n",
    "rdd1.union(rdd2)\n",
    "\n",
    "\n",
    "(rdd1.union(rdd2)).subtract(rdd1.intersection(rdd2))\n",
    "\n",
    "\n",
    "(rdd2.union(rdd1)).subtract(rdd2.intersection(rdd1))\n",
    "\n",
    "\n",
    "rdd1.union(rdd2).distinct()   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639f1365",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19aeeb01",
   "metadata": {},
   "source": [
    "## Action Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa28ee6",
   "metadata": {},
   "source": [
    "Transformations and Actions\n",
    "Suppose you have the following RDD.\n",
    "rdd1 = sc.parallelize(['upGrad', 'IITM', 'Prof. Janakiram', 'MLC', 'AWS', 'Cloud'])\n",
    "\n",
    "Which of the following commands will result in the output as 'upGrad'?\n",
    "\n",
    "\n",
    "rdd.collect()\n",
    "\n",
    "\n",
    "rdd1.first()    ✓ Correct\n",
    "\n",
    "rdd1.filter(lambda x: x[0] =='u')\n",
    "\n",
    "\n",
    "rdd1.take(1)    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612a57bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1b93620",
   "metadata": {},
   "source": [
    "Apache Spark\n",
    "‘Fine-grained’ means that you can transform individual elements of a data set. ‘Coarse-grained’ means that you can transform an entire data set but not an individual element of it. \n",
    "Which of the following statements is true about RDDs?\n",
    "\n",
    "\n",
    "The read operation on an RDD can either be fine-grained or coarse-grained.   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef5ba80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "868f5f1c",
   "metadata": {},
   "source": [
    "RDD Operations\n",
    "Which of the following is not a transformation?\n",
    "\n",
    "\n",
    "sample()\n",
    "\n",
    "\n",
    "map()\n",
    "\n",
    "\n",
    "reduce()   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755dfef5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9fc4ccf1",
   "metadata": {},
   "source": [
    "RDD Operations\n",
    "In a given RDD, you need to find out the number of occurrences of a particular element of the RDD. Which of the following actions will you perform?\n",
    "\n",
    "\n",
    "count()\n",
    "\n",
    "\n",
    "take()\n",
    "\n",
    "\n",
    "fold()\n",
    "\n",
    "\n",
    "countByValue()   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c998baab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5135568",
   "metadata": {},
   "source": [
    "## Lazy Evaluation in Spark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9efae13",
   "metadata": {},
   "source": [
    "DAG\n",
    "Consider the following DAG showing an overall execution path of a Spark application and answer the following question.\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "What is the total number of transformations included in a Spark application?\n",
    "\n",
    "\n",
    "7\n",
    "\n",
    "\n",
    "6\n",
    "\n",
    "\n",
    "5   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9406f72a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b7a83fa",
   "metadata": {},
   "source": [
    "DAG\n",
    "Consider the following DAG showing an overall execution path of a Spark application and answer the following question.\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "Suppose a node on the cluster, storing one of the partitioned data of RDD5, loses all its data. Now, in order to recover the partitions of RDD5, the lineage graph of RDD5 is referred to, which is:\n",
    "\n",
    "\n",
    "RDD1→RDD2→RDD3→RDD4→RDD5​​​\n",
    "\n",
    "\n",
    "RDD1→RDD2→RDD3→RDD5​​   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfc880b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f3a8425",
   "metadata": {},
   "source": [
    "DAG\n",
    "RDD Lineage (a.k.a RDD operator graph or RDD dependency graph) is a graph that consists of the parent RDDs of an RDD. It is built as a result of applying transformations to the RDD.\n",
    "join: It is a transformation for joining two paired RDDs based on common keys. If there are two RDDs of <x,y> and <x,z> types, then the resultant RDD will be in the form of <x,(y,z)>.\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "Let's consider this as the dependency or lineage graph for RDD R33. From the diagram above, identify the RDDs that are directly created by referring to external datasets in a single step.\n",
    "\n",
    "\n",
    "R00 and R01  ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04528d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c940cf4",
   "metadata": {},
   "source": [
    "# Paired RDDs\n",
    "Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384a8f7e",
   "metadata": {},
   "source": [
    "## Paired RDDs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317b0b3b",
   "metadata": {},
   "source": [
    "Paired RDDs\n",
    "Suppose you have the following RDD:\n",
    "\n",
    "rdd1 = sc.parallelize(['upGrad', 'IIITB', 'SME', 'DE', 'AWS', 'Cloud'])\n",
    "Select the code that gives the number of characters in each element of the RDD along with it.\n",
    "\n",
    "Resultant RDD: [('upGrad', 6),  ('IIITB', 5),  ('SME', 3),  ('DE', 2),  ('AWS', 3),  ('Cloud', 5)]\n",
    "\n",
    "\n",
    "rdd1.map(x, len(x))\n",
    "\n",
    "\n",
    "rdd1.map(lambda x: (x, count(x)))\n",
    "\n",
    "\n",
    "rdd1.flatMap(lambda x: (x, len(x)))\n",
    "\n",
    "\n",
    "rdd1.map(lambda x: (x, len(x))) ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be37b43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "154afc55",
   "metadata": {},
   "source": [
    "Paired RDDs\n",
    "Suppose you have the following RDD that represents the marks of students in different subjects out of 100:\n",
    "\n",
    "marks = sc.parallelize([('Phanendra', 'English', 98), ('Kaustubh', 'Mathematics', 99), ('Vishal', 'English', 95), ('Kaustubh', 'Science', 100), ('Phanendra', 'Science', 94), ('Vishal', 'Science', 97), ('Kaustubh', 'English', 96), ('Vishal', 'Mathematics', 98), ('Phanendra', 'Mathematics', 98)])\n",
    "Which of the following codes will result in the aggregate percentage scored by the students in the class?\n",
    "\n",
    "\n",
    "marks.groupByKey().mapValues(sum).map(lambda x: (x[0], x[1]/3)).collect()\n",
    "\n",
    "\n",
    "marks.map(lambda x: (x[0], x[2])).reduceByKey(lambda x,y: (x+y)).map(lambda x: (x[0], x[1]/3)).collect()  ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fa4df9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa20a47e",
   "metadata": {},
   "source": [
    "Paired RDDs\n",
    "Suppose you have the following RDD that represents the marks of students in different subjects out of 100:\n",
    "\n",
    "marks = sc.parallelize([('Phanendra', 'English', 98), ('Kaustubh', 'Mathematics', 99), ('Vishal', 'English', 95), ('Kaustubh', 'Science', 100), ('Phanendra', 'Science', 94), ('Vishal', 'Science', 97), ('Kaustubh', 'English', 96), ('Vishal', 'Mathematics', 98), ('Phanendra', 'Mathematics', 98)])\n",
    "Which of the following codes will help in obtaining the highest score for each subject?\n",
    "\n",
    "\n",
    "marks.map(lambda x: (x[1], x[2])).reduceByKey(max).collect()    ✓ Correct\n",
    "\n",
    "marks.reduceByKey(max).collect()\n",
    "\n",
    "\n",
    "marks.map(lambda x: (x[1], x[2])).groupByKey().map(lambda x: (x[0], max(x[1]))).collect()    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2e8f9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc0cc48d",
   "metadata": {},
   "source": [
    "## Operations on Paired RDDs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a42b374",
   "metadata": {},
   "source": [
    "RDD Operations\n",
    "In a given paired RDD, if we want to find out whether a certain key is present or not which of the following commands should be used?\n",
    "\n",
    "\n",
    "collectAsMap()\n",
    "\n",
    "\n",
    "lookup()   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e87798c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8c25727",
   "metadata": {},
   "source": [
    "Paired RDDs\n",
    "Which of the following statements is/are correct?\n",
    "\n",
    "\n",
    "The result of rdd1.leftOuterJoin(rdd2) will contain all those elements whose keys are present in rdd1.   ✓ Correct\n",
    "\n",
    "The result of rdd1.rightOuterJoin(rdd2) will contain all those elements whose keys are present in rdd1.\n",
    "\n",
    "\n",
    "The result of rdd1.cogroup(rdd2) will contain all those elements whose keys are present in rdd1.\n",
    "\n",
    "\n",
    "The result of rdd1.cogroup(rdd2) will contain all those elements whose keys are present in both the RDDs.   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b251225",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dee84108",
   "metadata": {},
   "source": [
    "## Word Count Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdd8f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "RDD Operations\n",
    "Which of the following statements is/are correct?\n",
    "\n",
    "\n",
    "rdd1.map() returns the same number of elements as present in the rdd1.    ✓ Correct\n",
    "\n",
    "rdd1.flatMap() returns the same number of elements as present in the rdd1.\n",
    "\n",
    "\n",
    "The rdd1.flatmap() does not return the same number of elements as present in the rdd1.    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26a5695",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7430e90f",
   "metadata": {},
   "source": [
    "# Spark Structured APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db43c773",
   "metadata": {},
   "source": [
    "## DataFrames and Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb60bde",
   "metadata": {},
   "source": [
    "RDDs vs Dataframes\n",
    "What are the benefits of using dataframes over RDDs?\n",
    "\n",
    "\n",
    "API in multiple languages\n",
    "\n",
    "\n",
    "Data type safety is offered in dataframes   ✓ Correct\n",
    "\n",
    "Dataframes optimes execution plan   ✓ Correct\n",
    "\n",
    "Dataframe API can infer the schema of the data   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc80d84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a289080",
   "metadata": {},
   "source": [
    "RDDs vs Dataframes/Datasets\n",
    "A data set is given to you, it is quite large (in Gbs). The column names in the data set are not standardised yet. To call column type transformations on this kind of data which API is most suitable?\n",
    "\n",
    "\n",
    "Dataset   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1435e74f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "161dde92",
   "metadata": {},
   "source": [
    "Encoders\n",
    "What is the function of encoders?\n",
    "\n",
    "\n",
    "Encryption of the data so that it is safe on the cluster\n",
    "\n",
    "\n",
    "Conversion of high-level instructions to sparks internal binary format.\n",
    "\n",
    "\n",
    "Conversion of spark tabular data to JVM objects   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35500da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c37dcfff",
   "metadata": {},
   "source": [
    "Spark APIs\n",
    "GC(Garbage Collector) in is responsible for cleaning both off-heap and on-heap memory.\n",
    "Please choose whether the above statement is True or False.\n",
    "\n",
    "\n",
    "True\n",
    "\n",
    "\n",
    "False  ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1d1b8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "718469b0",
   "metadata": {},
   "source": [
    "## Catalyst Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db263493",
   "metadata": {},
   "source": [
    "RDDs vs Dataframes\n",
    "Which of the following Spark data structure/s leverage/s the benefits of the Catalyst optimiser?\n",
    "\n",
    "\n",
    "RDD\n",
    "\n",
    "\n",
    "Dataframe   ✓ Correct\n",
    "\n",
    "Dataset   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec7edd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf0ab0f8",
   "metadata": {},
   "source": [
    "RDDs vs Dataframes\n",
    "Identify the Catalyst transformation in the situation given below:\n",
    "\"If your query only utilises a set of columns rather than the entire column list present in the data, then the Catalyst optimiser will try to fetch the relevant columns that are used in the query, to reduce storage and computation.\"\n",
    "\n",
    "\n",
    "Predicate pushdown\n",
    "\n",
    "\n",
    "Column pruning  ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd30ad0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5fdd304d",
   "metadata": {},
   "source": [
    "## Getting Started with DataFrame APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06331322",
   "metadata": {},
   "source": [
    "Loading CSV\n",
    "Analysis needs to be carried out on a dataset stored in data.csv. Which of the following commands will read the data from the CSV into a dataframe?\n",
    "\n",
    "\n",
    "spark.read.load(“data.csv”,format = “csv”)   ✓ Correct\n",
    "\n",
    "spark.read.csv(“data.csv”)   ✓ Correct\n",
    "\n",
    "spark.sql(“select * from csv.data.csvdata.csv\")   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8f1984",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "604650a6",
   "metadata": {},
   "source": [
    "InferSchema\n",
    "State whether the following statement is true or false.\n",
    "‘If inferSchema is set as true, Spark will set the data types for all the columns.’\n",
    "\n",
    "\n",
    "True  ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ba93bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5101cb9e",
   "metadata": {},
   "source": [
    "File Formats\n",
    "The following read command was used to read data and it was executed successfully.\n",
    "\n",
    "spark.read.load(\"filename.fileformat\")\n",
    "What should be the file format here?\n",
    "\n",
    "\n",
    "Csv\n",
    "\n",
    "\n",
    "Json\n",
    "\n",
    "\n",
    "ORC\n",
    "\n",
    "\n",
    "Parquet  ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1c7071",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d6db239",
   "metadata": {},
   "source": [
    "## DataFrame Operations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2213d747",
   "metadata": {},
   "source": [
    "Dataframes\n",
    "Consider the following code:\n",
    "\n",
    "df2 = df.select(df.name).orderBy(df.name.desc())\n",
    "df2  is a dataframe with:\n",
    "\n",
    "\n",
    "All columns in df in ascending order\n",
    "\n",
    "\n",
    "All columns in df in descending order\n",
    "\n",
    "\n",
    "The column ‘name’ in descending order  ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097bb0b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33410f45",
   "metadata": {},
   "source": [
    "Dataframes\n",
    "Consider the following code:\n",
    "\n",
    "df.describe()\n",
    "What will be the output of the code?\n",
    "\n",
    "\n",
    "The statistical description of all the numerical columns in df\n",
    "\n",
    "The object df and its memory location   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba1d623",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c14fa925",
   "metadata": {},
   "source": [
    "Spark SQL API\n",
    "Consider the following code:\n",
    "\n",
    "df2 = df.filter(\"speed>100\")  #filters and gives a new dataframe with all speeds more than 100\n",
    "\n",
    "df2    #show the new dataframe df2\n",
    "What will be the output of the command?\n",
    "\n",
    "\n",
    "It will show the new dataframe created\n",
    "\n",
    "\n",
    "It will show that df2 is a dataframe and show its alloted memory position   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937ea5cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a19eadc",
   "metadata": {},
   "source": [
    "# Graded Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbee2cd8",
   "metadata": {},
   "source": [
    "## Graded Questions Part - I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe996a37",
   "metadata": {},
   "source": [
    "Q1 Spark Architecture\n",
    "Feature\tElement\n",
    "1. To control the execution of Spark application\tI. Driver node\n",
    "2. To execute tasks associated with a Spark application\tII. Driver program\n",
    " \tIII. Cluster Manager\n",
    " \tIV. Executor\n",
    "\n",
    "1 - II, 2 - III\n",
    "\n",
    "\n",
    "1 - I, 2 - IV\n",
    "\n",
    "\n",
    "1 - II, 2 - I\n",
    "\n",
    "1 - II, 2 - IV   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ede92b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ac798f3",
   "metadata": {},
   "source": [
    "Q2 Spark RDDs\n",
    "Select the correct statement from the following options.\n",
    "\n",
    "\n",
    "The RDDs are loaded as soon as a transformation is executed in Spark.\n",
    "\n",
    "\n",
    "The RDDs are loaded in the executor memory as soon as the parallelize() command is executed.\n",
    "\n",
    "\n",
    "The RDDs are lazily loaded into the Executor memory.   ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb1c0d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51c95756",
   "metadata": {},
   "source": [
    "Q3 Spark SQL\n",
    "Let's say we have a variable 'hdfspath' containing a valid path to an HDFS file. What is wrong with the following snippet of code?\n",
    "\n",
    "Code Format:\n",
    "\n",
    "df = spark.read.json(hdfspath)\n",
    "spark.sql(\"select count(reviewText), asin from df group by asin\")\n",
    " \n",
    "\n",
    "\n",
    "The code is fine.\n",
    "\n",
    "\n",
    "You cannot use a 'count' type aggregation on a field containing strings (i.e., reviewText).\n",
    "\n",
    "\n",
    "Temporary table has to be created from the dataframe.  ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca6968c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "208b1a78",
   "metadata": {},
   "source": [
    "Q4 Spark Session\n",
    "Which of the following are the properties of a spark session?\n",
    "\n",
    "\n",
    "It provides a gateway to access all of the spark contexts functionality\n",
    "\n",
    "✓ Correct\n",
    "Feedback:\n",
    "With a spark session, there is no need to create new spark context. A Spark session combines all the different APIs.\n",
    "\n",
    "\n",
    "It can handle HIVE, SQL APIs  ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb874f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de6486d9",
   "metadata": {},
   "source": [
    "Q5 Dataframe Operations\n",
    "Suppose you are given a dataframe with the following columns:\n",
    "Roll_No, Age, Weight, Height, Medical_Alleries.\n",
    "\n",
    "You are supposed to find out the number of students whose weight is above 60 kg and height is greater than 5 feet. Which of the following commands will yield the required solution correctly?\n",
    "\n",
    "\n",
    "df.filter((df['weight']>60.0) & (df['Height’]>5.0)).show() ✓ Correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fc524f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "209b14e2",
   "metadata": {},
   "source": [
    "Q6 Dataframe Operations\n",
    "Consider the following code:\n",
    "\n",
    "df2 = df.select(df.name).orderBy(df.name.desc())\n",
    "df2 is a dataframe with:\n",
    "\n",
    "\n",
    "All rows in df in ascending order\n",
    "\n",
    "\n",
    "The resultant dataset will contain all the columns present in df2\n",
    "\n",
    "\n",
    "The resultant dataset will contain only the 'name' column arranged in descending order.  ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4ff5a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e72b01c0",
   "metadata": {},
   "source": [
    "## Graded Questions Part - II"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7955051d",
   "metadata": {},
   "source": [
    "Q7 Dataframe Operations\n",
    "Using the data frame abstraction, calculate the number of ‘Iris_setosa’ species:\n",
    "\n",
    "\n",
    "df.filter(“species” == 'Iris-setosa').count(), 50\n",
    "\n",
    "\n",
    "df.filter(df[“species”] == 'Iris-setosa').count(), 50 ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d540e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "942b5c0f",
   "metadata": {},
   "source": [
    "Q8 Dataframe Operations\n",
    "Analyse the 'Iris-versicolor' species of the flower and calculate the sum of all ‘sepal_width’ and ‘petal_length’ for this species.\n",
    "\n",
    "\n",
    "df.filter(groupBy('species').sum('sepal_width','petal_length').show()\n",
    "\n",
    "sepal_width= 135.3, petal_length= 221.5\n",
    "\n",
    "\n",
    "df.filter(df['species'] == 'Iris-versicolor').groupBy('species').add('sepal_width','petal_length').show()\n",
    "\n",
    "sepal_width= 140.5, petal_length= 200\n",
    "\n",
    "\n",
    "df.filter(df['species'] == 'Iris-versicolor').groupBy('species').sum('sepal_width','petal_length').show()\n",
    "\n",
    "sepal_width= 138.5, petal_length= 212.97  ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd617ddd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a38b319",
   "metadata": {},
   "source": [
    "Q9 Dataframe Operations\n",
    "Is there any ‘Iris-setosa'  species with sepal_width greater than 4.0 and sepal_width less than 5.0? If yes, find out how many?\n",
    "\n",
    "\n",
    "No\n",
    "\n",
    "\n",
    "df.filter((df['species']==\"Iris-setosa\") & (df['sepal_width']>4) | (df['sepal_width']<5)).count(), 1\n",
    "\n",
    "\n",
    "df.filter((df['species']==\"Iris-setosa\") & (df['sepal_width']>4) & (df['sepal_width']<5)).count(), 3    ✓ Correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09da1bb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be99370a",
   "metadata": {},
   "source": [
    "Q10 Dataframe Operations\n",
    "Calculate the minimum petal_width for ‘Iris-virginica’ species.\n",
    "\n",
    "\n",
    "df.filter(df['species'] == 'Iris-virginica' ).groupBy('species').min('petal_width').show(), 1.4    ✓ Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756ec8f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c8f4023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jovian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0672a7aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Committed successfully! https://jovian.ai/ashutoshgole18/data-engineering-all-modules\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://jovian.ai/ashutoshgole18/data-engineering-all-modules'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jovian.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca08ca7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
